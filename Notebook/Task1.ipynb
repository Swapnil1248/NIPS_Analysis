{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step1: Read Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv(\"./data/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>EventType</th>\n",
       "      <th>PdfName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>PaperText</th>\n",
       "      <th>AbstractClean</th>\n",
       "      <th>PaperTextClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5677</td>\n",
       "      <td>Double or Nothing: Multiplicative Incentive Me...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>5677-double-or-nothing-multiplicative-incentiv...</td>\n",
       "      <td>Crowdsourcing has gained immense popularity in...</td>\n",
       "      <td>Double or Nothing: Multiplicative\\nIncentive M...</td>\n",
       "      <td>crowdsourcing gained immense popularity machin...</td>\n",
       "      <td>double nothing multiplicative incentive mechan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5941</td>\n",
       "      <td>Learning with Symmetric Label Noise: The Impor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5941-learning-with-symmetric-label-noise-the-i...</td>\n",
       "      <td>Convex potential minimisation is the de facto ...</td>\n",
       "      <td>Learning with Symmetric Label Noise: The\\nImpo...</td>\n",
       "      <td>convex potential minimisation de facto approac...</td>\n",
       "      <td>learning symmetric label noise importance unhi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>6019</td>\n",
       "      <td>Algorithmic Stability and Uniform Generalization</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6019-algorithmic-stability-and-uniform-general...</td>\n",
       "      <td>One of the central questions in statistical le...</td>\n",
       "      <td>Algorithmic Stability and Uniform Generalizati...</td>\n",
       "      <td>one central questions statistical learning the...</td>\n",
       "      <td>algorithmic stability uniform generalization i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>6035</td>\n",
       "      <td>Adaptive Low-Complexity Sequential Inference f...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>6035-adaptive-low-complexity-sequential-infere...</td>\n",
       "      <td>We develop a sequential low-complexity inferen...</td>\n",
       "      <td>Adaptive Low-Complexity Sequential Inference f...</td>\n",
       "      <td>develop sequential lowcomplexity inference pro...</td>\n",
       "      <td>adaptive lowcomplexity sequential inference di...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Id                                              Title  \\\n",
       "0           0  5677  Double or Nothing: Multiplicative Incentive Me...   \n",
       "1           1  5941  Learning with Symmetric Label Noise: The Impor...   \n",
       "2           2  6019   Algorithmic Stability and Uniform Generalization   \n",
       "3           3  6035  Adaptive Low-Complexity Sequential Inference f...   \n",
       "\n",
       "   EventType                                            PdfName  \\\n",
       "0     Poster  5677-double-or-nothing-multiplicative-incentiv...   \n",
       "1  Spotlight  5941-learning-with-symmetric-label-noise-the-i...   \n",
       "2     Poster  6019-algorithmic-stability-and-uniform-general...   \n",
       "3     Poster  6035-adaptive-low-complexity-sequential-infere...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Crowdsourcing has gained immense popularity in...   \n",
       "1  Convex potential minimisation is the de facto ...   \n",
       "2  One of the central questions in statistical le...   \n",
       "3  We develop a sequential low-complexity inferen...   \n",
       "\n",
       "                                           PaperText  \\\n",
       "0  Double or Nothing: Multiplicative\\nIncentive M...   \n",
       "1  Learning with Symmetric Label Noise: The\\nImpo...   \n",
       "2  Algorithmic Stability and Uniform Generalizati...   \n",
       "3  Adaptive Low-Complexity Sequential Inference f...   \n",
       "\n",
       "                                       AbstractClean  \\\n",
       "0  crowdsourcing gained immense popularity machin...   \n",
       "1  convex potential minimisation de facto approac...   \n",
       "2  one central questions statistical learning the...   \n",
       "3  develop sequential lowcomplexity inference pro...   \n",
       "\n",
       "                                      PaperTextClean  \n",
       "0  double nothing multiplicative incentive mechan...  \n",
       "1  learning symmetric label noise importance unhi...  \n",
       "2  algorithmic stability uniform generalization i...  \n",
       "3  adaptive lowcomplexity sequential inference di...  "
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "paper_id=list(df['Id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "import numpy.core.defchararray as npd\n",
    "import spacy\n",
    "from spacy.lang.en import English\n",
    "nlp = spacy.load('en')\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test1:\n",
    "    def _iter_nouns(self, sent):\n",
    "        '''\n",
    "        INPUT: SentCustomProperties\n",
    "        OUTPUT: str\n",
    "\n",
    "        Iterates through each token of spacy sentence and collects lemmas of all nouns into a set.\n",
    "        '''        \n",
    "        wordset = set()\n",
    "        noun_tag = set(['NN', 'NNP', 'NNS'])\n",
    "        nonaspects=set()\n",
    "        c=0\n",
    "        for token in doc:#nlp(sent):\n",
    "            c+=1\n",
    "            if c <100:\n",
    "                try:\n",
    "                    #print(\"test\")\n",
    "                    root = nlp.vocab[token.lemma].prob \n",
    "                    root1= nlp.vocab[token.lemma].vector_norm\n",
    "                    print(root1,root,token.tag_)\n",
    "                    # filter to only consider nouns, valid aspects, and uncommon words\n",
    "                    if token.tag_ in noun_tag :#and (root < -3.5 and token.lemma_ not in nonaspects):\n",
    "                        #print(root1,root,token.tag_)\n",
    "                        wordset.add(token)#, token.lemma_)\n",
    "                except:\n",
    "                    continue               \n",
    "            else:\n",
    "                break\n",
    "        #print(wordset)\n",
    "        #for token in doc: \n",
    "        #    print(token.text, token.lemma_, token.pos_, token.tag_)\n",
    "        #return \" \".join(wordset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [],
   "source": [
    "def jjnn_pairs(phrase):\n",
    "    '''\n",
    "    Iterate over pairs of JJ-NN.\n",
    "    '''\n",
    "    tagged = nltk.pos_tag(nltk.word_tokenize(phrase))\n",
    "    def ngramise(sequence):\n",
    "        \"\"\"\n",
    "        generate bigrams\n",
    "        \"\"\"\n",
    "        for bigram in nltk.ngrams(sequence, 2):\n",
    "            yield bigram\n",
    "\n",
    "    for ngram in ngramise(tagged):\n",
    "        tokens, tags = zip(*ngram)\n",
    "        if tags == ('JJ', 'NN'):\n",
    "            print(tokens,tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('sweet', 'chili') ('JJ', 'NN')\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "s = [\"thai iced tea spicy fried chicken sweet chili pork thai chicken curry\"]\n",
    "for phrase in s:\n",
    "    #print(noun_notnoun(phrase))\n",
    "    print(jjnn_pairs(phrase))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class test:\n",
    "    def _iter_nouns(self, sent):\n",
    "        '''\n",
    "        INPUT: SentCustomProperties\n",
    "        OUTPUT: str\n",
    "        Iterates through each token of spacy sentence and collects lemmas of all nouns into a set.\n",
    "        '''\n",
    "        # dictionary of unigram_nouns\n",
    "        unigram_wordset = dict()\n",
    "        # Identify noun tags\n",
    "        noun_tag = set(['NN', 'NNP', 'NNS'])\n",
    "        # List of keywords we want to exclude \n",
    "        nonaspects=set()\n",
    "            \n",
    "        for token in sent:            \n",
    "            # filter to only consider nouns, valid aspects, and uncommon words\n",
    "            if token.tag_ in noun_tag and token.lemma_ not in nonaspects:\n",
    "                if token.lemma_ in unigram_wordset:\n",
    "                    unigram_wordset[token.lemma_]+=1\n",
    "                else:\n",
    "                    unigram_wordset[token.lemma_]= 1\n",
    "\n",
    "        # Note: We need to normalize the count of nouns with respect to the total noun counts \n",
    "        # as in certain scenarios there will be few nouns and we can't pick nouns based on count\n",
    "        nouns_count=sum([val for val in unigram_wordset.values()])\n",
    "        \n",
    "        unigram_wordset_norm={key: val/nouns_count for (key,val) in unigram_wordset.items()}\n",
    "        top_aspects=[aspect for aspect in unigram_wordset_norm.keys() if unigram_wordset_norm[aspect]>0.01]\n",
    "        print(top_aspects)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mechanism', 'crowdsourcing', 'amount', 'datum', 'payment', 'worker', 'question', 'experiment', 'task', 'algorithm', 'answer', 'confidence', 'g']\n"
     ]
    }
   ],
   "source": [
    "for i in paper_id[:1]:\n",
    "    nlp = spacy.load('en_core_web_sm') # this is for core english\n",
    "    nlp.add_pipe(nlp.create_pipe('sentencizer'))\n",
    "    doc=nlp(str(df[df.Id==i]['PaperTextClean'][0])) #Spacy Doc type\n",
    "    #print(type(doc))\n",
    "    a._iter_nouns(doc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1: Generate FastText word embeddings\n",
    "1. support a user-defined number of dimensions \n",
    "2. have the ability to turn on/off at least one text-preprocessing step.\n",
    "\n",
    "### Step 1: Preprocessing data\n",
    "- data be in str format for python 3 \n",
    "space\n",
    "tab\n",
    "vertical tab\n",
    "carriage return\n",
    "formfeed\n",
    "the null character\n",
    "\n",
    "#### text preprocessing guidelines - \n",
    "https://www.kdnuggets.com/2018/08/practitioners-guide-processing-understanding-text-2.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from nltk.corpus import gutenberg\n",
    "from string import punctuation\n",
    "\n",
    "bible = gutenberg.sents('bible-kjv.txt')\n",
    "from string import punctuation\n",
    "remove_terms = punctuation + '0123456789'\n",
    "!python -m spacy link en_core_web_sm en"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import en_core_web_sm\n",
    "#nlp = en_core_web_sm.load()\n",
    "import spacy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "from nltk.tokenize.toktok import ToktokTokenizer\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "#from pycontractions import Contractions\n",
    "import unicodedata\n",
    "\n",
    "import spacy\n",
    "nlp = spacy.load('en')\n",
    "#nlp = spacy.load('en_core', parse=True, tag=True, entity=True)\n",
    "#nlp_vec = spacy.load('en_vecs', parse = True, tag=True, #entity=True)\n",
    "tokenizer = ToktokTokenizer()\n",
    "stopword_list = nltk.corpus.stopwords.words('english')\n",
    "stopword_list.remove('no')\n",
    "stopword_list.remove('not')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [],
   "source": [
    "def strip_html_tags(text):\n",
    "    soup = BeautifulSoup(text, \"html.parser\")\n",
    "    stripped_text = soup.get_text()\n",
    "    return stripped_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_accented_chars(text):\n",
    "    text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Abstract[:10].apply(remove_accented_chars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Well this was fun What do you think '"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_special_characters(text, remove_digits=False):\n",
    "    pattern = r'[^a-zA-z0-9\\s]' if not remove_digits else r'[^a-zA-z\\s]'\n",
    "    text = re.sub(pattern, '', text)\n",
    "    return text\n",
    "\n",
    "remove_special_characters(\"Well this was fun! What do you think? 123#@!\", remove_digits=True)\n",
    "#df.Abstract[:10].apply(remove_special_characters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simple_stemmer(text):\n",
    "    ps = nltk.porter.PorterStemmer()\n",
    "    text = ' '.join([ps.stem(word) for word in text.split()])\n",
    "    return text\n",
    "\n",
    "#simple_stemmer(\"My system keeps crashing his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatize_text(text):\n",
    "    text = nlp(text)\n",
    "    text = ' '.join([word.lemma_ if word.lemma_ != '-PRON-' else word.text for word in text])\n",
    "    return text\n",
    "\n",
    "#lemmatize_text(\"My system keeps crashing! his crashed yesterday, ours crashes daily\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.Abstract[:10].apply(lemmatize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stopwords(text, is_lower_case=False):\n",
    "    tokens = tokenizer.tokenize(text)\n",
    "    tokens = [token.strip() for token in tokens]\n",
    "    if is_lower_case:\n",
    "        filtered_tokens = [token for token in tokens if token not in stopword_list]\n",
    "    else:\n",
    "        filtered_tokens = [token for token in tokens if token.lower() not in stopword_list]\n",
    "    filtered_text = ' '.join(filtered_tokens)    \n",
    "    return filtered_text\n",
    "\n",
    "#remove_stopwords(\"The, and, if are stopwords, computer is not\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_corpus(doc, html_stripping=False, accented_char_removal=True, text_lower_case=True, \n",
    "                     text_lemmatization=True, special_char_removal=True, \n",
    "                     stopword_removal=True, remove_digits=True):\n",
    "    #normalized_corpus = []\n",
    "    # normalize each document in the corpus\n",
    "    #for doc in corpus:\n",
    "    # strip HTML\n",
    "    if html_stripping:\n",
    "        doc = strip_html_tags(doc)\n",
    "\n",
    "    # remove accented characters\n",
    "    if accented_char_removal:\n",
    "        doc = remove_accented_chars(doc)\n",
    "\n",
    "    # lowercase the text    \n",
    "    if text_lower_case:\n",
    "        doc = doc.lower()\n",
    "\n",
    "    # remove extra newlines\n",
    "    doc = re.sub(r'[\\r|\\n|\\r\\n]+', ' ',doc)\n",
    "\n",
    "    # lemmatize text\n",
    "    if text_lemmatization:\n",
    "        doc = lemmatize_text(doc)\n",
    "\n",
    "    # remove special characters and\\or digits    \n",
    "    if special_char_removal:\n",
    "        # insert spaces between special characters to isolate them    \n",
    "        special_char_pattern = re.compile(r'([{.(-)!}])')\n",
    "        doc = special_char_pattern.sub(\" \\\\1 \", doc)\n",
    "        doc = remove_special_characters(doc, remove_digits=remove_digits)  \n",
    "\n",
    "    # remove extra whitespace\n",
    "    doc = re.sub(' +', ' ', doc)\n",
    "\n",
    "    # remove stopwords\n",
    "    # http://www.cs.cornell.edu/~xanda/stopwords2017.pdf\n",
    "    if stopword_removal:\n",
    "        doc = remove_stopwords(doc, is_lower_case=text_lower_case)\n",
    "\n",
    "    #normalized_corpus.append(doc)\n",
    "    return doc\n",
    "    #return normalized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [],
   "source": [
    "#html_stripping=False, \n",
    "#accented_char_removal=True, text_lower_case=True,text_lemmatization=False, special_char_removal=True, stopword_removal=False, remove_digits=True))\n",
    "#df['AbstractClean']=df.Abstract.apply(normalize_corpus, args=(False, True, True, True, True, True, True))\n",
    "#    True, True, True,True,True, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['PaperTextClean']=df.PaperText.apply(normalize_corpus, args=(False, True, True, True, True, True, True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Id</th>\n",
       "      <th>Title</th>\n",
       "      <th>EventType</th>\n",
       "      <th>PdfName</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>PaperText</th>\n",
       "      <th>AbstractClean</th>\n",
       "      <th>PaperTextClean</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>5677</td>\n",
       "      <td>Double or Nothing: Multiplicative Incentive Me...</td>\n",
       "      <td>Poster</td>\n",
       "      <td>5677-double-or-nothing-multiplicative-incentiv...</td>\n",
       "      <td>Crowdsourcing has gained immense popularity in...</td>\n",
       "      <td>Double or Nothing: Multiplicative\\nIncentive M...</td>\n",
       "      <td>crowdsourcing gained immense popularity machin...</td>\n",
       "      <td>double nothing multiplicative incentive mechan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>5941</td>\n",
       "      <td>Learning with Symmetric Label Noise: The Impor...</td>\n",
       "      <td>Spotlight</td>\n",
       "      <td>5941-learning-with-symmetric-label-noise-the-i...</td>\n",
       "      <td>Convex potential minimisation is the de facto ...</td>\n",
       "      <td>Learning with Symmetric Label Noise: The\\nImpo...</td>\n",
       "      <td>convex potential minimisation de facto approac...</td>\n",
       "      <td>learning symmetric label noise importance unhi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0    Id                                              Title  \\\n",
       "0           0  5677  Double or Nothing: Multiplicative Incentive Me...   \n",
       "1           1  5941  Learning with Symmetric Label Noise: The Impor...   \n",
       "\n",
       "   EventType                                            PdfName  \\\n",
       "0     Poster  5677-double-or-nothing-multiplicative-incentiv...   \n",
       "1  Spotlight  5941-learning-with-symmetric-label-noise-the-i...   \n",
       "\n",
       "                                            Abstract  \\\n",
       "0  Crowdsourcing has gained immense popularity in...   \n",
       "1  Convex potential minimisation is the de facto ...   \n",
       "\n",
       "                                           PaperText  \\\n",
       "0  Double or Nothing: Multiplicative\\nIncentive M...   \n",
       "1  Learning with Symmetric Label Noise: The\\nImpo...   \n",
       "\n",
       "                                       AbstractClean  \\\n",
       "0  crowdsourcing gained immense popularity machin...   \n",
       "1  convex potential minimisation de facto approac...   \n",
       "\n",
       "                                      PaperTextClean  \n",
       "0  double nothing multiplicative incentive mechan...  \n",
       "1  learning symmetric label noise importance unhi...  "
      ]
     },
     "execution_count": 321,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref: https://www.kdnuggets.com/2018/05/implementing-deep-learning-methods-feature-engineering-text-data-fasttext.html\n",
    "# ref: https://radimrehurek.com/gensim/models/fasttext.html\n",
    "from gensim.models.fasttext import FastText\n",
    "import nltk\n",
    "wpt = nltk.WordPunctTokenizer()\n",
    "#tokenized_corpus = [wpt.tokenize(document) for document in norm_bible[:1000]]\n",
    "tokenized_corpus = [wpt.tokenize(document) for document in list(df.AbstractClean)]#[:10])]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenized_corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set values for various parameters\n",
    "feature_size = 100    # Word vector dimensionality  \n",
    "window_context = 50   # Context window size                                                                                    \n",
    "min_word_count = 5    # Minimum word count                        \n",
    "sample = 1e-3         # Downsample setting for frequent words\n",
    "mode=1               # sg decides whether to use the skip-gram model (1) or CBOW (0)\n",
    "ft_model = FastText(tokenized_corpus, size=feature_size, window=window_context, \n",
    "                    min_count=min_word_count,sample=sample, sg=mode, iter=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.7/site-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
      "  if np.issubdtype(vec.dtype, np.int):\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'crowdsourcing': ['loss',\n",
       "  'learning',\n",
       "  'algorithmic',\n",
       "  'stability',\n",
       "  'logarithmic',\n",
       "  'clustering',\n",
       "  'propose',\n",
       "  'mechanism',\n",
       "  'data',\n",
       "  'convex'],\n",
       " 'classification': ['clustering',\n",
       "  'number',\n",
       "  'problem',\n",
       "  'propose',\n",
       "  'logarithmic',\n",
       "  'mechanism',\n",
       "  'loss',\n",
       "  'data',\n",
       "  'size',\n",
       "  'learning'],\n",
       " 'regularised': ['propose',\n",
       "  'large',\n",
       "  'number',\n",
       "  'problem',\n",
       "  'logarithmic',\n",
       "  'loss',\n",
       "  'size',\n",
       "  'learning',\n",
       "  'data',\n",
       "  'show'],\n",
       " 'experiments': ['number',\n",
       "  'clustering',\n",
       "  'learning',\n",
       "  'large',\n",
       "  'problem',\n",
       "  'approach',\n",
       "  'algorithmic',\n",
       "  'mechanism',\n",
       "  'show',\n",
       "  'stability']}"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# view similar words based on gensim's FastText model\n",
    "similar_words = {search_term: [item[0] for item in ft_model.wv.most_similar([search_term], topn=10)]\n",
    "                  for search_term in ['crowdsourcing','classification','regularised','experiments']}\n",
    "similar_words    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAxsAAAJPCAYAAAAUtsmcAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4wLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvqOYd8AAAIABJREFUeJzs3Xl4VNXB+PHvmUmAECBsKosIYgCRAApRqZTFhRdcqqK4URW3utS1Wt+iLQou7WtFtFp/vmJtq9YVtC1aUeuKWrEECgp1ISCtIlSI7BBCMuf3R2BeoLg1uUbg+3mePM3cOXPvmdEH+fbOuTfEGJEkSZKk2paq6wlIkiRJ2jEZG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEpFT1xP4T7Rs2TJ26NChrqchSZKkHdj06dOXxhh3qet5bM+2y9jo0KEDJSUldT0NSZIk7cBCCP+o6zls7/walSRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGxnbgobcfosudXUhfl6bLnV146O2H6npKkiRJ0hfKqesJ6PM99PZDXP7C5Qw7ZBjntTmP+R/P5/IXLgdgePfhdTw7SZIk6bPVypmNEMKQEMJ7IYTSEMLIbTxfP4Tw6Mbn3wwhdNi4vUMIYV0IYebGn/+tjfnsSMZMGcOwQ4bRqV0n0uk0ndp1YtghwxgzZUxdT02SJEn6XDWOjRBCGrgTOBzYBzglhLDPVsPOBpbFGAuBW4GbNntuXoxx340/59d0Pjua0rJSOrbpuMW2jm06UlpWWkczkiRJkr6c2jizcQBQGmOcH2OsAB4BjtlqzDHAfRt/nwgcGkIItXDsHV5hi0Lmfzx/i23zP55PYYvCOpqRJEmS9OXURmy0BT7c7PFHG7dtc0yMsRJYAbTY+NyeIYS/hRBeCSH0q4X57FCu7X8tE1+cyNwP51JVVcXcD+cy8cWJXNv/2rqemiRJkvS56nqB+CJgjxhjWQihN/CHEEK3GOPKrQeGEM4FzgXYY489vuZp1p1Ni8DHTBlDaVkphS0KGXfoOBeHS5Ik6RuvNmJjIdBus8e7b9y2rTEfhRBygAKgLMYYgfUAMcbpIYR5QGegZOuDxBjHA+MBiouLYy3Me7sxvPtw40KSJEnbndr4GtU0oFMIYc8QQj3gZGDSVmMmASM2/j4MeDHGGEMIu2xcYE4IoSPQCZiPJEmSpO1ejc9sxBgrQwgXAc8CaeDXMcY5IYTrgJIY4yTgXuCBEEIp8CnVQQLQH7guhLAByADnxxg/remcJEmSJNW9UP1Npu1LcXFxLCn5t29aSZIkSbUmhDA9xlhc1/PYntXKTf0kSZIkaWvGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUpErcRGCGFICOG9EEJpCGHkNp6vH0J4dOPzb4YQOmz1/B4hhNUhhB/WxnwkSZIk1b0ax0YIIQ3cCRwO7AOcEkLYZ6thZwPLYoyFwK3ATVs9Pw6YXNO5SJIkSfrmqI0zGwcApTHG+THGCuAR4JitxhwD3Lfx94nAoSGEABBCOBb4AJhTC3ORJEmS9A1RG7HRFvhws8cfbdy2zTExxkpgBdAihNAI+BEwphbmIUmSJOkbpK4XiI8Gbo0xrv6igSGEc0MIJSGEkiVLliQ/M0mSJEk1klML+1gItNvs8e4bt21rzEchhBygACgDDgSGhRB+DjQFMiGE8hjjL7c+SIxxPDAeoLi4ONbCvCVJkiQlqDZiYxrQKYSwJ9VRcTIwfKsxk4ARwBvAMODFGGME+m0aEEIYDazeVmhIkiRJ2v7UODZijJUhhIuAZ4E08OsY45wQwnVASYxxEnAv8EAIoRT4lOogkSRJkrQDC9UnGLYvxcXFsaSkpK6nIUmSpB1YCGF6jLG4ruexPavrBeKSJEmSdlDGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUpErcRGCGFICOG9EEJpCGHkNp6vH0J4dOPzb4YQOmzcfkAIYebGn1khhKG1MR9JkiRJda/GsRFCSAN3AocD+wCnhBD22WrY2cCyGGMhcCtw08bts4HiGOO+wBDg7hBCTk3nJEmSJKnu1caZjQOA0hjj/BhjBfAIcMxWY44B7tv4+0Tg0BBCiDGujTFWbtzeAIi1MB9JkiRJ3wC1ERttgQ83e/zRxm3bHLMxLlYALQBCCAeGEOYAbwPnbxYfkiRJkrZjdb5APMb4ZoyxG7A/cFUIocG2xoUQzg0hlIQQSpYsWfL1TlKSJEnSV1YbsbEQaLfZ4903btvmmI1rMgqAss0HxBjfAVYDRds6SIxxfIyxOMZYvMsuu9TCtCVJkiQlqTZiYxrQKYSwZwihHnAyMGmrMZOAERt/Hwa8GGOMG1+TAxBCaA/sDSyohTlJkiRJqmM1vvJTjLEyhHAR8CyQBn4dY5wTQrgOKIkxTgLuBR4IIZQCn1IdJADfBkaGEDYAGeD7McalNZ2TJEmSpLoXYtz+LgBVXFwcS0pK6noakiRJ2oGFEKbHGIvreh7bszpfIC5JkiRpx2RsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmStumhtx+iy51dSF+XpsudXXjo7YfqekraztRKbIQQhoQQ3gshlIYQRm7j+fohhEc3Pv9mCKHDxu2DQgjTQwhvb/zfQ2pjPpIkSaqZh95+iMtfuJxB/QZx8/dvZlC/QVz+wuUGh76SGsdGCCEN3AkcDuwDnBJC2GerYWcDy2KMhcCtwE0bty8FvhNj7A6MAB6o6XwkSZJUc2OmjGHYIcPo1K4T6XSaTu06MeyQYYyZMqaup6btSG2c2TgAKI0xzo8xVgCPAMdsNeYY4L6Nv08EDg0hhBjj32KMH2/cPgfICyHUr4U5SZIkqQZKy0rp2KbjFts6tulIaVlpHc1I26PaiI22wIebPf5o47ZtjokxVgIrgBZbjTkemBFjXF8Lc5IkSVINFLYoZP7H87fYNv/j+RS2KKyjGWl79I1YIB5C6Eb1V6vO+5wx54YQSkIIJUuWLPn6JidJkrQTurb/tUx8cSJzP5xLVVUVcz+cy8QXJ3Jt/2vremrajuTUwj4WAu02e7z7xm3bGvNRCCEHKADKAEIIuwO/B06PMc77rIPEGMcD4wGKi4tjLcxbkiRJn2F49+FA9dqN0rJSClsUMu7Qcdnt0pdRG7ExDegUQtiT6qg4Gdj638JJVC8AfwMYBrwYY4whhKbAn4CRMcbXa2EukiRJqiXDuw83LlQjNf4a1cY1GBcBzwLvAI/FGOeEEK4LIRy9cdi9QIsQQilwObDp8rgXAYXANSGEmRt/dq3pnCRJkiTVvRDj9veNpOLi4lhSUlLX05AkSdIOLIQwPcZYXNfz2J59IxaIS5IkSdrxGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJEmSpEQYG5IkSZISYWxIkiRJSoSxIUmSJCkRxoYkSZKkRBgbkiRJkhJhbEiSJElKhLEhSZIkKRHGhiRJkqREGBuSJEmSEmFsSJIkSUqEsSFJkiQpEcaGJO3EcnJyGDNmTF1PQ5K0gzI2JEn/kdWrV9f1FCRJ33DGhiRtByZMmEAIgaZNm5JKpcjNzWXhwoVbnJmYOnUqIQQA+vfvT4MGDcjNzSWEwH777UdRURGpVIp0Os306dOz+/7lL39JKpUilUoxatQoAD744AMKCgpIp9OkUimGDRuW3W/9+vXJzc2ladOmX/OnIEna3hgbkrQdueqqq8hkMuTm5nL66ad/7tj169czZ84cXnvtNWbOnEleXh6ZTIYWLVpwxhlnZMdt2LCBTCbDxRdfzI033ghAv379KC4upqqqipkzZ/L444/zwQcfAFBRUcHUqVOprKxM7H1KknYMxoYkbUd+9KMfAdCuXTsWLFjwuWMLCgro3Lkzffv2BcieAencuTOLFy/Ojjv55JMB+MUvfkGMkbfeeotFixbx0ksvkUql2HfffQF45plnAGjcuDG9e/eu1fclSdoxGRuStJ3Y9BUpgFQqRVVVFSGE7BmGpUuXbjE+nU5v8bh58+bZ12YymS32tblUKkWMkbvvvptMJkMmkyHGyAUXXABAbm5u7b0pSdIOzdiQpO1Yw4YNmTx5MlD9Fav/xMMPPwzA5ZdfTgiBoqIi2rRpw8iRI6mqqgLgZz/7We1MWJK0U8mp6wlIkv5zP//5z7ngggtIpVK0bdv2P9pHTk5O9uzGj3/8YwDefPNNioqKsmcxcnNz/+OYkSTtvEKMsa7n8JUVFxfHkpKSup6GJEmSdmAhhOkxxuK6nsf2zK9RSZIkSUqEsSFJkiQpEcaGJEmSpEQYG5K0kxo4cCCuf5MkJcnYkKTtiHftliRtT4wNSUrQscceS+/evenWrRvjx48HoFGjRvzgBz+gW7duHHrooSxZsgSoPtNw6aWXUq9ePerXr89f//pXAEaPHs1pp51G3759Oe200ygvL+fMM8+ke/fu7Lfffrz00ksATJ48mRACrVu3plevXvzlL3/JzmPPPfckJyeHnj17MnLkyOz2CRMmcMABBxBC4Le//e3X9KlIknYWxoYkJejXv/4106dPp6SkhNtvv52ysjLWrFlDcXExc+bMYcCAAYwZMyY7fu3atbRp04ZWrVpx1llnZbf//e9/5/nnn+fhhx/mtttuI4TA22+/zcMPP8yIESMoLy+nrKwMgPPPP59HH32USy65BKiOkLKyMpo0acKsWbP47//+7+x+KyoqeO211/jTn/7E7373u6/pU5Ek7Sy8z4YkJWj06NH8/ve/B2DBggU8++yz9O3bl/Xr15OTk8P8+fPp0aMHa9euJcZITk4OlZWVhBDY9OfzgQceyJtvvkmLFi0oKytj1113Za+99uKNN97IHuf888/nt7/9LeXl5Vscv3nz5nz66acAhBDIZDJcf/31XHPNNdkx3/nOd3jyySdJp9Pk5ub+2z5CCOTk5HDZZZcxduxYAHbddVc++eQTMplM7X9okvQN4X02as4zG5KUkJdffpnnn3+eN954g1mzZrHffvv921/k77vvPtasWcNf/vIXBgwYwBlnnAFA06ZNadeuHQBvvfUWAPn5+QAcdNBBvPHGG7Rt25YYI/Xq1eOhhx7iqKOOAqBJkyZs2LABgE8//ZTLLruMvfbaixgjl156KTfeeCMA7dq14+c//zlPPvkkADFG1q9fD8Dhhx8OQCqV4uCDDyaVSnHzzTdz5ZVXkslksncclyTp8/hfC0lKyIoVK2jWrBkNGzbk3XffZerUqQBkMhkmTpwIwPjx48nPz6dPnz5A9dkPgMaNG1NQUACQDZTzzjsPgMLCQgA+/vhj9txzT+rVq8fKlStZu3YtAKeccgoPPPBAdh633XYb8+bNA6CkpCQbFB9++OEWX6mC6jMWAH/4wx8A6NixIwsWLKBZs2YA3HTTTQBcccUVNf+AJEk7PGNDkhIyZMgQKisr6dq1KyNHjswGRX5+Pn/9618pKipi9erVNG7cOPuaevXqAbB48WLuvfdeQgjZ5+rXrw/AySefDEDbtm1ZvHgxq1evBmDw4MEATJw4kXfffTf72rfffpsOHTqQSqVYs2ZNdn8DBgxg2rRpbP512nQ6TQghO4+cnByqqqq2mIckSV+WsSFJCalfvz6TJ0/mnXfe4Q9/+AMvv/wyAwcOBGDcuHHMnj2bn/70pyxevDh75ak999wTqL5i1QEHHECMMRsZ/+///T8AevfuDcBxxx3HunXrSKVSpNPpbMxUVVVx00030bVrVwDy8vJo164d+fn53H777dn9vfzyyxQXF2fPVuyyyy6f+V42xcePf/xjAG699dba+ZAkSTs0F4hL0tesUaNG2bMRUH2G4dVXXyXGSG5uLhs2bMguEN+0YByqY2DJkiXEGGnZsmX26lMADz74IMOHD9/iDEQIgZYtW7J06dLs2YsHHniABQsWMGrUqOwxmjZtyvLly9ltt91Ip9MsWrSITCZDCIG9996bdevWAbB69ersYvMWLVrw6aefUlVVlfjnJUl1xQXiNZdT1xOQpJ3N5qEB8Morr2R/nzBhAieddNI2r/IUQshegWrp0qXb3PeX/T+Qrr/+eqZNm0aPHj0+c8zW+5o3bx577bUXAJ07d/5Sx5Ek7dyMDUnaCW1aJP5VXHTRRTz77LMA5Obm8uKLL9b2tCRJO5haWbMRQhgSQngvhFAaQhi5jefrhxAe3fj8myGEDhu3twghvBRCWB1C+GVtzEWSkvZlFktPmDCBEAJNmjQhhEB+fj7f+973sguwR40axQcffEBBQQHpdJpUKsWwYcM44YQTWLNmDbm5uYQQSKVS7Lvvvtn9nnTSSaRSKVKpFHfffTcAo0aNyu4jnU5zzz33ANC/f38aNGhAvXr1sncW3/w9TJ06lQ8++ID69etn97npkrchBNq2bZvd5w033MALL7xAjJHevXuzfv16+vbtW5sfqyRpB1Tj2AghpIE7gcOBfYBTQgj7bDXsbGBZjLEQuBW4aeP2cmAU8MOazkOSvolGjx7N+vXrWbduHY899hgVFRUcf/zx3HzzzfTt25fi4mKqqqqYOXMmjz/+OB988AH9+vUjJyeHVatWkclkuPfee7P7a9asGZlMhv322y972drhw4ezYsUKMpkMZ511VvbO4VB9BmPGjBksWrSIxYsXM2nSpC3md9lll5GXl0cmkyGTyXDzzTdnn2vdujWZTIYWLVpwzTXXMHv2bF577TVcMydJ+rJq48zGAUBpjHF+jLECeAQ4ZqsxxwD3bfx9InBoCCHEGNfEGF+jOjokabuz6667EkIghJC9LwbAiSeeCFTfj6JLly7k5+ez//77k5OTw5NPPsn69etZtGgRL774IiEEevbsCcDFF1/MnDlzyM3NpWXLlgD06dOHvLw8AGbNmkXv3r0ZMmQIa9asoUGDBuyzzz40btyYEAK/+tWvtrhxYEFBAUVFRbRq1Yrc3FxefvnlLeZ/9NFHs2LFCtq0acNll11GUVFR9rnrrrsOqF6f0aRJEzp37pw9m7HpRoOSJH2e2oiNtsCHmz3+aOO2bY6JMVYCK4AWtXBsSaozgwcPZvny5WzYsIF169axatUqhg0bBpC92tPcuXNZsGABlZWV2WBo3bp1NlAA2rRpQ4yRdu3a8dxzz23zWBUVFQCMGDGCGTNmUK9ePaqqqqioqCA/P5899tgD+L9L526STqezv4cQsvvZ5Oyzz6akpISuXbvyy1/+covXN2/eHCD7VarNbbqBoCRJn2e7uc9GCOHcEEJJCKFkyZIldT0dSeK1115jw4YN5ObmkpeXR4yRmTNnAjB27FhijHTq1Akge/lagDFjxgDVkQFw4403AtCyZUsqKyspKipi1apV2atBxRiz98w4//zzt5hDYWEhlZWV7LvvvqRSKT766KOv9B6effZZ2rZtywsvvMCwYcNYtGjRV/0YJEn6TLURGwuBdps93n3jtm2OCSHkAAVAGV9BjHF8jLE4xlj8eTeekqSvy9q1a2nfvj0xxuxPaWkpQ4cOzd6bYvNg2KRhw4YAvPnmmwCceeaZpFIpZs2aRYyRl156iVQqRUVFBalUiqqqquyN+Lbl0ksvZdKkSdu8XO4Xefjhh2nTpg2pVIoJEyZw1VVXfeV9SJL0WWp8U7+N8fA+cCjVUTENGB5jnLPZmAuB7jHG80MIJwPHxRhP3Oz5M4DiGONFX+aY3tRPUl3adDO8TV+DmjVrFj169OD++++noKCAm266ialTp5LJZBgzZgyjR4/m6KOP5vHHHyc3N3eL8AghMHnyZIYMGcK5557LPffcQ4yRLl268I9//IPy8nJyc3Pp0aMH06dP3+L4vXv35m9/+xtr167l6aef5vjjj6dXr17ZcZKkmvGmfjVX4/tsxBgrQwgXAc8CaeDXMcY5IYTrgJIY4yTgXuCBEEIp8Clw8qbXhxAWAE2AeiGEY4H/ijH+vabzkqSvQ+vWrbOLuwFycnI477zzmDp16haXyH3qqaeyZzLq1atHvXr12H333bPPv/POOzz44IMA5Ofn06hRoy889uuvv05BQQF5eXnZNSCe+ZUkfZPUypqNGOPTMcbOMca9Yow3btx2zcbQIMZYHmM8IcZYGGM8IMY4f7PXdogxNo8xNoox7m5oSPqm2/zMxMcff8y6dev48MMPiTEye/Zs7r77biorK3n11VcBuOeee6iqqiIvL490Os0777zDJ598wqJFi+jevTtDhgzh8MMP5+abbybGyPPPP8/y5cuzV5XasGHDFmcrNh2/QYMGTJs2jRgjzz77LDFGzjnnnK/xk5Ak6fPV+GtUdcGvUUn6Jtj0daa1a9fSp08f5s6dC0B5eTmzZs1i5cqVHHzwwWzYsAGAq666iscee4x58+YBcPzxxzN37lzeeustUqnUFusyKioqWLhwIa1atfrCOWzSuXNn3nvvvdp+m5K00/JrVDVX469RSdLO7pIDtpWtAAAgAElEQVRLLmH58uWUlZXRsGFDcnJyWLlyJcC/XTL28yxatIimTZt+pWNvj/+HkSRp57HdXPpWkr6pPv30U5o2bUrDhg0ZN24cVVVV2xx3/PHH849//IMPPviA8vJyXnjhhexze+yxB9/97nezjx999NHE5y1JUtI8syFJNfSzn/2M4uJiGjRoQLt27ahXr942xxUXF3PyySfTpUsX6tWrx2677Ubjxo2B6vtdDBo0iLy8PDKZDHvttRcnnXTS1/k2JEmqdZ7ZkKT/0KavMHXp0oVVq1ZRXl7O3Llzueeee/j+97/PhRdeyAknnMCCBQs45JBD6NGjBwsWLKC0tJSlS5fy8ccfU15ezkEHHcThhx/OuHHjWLduHUOHDuXmm2/OHueMM85g4sSJVFVVceWVV7L//vvTo0cP7r77bgB+//vfc+ihhxJjZNGiRXTu3JnFixfXyWciSdLmjA1JqkVz5szhhhtu4MUXX2TWrFn84he/4OKLL2bEiBG89dZbfPTRR+y5557ZS9Z26NCB1157jaeeeoqRI0cCcNJJJ/HYY48B1QvFX3jhBY488kjuvfdeCgoKmDZtGtOmTeOee+7hgw8+YOjQobRu3Zo777yT733ve4wZM+YLF5ZLkvR18GtUklSLXnzxRU444QRatmwJQPPmzXnjjTd44oknAJg7dy6tW7dm6dKlnHHGGQwaNIhUKsU+++zDv/71LwAOP/xwLr30UtavX88zzzxD//79ycvL47nnnuOtt95i4sSJAKxYsYK5c+ey5557cscdd1BUVESfPn045ZRT6ubNS5K0FWNDkv4DOTk5zJkzhy5dunzp13Tp0oWf/exnW2zb/HK3m98/Y+DAgTz77LM8+uijnHzyydnn77jjDgYPHvxv+/7oo49IpVL861//IpPJkEp54lqSVPf8r5Ek1aJDDjmECRMmUFZWBlRfqeqggw7ikUce4b333mPlypX069fvC/dz0kkn8Zvf/IZXX32VIUOGADB48GDuuuuu7H073n//fdasWUNlZSVnnXUWDz/8MF27dmXcuHHJvUFJkr4Cz2xI+toNHDiQsWPHUlz89d4n6ZprrqF///4cdthhX+l1n3zyCUVFRaxatYoYI+eddx4A5557LtOmTSOTyfDEE09wxBFH0KBBAz755BN22WUXYoyEEMjNzeXJJ5/k9NNPp0uXLrz33nvk5FT/8XvfffcRQiCTybBhwwaaNm1KRUUFDRs2pKKiguOPPz57datzzjmH999/n169ehFjZJddduEPf/gDt9xyC/369ePb3/42PXv2ZP/99+fII4+ka9eutfsBSpL0FXlmQ9KXUllZWddT+FI+b57XXXfdVw4NgJtvvpnmzZuzbt06KisrGTp0KAC77LILa9eu5dhjj+UHP/gBAEOHDmW//fbjiiuuoGXLltSvX5/169dTWFhI/fr1GTx4MA0bNqSwsJATTzwRgKOOOooRI0YA1eswQgiUlZWxatUqxowZQwiBNm3akJOTw+zZszn11FN55513eOWVV9htt904+uijGTduHDk5OXTs2JH333+fffbZJ3vp3OnTp9OgQQNSqRTpdJpbbrkFgIsvvphUKpX9ef/99wHo2rUr6XSaVCpF+/btv/LnJUnSJsaGpKz777+fHj160LNnT0477TTOOOMMzj//fA488ED++7//m08//ZRjjz2WHj160KdPH9566y0AunfvzvLly4kx0qJFC+6//34ATj/9dP785z+zbt06Tj75ZLp27crQoUNZt24dAFVVVZxxxhkUFRXRvXt3br31VgBmzpxJnz596NGjB0OHDmXZsmVA9RmRkpISAJYuXUqHDh0A+O1vf8vRRx/NIYccwqGHHgrATTfdRPfu3enZs2f2Kk+bLiEL0KFDB6699lp69epF9+7deffddwFYsmQJgwYNolu3bpxzzjm0b9+eAw44gNLSUg488EAymQytW7cGyO530KBBLFmyBIDS0lKuvfZaxo4dy7JlyygvL+f6669n0KBBbNiwgalTp3LiiSfy0Ucf8Y9//IMQApMmTWLixIlUVFQAsH79+uw/k03rM5o0aUImk+GZZ57hqquu4vvf/z69e/cmxsigQYPo379/9uxIJpMByF7RavDgwbRu3ZpMJsP3vvc9rrzySgDGjx/P5ZdfTiaTYe7cubRp04azzjqLRYsW0ahRI8aNG8fixYu59NJLa/zvliRpJxVj3O5+evfuHSXVrtmzZ8dOnTrFJUuWxBhjLCsriyNGjIhHHnlkrKysjDHGeNFFF8XRo0fHGGN84YUXYs+ePWOMMZ533nnxqaeeim+//XYsLi6O55xzTowxxsLCwrh69ep4yy23xDPPPDPGGOOsWbNiOp2O06ZNiyUlJfGwww7LzmHZsmUxxhi7d+8eX3755RhjjKNGjYqXXnppjDHGAQMGxGnTpsUYY1yyZEls3759jDHG3/zmN7Ft27axrKwsxhjj008/Hb/1rW/FNWvWZN9LjDGOGDEiTpgwIcYYY/v27ePtt98eY4zxzjvvjGeffXaMMcYLL7ww/vSnP40xxtisWbMIxHr16sVjjjkmnn/++RGIBx54YEyn0/HAAw+Mubm5sX79+jGEEI888siYl5cXR40alX0dEPPz82OvXr0iENPpdKxXr15Mp9MRiI0bN46XX355BLI/ZWVlMZ1Ox1atWmW3XXXVVTHGGIuLi7OvS6fT8YgjjtjitZvex6bHs2bNys6lQYMG2ff097//PXbq1CmmUqnYo0eP+OSTT8YYY9xtt90iEEMIMYQQgXjQQQfV4N8sSdp+ASXxG/B33+35xzMbkoBtX7IV4IQTTiCdTgPw2muvcdpppwHVC6HLysqyC56nTJnClClTuOCCC3j77bdZuHAhzZo1Iz8/nylTpnDqqacC0KNHD3r06AFAx44dmT9/PhdffDHPPPMMTZo0YcWKFSxfvpwBAwYAMGLECKZMmfKF8x80aFB2zs8//zxnnnkmDRs23OK9bO24444DoHfv3ixYsCD7Hjdd/WnatGk0a9aMRx55hMmTJ3P55ZcTQmDevHnEGJk5cyaffPIJN910E9X/Tar+Gtf1118PwOjRo0mlUqxdu5YZM2YA1WdzLrzwwuzZh1WrVnH77bdvMa/evXtTVVW1xY35fve735GTk8Pf/vY3ANq2bUuzZs14+umnt3jtvffey8KFC7OPe/bsCcBhhx3GunXryMvLA6CoqIi5c+fStWtX5syZw3e+8x3S6TRVVVXsv//+pFIprr32WmKMFBYWZr9qlZub+4X/LCRJ2sTYkPS58vPzv3BM//79efXVV3n11VcZOHAgu+yyCxMnTvzCqy41a9aMWbNmMXDgQP73f/+Xc84553PH5+TkZP+SXl5e/pXnubVNl51Np9PbXOtx9tlns2zZMk444QQqKiro1q0bMUZ++MMfEmOke/fuNG3alGbNmmUvNdusWbPs66+++moymQwxRu65557s9l/96lfZONl87i1atADgn//8Z3ZeIQQAli9fvsXcBg8enA2Hli1bZoMwNzeXtm3bZsf95Cc/AWDy5MkArFy5Eqi+StZJJ53EnDlzOOWUU2jQoAEADRs2ZPr06dnXjx07lvvvv5+HH36YTCbD1KlTv/BzlSRpE2NDErDtS7ZurV+/fjz44IMAvPzyy7Rs2ZImTZrQrl07li5dyty5c+nYsSPf/va3GTt2LP379weqY+Shhx4CYPbs2dm1HkuXLiWTyXD88cdzww03MGPGDAoKCmjWrBmvvvoqAA888ED2LEeHDh2yfxHetPZiWwYNGsRvfvMb1q5d+5nv5bP07duXxx57jNtuu41p06YBsHjxYgoKCvj5z39OOp3m2GOP5ZhjjsmeObnuuuvIZDL86U9/yv5lHtjiXhf/9V//lb2q1KpVq4Dq+2k0bdo0+3jTZ78pMKqqqrJRsimydtttN7p06cIdd9zBhx9+CMCf//zn7HFCCNnjHnDAAUB1zMQYSaVSrF69mubNm1NQUMBzzz0HVJ81SaVStG7dmiZNmtCtWzeqqqoYPXo0V155JfXq1csuNu/du/eX/iwlSTI2JAHQrVs3fvzjHzNgwAB69uzJ5Zdf/m9jRo8ezfTp0+nRowcjR47kvvvuyz534IEH0rlzZ6A6ShYuXMi3v/1tAC644AJWr15N165dueaaa7J/YV24cCEDBw5k33335dRTT83e8O6+++7jyiuvpEePHsycOZNrrrkGgB/+8Ifcdddd7LfffixduvQz38uQIUM4+uijKS4uZt9992Xs2LFf+nO49tpree6557jxxhvJZDK0atWK119/nRUrVmwx7thjj2XatGlcffXVzJs3j5ycHAYMGEB5efkWsbDpErdHH3109kxEq1ataNmyJfXq1cv+xR7+L06qqqpIpVK8++67tG/fnhYtWmT3k5ubS2FhIVVVVdkrRe27777ZebVv3z4bJoMHD2b48OGsXbuWVCpFJpOhTZs27LrrrsD/RViMkTVr1pCTk0NlZSVvvfUW6XSa0aNHc+KJJ2aPLUnSV1bXi0b+kx8XiEtKSnl5edywYUNcsWJFLCgoiCGE2KpVq1hQUBBvvfXWmE6n47vvvhtjrF6wzsbF1G3atImnnXZa3HXXXWObNm22WLQNxIKCgpifnx+B2KdPn3jkkUdGIO6xxx4xlUr92/h0Oh2fe+65GEKILVq0iAUFBTGdTsf27dvHI488MsZYvci9+o/xmF2M3qlTpxhjjEAcNWpUjDHGgQMHRiA2aNAghhDi3nvvnX2/m16/aX+bnkun03H06NHxtddei0B85JFHYowxlpSUJPxPQJK+OXCBeI1/PLMhSZv55z//yf7770+/fv3o1KkTb775JosWLWL58uVcdtllVFZW0qVLFwAeeeQRioqKaN26NcuXL9/iMrVQffndyspKcnJyWLFiBWvXriWdTtOyZUueeOIJmjZtyj//+U9ijOTk5LDbbrvRuHFjdt99d6qqqhgyZAiNGjWiUaNG2TUbZ555Jk899VR2vnvvvTdA9i7jpaWl2QXiRxxxBFB9yeB0Os26devYY489vtLn0bdvX0499VROOeUUUqkUffr0+U8/WknSTihUR9v2pbi4OG661r4k1ZUOHTqwcOFCKisr6d+/P/fccw9dunRh77335t133+WVV16hZ8+etGzZkry8PFauXEnLli3p2rUrr776KvPmzaOwsJC77rqLCy64gHQ6TcOGDbdY9yFJqjshhOkxxuK6nsf2zNiQpBoqLCxk3rx5pNNp6tevzx577EF+fj7Tp08nlUrRrFkzKioqWLlyJT/84Q+55ZZbsus6Nv8zuEWLFtlxkqS6Z2zUnLEhSZIkbYOxUXOu2ZC0Qxs6dOjnXrlqk5ycHN57771/2z58+HDOPfdcoPqysldccQUAXbp0YdKkSUD1ZW0lSdK/83qGknZoTz75JGVlZdk7o39Vm+4PsrXNw2Tz+1xIkqT/45kNSTuMTz75hF133ZW8vDwaNGjAwQcfTFVVFT179sze2btbt27k5+fToEGD7M0CNznttNNo0KABjRo14oUXXgCqr+R01FFHbTFu030wQgjZtRd5eXm0atUquy2VSnHZZZfRp08fcnJySKVSpFIpunfv/jV8EpIkfTMYG5J2GDfffDPNmzdn3bp1lJeXc99995FOp5k1axbLli0DYNKkSaxZs4aVK1cya9asLe5EXlBQQHl5OcOHD2f48OGfeZzjjjuOGCPjx4/npZdeyu63efPmtGnThry8PNasWcO5556bvQt5JpMhk8lk78AuSdLOwNiQtMM47LDDKC0t5cADD+SXv/zlNu8pMWrUKBo2bEhBQQErV65kypQp2ed+/OMfA3DbbbexZMmSzzzOG2+8kb3y1MCBAwEYP348gwYN4uOPP6a8vJyzzjqLJ554ghYtWlBVVUXLli0ZMWJE9r4YkiTtDIwNSTuMwYMH895779GrVy9+8pOfcMghh2zx/JQpU5gwYQJz5sxh3bp1dOzYkbVr12afT6Vq9kfiL37xC5555hl23XVXHnnkEW644QYuvPBCSktL6du3L48++ii77LJLjY4hSdL2xNiQtMOYMWMGLVq04K677uKSSy7hnXfeIScnh3/9618ALF68mJycHNq1a8fs2bOZP3/+Fq//6U9/CsAVV1zxuVFw0EEHUVVVxfr163n99dcBOOOMM3j88cfp378/paWlAKxfv56DDz6YiooK/vjHP/I///M/rFq1Kom3LknSN5JXo5K0w5g8eTI33HADUH2W4q677mLSpEkcdthh5Ofns2zZMq6++moaNmxIo0aNaNWq1RavX7ZsGXl5eaRSqexlbbfl8ccfJzc3l3PPPZcQAk2aNOG4444jhEBFRUV2XGFhIVOnTmXkyJHZbd/97ndr+V1LkvTN5U39JKmWVVZW0rhxYyZNmsSgQYPqejqSpP+QN/WrOb9GJUm1aNKkSeTl5dGtWzdDQ5K00/NrVJJUi44++mg2bNhQ19OQJOkbwTMbkiTVskaNGn3l1xxxxBEsX768RsddsGABRUVFNdqHJNUmz2xIknZ6MUZijDW+/HFNjv30009/7ceWpKR5ZkOStFNasGABXbp04fTTT6eoqIgHHniAb33rW/Tq1YsTTjiB1atXA/D000+z995707t3by655BKOOuooAEaPHs3YsWOz+ysqKmLBggVbHGP16tUceuih9OrVi+7du/PHP/5xm8f+8MMP6dChA0uXLmXNmjUceeSR9OzZk6KiIh599FEApk+fzoABA+jduzeDBw9m0aJF2e09e/akZ8+e3HnnnUl/bJL0lRgbkqSd1ty5c/n+97/PK6+8wr333svzzz/PjBkzKC4uZty4cZSXl3PeeecxefJkpk+f/rl3lt+WBg0a8Pvf/54ZM2bw0ksvccUVV7DpKpCbjj1nzhzat2+ffc0zzzxDmzZtmDVrFrNnz2bIkCFs2LCBiy++mIkTJzJ9+nTOOuus7B3vzzzzTO644w5mzZpVex+MJNUSv0YlSdpptW/fnj59+vDUU0/x97//nb59+wJQUVHBt771Ld599106duzInnvuCcApp5zC+PHjv/T+Y4xcffXVTJkyhVQqxcKFC7M3mdx07K11796dK664gh/96EccddRR9OvXj9mzZzN79uzsFc6qqqpo3bo1y5cvZ/ny5fTv3x+A0047jcmTJ9foM5Gk2mRsSJJ2Wvn5+UB1FAwaNIiHH354i+dnzpz5ma/Nyckhk8lkH5eXl//bmAcffJAlS5Ywffp0cnNz6dChQ3bcpmNvrXPnzsyYMYOnn36an/zkJxx66KEMHTqUbt268cYbb2wxtqYLyiUpaX6NSpK00+vTpw+vv/46paWlAKxZs4b333+fLl26MP//t3f/sXHX9x3HX29MbCeO2oQMAmnCwPLFiMhRN44f2ua0CuScklEq4akQahvhqqy4QjQaG1WluqZ00F9pN80gUaLGNvIYMpqaDa9OmtDGnZYVJ2OxQod8O4ZiTFIIIVLc2iHmvT98ts7JBcc+f+97P54PKfJ9v/f5fvM++MTOK9/Pj0Riei7G1PwJSbrmmmt06NAhSdKhQ4f0xhtvnHffU6dO6YorrtCiRYv08ssv680335y1lpGRES1ZskRf+MIX9Mgjj+jQoUOqrq7WO++8Mx02PvjgAx05ckTLli3TsmXL9Ktf/UrSZLgBgFzCkw0AQNG7/PLLtXPnTt1zzz0aHx+XJD3++ONau3atnnrqKW3evFkVFRW68cYbp6+566671NnZqXXr1unmm2/W2rVrz7vvvffeqzvuuEM1NTWKRqO67rrrZq1lcHBQjzzyiC655BItWrRITz/9tEpLS9XT06OHHnpIp06d0tmzZ/Xwww9r3bp1+slPfqL7779fZqZYLLZw/1EAYAHY1ES1fBKNRn1gYCDsMgAAReD06dNaunSp3F0tLS2KRCL66le/GnZZALLAzA66ezTsOvIZw6gAAPgIP/7xj/XJT35S69at06lTp/TAAw+EXRIA5A2ebAAAAABp8GQjczzZAAAAABAIJogDCFWsK6b+4X6NnRlTeWm5alfXanfD7rDLAgAAC4CwASA0sa6YDhw7oOYtzapcVanESEKdfZ2KdcUIHAAAFACGUQEITf9wvxrrGhVZE1FJSYkiayJqrGtU/3B/2KUBAIAFQNgAEJqxM2OqXFU541zlqkqNnTl/J2YAAJB/CBsAQlNeWq7ESGLGucRIQuWl5SFVBAAAFhJhA0BoalfXqrOvU0NHhzQxMaGho0Pq7OtU7erasEsDAAALgAniAEKzu2G3Yl0x7XhpB6tRAQBQgAgbAEJFsAAAoHAxjAoAAABAIAgbAAAAAAJB2AAAAAAQCMIGAAAAgEAQNgDMWfdgt6rbq1XyWImq26vVPdgddkkAACAHsRoVgDnpHuzWtr3bVL+xXg+sekCJkYS27d0mSdpaszXk6gAAQC4xdw+7hjmLRqM+MDAQdhlAUapur9am2k2KrIlMnxs6OqQ9/Xv0esvr0+diXTH1D/dr7MyYFpUs0iWXXKLxD8bZSwMAkDfM7KC7R8OuI58xjArAnMRPxFW5qnLGucpVlYqfiE8fx7piOnDsgJq3NOveTfdq6ZKl+uKff1E/aPmBmrc068CxA4p1xbJdOgAAyDLCBoA5qVpRpcRIYsa5xEhCVSuqpo/7h/vVWNeoyJqI9h7cq623bVVkTUQlJSWKrImosa5R/cP92S4dAABkGWEDwJy0bmhVz74eDR0d0sTEhIaODqlnX49aN7ROtxk7Mzb99OP4yeNpn4SMnRnLat0AACD7mCAOYE6mJoG37W9T/ERcVSuqtP3W7TMmh5eXlisxklBkTUQrl6+cfj0lMZJQeWl51msHAADZxQRxAAtuas5GY12j3j/9vnoP9GrrbVtVuapSiZGEOvs6dcuVtzBJHACQ05ggnrkFCRtmtlnS30kqkfSsuz95zvtlkjol3SDphKTPu/v/Jd/7mqRmSROSHnL3vtl+P8IGkPtYjQoAkO8IG5nLeBiVmZVIape0SdKwpFfMbJe7v5bSrFnSSXevMrO7JX1H0ufN7HpJd0taJ2mVpJ+b2Vp3n8i0LgDhIkwAAICFmCB+k6S4uyfc/Yyk5yXdeU6bOyV1JF/3SLrVzCx5/nl3H3f3NyTFk/cDkKNiXTEtfmKxrM20+InFLGELAAAuaCHCxickHU05Hk6eS9vG3c9KOiVpxUVeK0kysy+Z2YCZDbzzzjsLUDaAuUrdP4M9MwAAwGzyZulbd3/G3aPuHr388svDLgcoSDVP18x4alHzdM2M91P3z2DPDAAAMJuFWPr2LUlrUo5XJ8+lazNsZpdK+rgmJ4pfzLUAsqDm6Rq9efpNNW9pnrFqVM3TNRr88qCkmftnTGHPDAAAcCEL8WTjFUkRM7vWzEo1OeF71zltdklqSr6ul7TPJ5fB2iXpbjMrM7NrJUUk/XoBagIwR/H342mfWsTfj0+3mdo/IxV7ZgAAgAvJOGwk52B8RVKfpN9IesHdj5jZY2b22WSzHZJWmFlc0jZJjyavPSLpBUmvSfqZpBZWogLCcTFPLWpX16qzr3PG7uGdfZ2qXV2b7XIBAEAeWJAdxN29V1LvOee+kfJ6TNJfXODab0v69kLUAWD+Unf9nnLuU4vdDbsV64ppx0s7NHZmjD0zAADAR1qQsAEg/1Utq5rc2fv6WzSYGNTxk8dVtqhMS0qWzGhHsAAAABcrb1ajAhCswS8PapEv0oHXDuiuT92l7z/4fTVvadZZO6uW3pawywMAAHmIsAFg2viH4+dNEm+oa1DH4Y7ZLwYAADgHYQPAtNHx0bSTxEfHR0OqCAAA5DPCBoBpFWUVaZe2rSirCKkiAACQzwgbAKY1rW9SV1/XjKVtu/q61LS+afaLAQAAzsFqVACmtd/eLkna2btTo+OjqiirUNP6JrXf3q7uwW617W9T/ERcVSuq1LqhVVtrtoZcMQAAyGU2uZF3folGoz4wMBB2GUDR6B7s1ra921S/sV6VqyqVGEmoZ1+Ptt+6ncABAChYZnbQ3aNh15HPGEYFYFZt+9tUv7F+xipV9Rvr1ba/LezSAABADiNsAJhV/EQ87SpV8RPxkCoCAAD5gLABYFZVK6rSrlJVtaIqpIoAAEA+YII4UMRaelvUcbjjvMng52rd0Do9Z+PVoVd1aOiQfj/+ey0pW6KW3pa01wAAABA2gCLV0tui5448p/tuv2960ndXX5cknRcepiaBP9j7oD685EPdf/v9s14zJdYVU/9wv8bOjKm8tFy1q2u1u2F3gJ8MAADkCoZRoeB1D3arur1aJY+VqLq9Wt2D3WGXlBM6Dneooa5hxqTvhroGdRzuSNt+a81WnfWzaqxrvOhrYl0xHTh2QM1bmvWDlh+oeUuzDhw7oFhXLMiPBgAAcgRhAwVtasnWTbWb9L0Hv6dNtZu0be+2og4cLb0tWvrkUo2Oj6ad9D06PnrBa+d6Tf9w/3nhpLGuUf3D/Zl/EAAAkPMIGyhoLNk6U+rQqSsvuzLtpO+KsooLXl9RVjGna8bOjKUNJ2Nnxub5CQAAQD4hbKCgsWTrTKlDpzbduEnP731eQ0eHNDExoaGjQ+rq61LT+qYLXr+8bLk6+zpnXNPZ16nlZcvTti8vLU8bTspLyxf0cwEAgNzEBHEUtKklWyNrItPninnJ1tRhUDdU3yBJevGXL+rYe8c+cjWqKe+Ovava9bV68Zcv6vjJ41q5fKVuuf4W9R9OPyyqdnWtOvs61VjXOD2hvLOvU7Wraxf+wwEAgJxD2EBBS12ydeovuz37erT91u1hlxaKqWFQU+Hrhuob9LElH9PO3p06/ejpGW3TrSI1dmZMm2/erC1/smW63cTEhPYM7En7++1u2K1YV0w7XtrBalQAABQhwgYK2tSSrW3729M8/bMAAAqbSURBVBQ/EVfViiptv3X79Pli07S+SV19XWqoa5ixdO25Q6dSV5FKfSKxqGRR2idFHzUsimABAEDxMncPu4Y5i0ajPjAwEHYZQF66mI38Fj+xWM1bmmeEiqGjQ3r2X59V6aLS84ZF3XLlLYQKAEDBMbOD7h4Nu458xpMNoMi0394+647fF1pFavyDcW1Ys4FhUQAA4KIQNgCcZ2oVqXTDpQgWAADgYrH0LYDzTK0ide4St6wiBQAA5oInGwDOwypSAABgIRA2AKRFsAAAAJliGBWQB1p6W7T0yaWyNtPSJ5eqpbdlwe4d64pp8ROLZW2mxU8sVqwrtmD3BgAAxY0nG0COa+lt0XNHntN9t983Y28MSbOuKjWbC+2nEeuK8WQDAABkjCcbQI7rONyhhroGRdZEVFJSosiaiBrqGtRxuCPje/cP96uxrnHGvRvrGtU/3L8AlQMAgGJH2ABy3Oj4aNo9L0bHRzO+94X20xg7M5bxvQEAAAgbQI6rKKtQYiQx41xiJKGKsoqM7z21n8a59y4vLc/43gAAAIQNIMc1rW9SV1/XjD0vuvq61LS+KeN7s58GAAAIEhPEgRw3NQl8Z+9OjY6PqqKsQk3rmzKeHC6xnwYAAAiWuXvYNcxZNBr1gYGBsMsAAABAATOzg+4eDbuOfMYwKgAAAACBIGwAAAAACARhAwAAAEAgCBsAUGC6B7tV3V6tksdKVN1ere7B7rBLAgAUKVajAoAC0j3YrW17t6l+Y70eWPWAEiMJbdu7TZK0tWZryNUBAIoNTzYAoIC07W9T/cZ6RdZEVFJSosiaiOo31qttf1vYpQEAihBhAwAKSPxEXJWrKmecq1xVqfiJeEgVAQCKGWEDAApI1YoqJUYSM84lRhKqWlEVUkUAgGJG2ACAAtK6oVU9+3o0dHRIExMTGjo6pJ59PWrd0Bp2aQCAIsQEcQAoIFOTwNv2tyl+Iq6qFVXafut2JocDAEJh7h52DXMWjUZ9YGAg7DIAAABQwMzsoLtHw64jnzGMCgAAAEAgCBsAAAAAAkHYAAAAABAIwgYAAACAQBA2AAAAAASCsAEAAAAgEIQNAAAAAIEgbAAAAAAIBGEDAAAAQCAIGwAAAAACQdgAAAAAEAjCBgAAAIBAEDYAAAAABIKwAQAAACAQhA0AAAAAgSBsAAAAAAgEYQMAAABAIAgbAAAAAAJB2AAAAAAQiIzChpldZmZ7zGwo+XX5Bdo1JdsMmVlTyvlvm9lRMzudSR0AAAAAck+mTzYelbTX3SOS9iaPZzCzyyS1SrpZ0k2SWlNCyb8kzwEAAAAoMJmGjTsldSRfd0j6XJo2dZL2uPt77n5S0h5JmyXJ3Q+4+9sZ1gAAAAAgB2UaNlamhIVjklamafMJSUdTjoeT5wAAAAAUsEtna2BmP5d0ZZq3vp564O5uZr5QhaWp40uSviRJV199dVC/DQAAAIAFMmvYcPfbLvSemR03s6vc/W0zu0rSb9M0e0vSp1OOV0v6xRzrlLs/I+kZSYpGo4GFGgAAAAALI9NhVLskTa0u1STpp2na9EmKmdny5MTwWPIcAAAAgAKWadh4UtImMxuSdFvyWGYWNbNnJcnd35P0LUmvJH89ljwnM/uumQ1LWmJmw2b2zQzrAQAAAJAjzD3/RiRFo1EfGBgIuwwAAAAUMDM76O7RsOvIZ+wgDgAAACAQhA0AAAAAgSBsAAAAAAgEYQMAAABAIAgbAAAAAAJB2AAAAAAQCMIGAAAAgEAQNgAAAAAEgrABAAAAIBCEDQAAAACBIGwAAAAACARhAwAAAEAgCBsAAAAAAkHYAAAAABAIwgYAAACAQBA2AAAAAASCsAEAAAAgEIQNAAAAAIEgbAAAAAAIBGEDAAAAQCAIGwAAAAACQdgAAAAAEAjCBgAAAIBAEDYAAAAABIKwAQAAACAQhA0AAAAAgSBsAAAAAAgEYQMAAABAIAgbAAAAAAJB2AAAAAAQCMIGAAAAgEAQNgAAAAAEwtw97BrmzMzekfRm2HUUqD+Q9G7YRSAv0XcwX/QdzBd9B/N1sX3nD9398qCLKWR5GTYQHDMbcPdo2HUg/9B3MF/0HcwXfQfzRd/JHoZRAQAAAAgEYQMAAABAIAgbONczYReAvEXfwXzRdzBf9B3MF30nS5izAQAAACAQPNkAAAAAEAjCRhEys8vMbI+ZDSW/Lr9Au6ZkmyEza0qeW2JmL5nZ/5jZETN7MrvVI9vMbLOZvW5mcTN7NM37ZWb2T8n3/9PMrkl572vJ86+bWV0260b45tt3zGyTmR00s8Hk143Zrh3hyuT7TvL9q83stJn9VbZqRm7I8GfWejP7j+TfbwbNrDybtRcqwkZxelTSXnePSNqbPJ7BzC6T1CrpZkk3SWpNCSXfd/frJP2RpD81s89kp2xkm5mVSGqX9BlJ10u6x8yuP6dZs6ST7l4l6YeSvpO89npJd0taJ2mzpKeS90MRyKTvaHLt+zvcvUZSk6Su7FSNXJBh35myXdK/BV0rckuGP7MulfScpL9093WSPi3pgyyVXtAIG8XpTkkdydcdkj6Xpk2dpD3u/p67n5S0R9Jmd/+du78sSe5+RtIhSauzUDPCcZOkuLsnkv+/n9dk/0mV2p96JN1qZpY8/7y7j7v7G5LiyfuhOMy777j7f7n7SPL8EUmLzawsK1UjF2TyfUdm9jlJb2iy76C4ZNJ3YpIOu/t/S5K7n3D3iSzVXdAIG8Vppbu/nXx9TNLKNG0+IeloyvFw8tw0M1sm6Q5NPh1BYZq1H6S2cfezkk5JWnGR16JwZdJ3Ut0l6ZC7jwdUJ3LPvPuOmS2V9DeS2rJQJ3JPJt931kpyM+szs0Nm9tdZqLcoXBp2AQiGmf1c0pVp3vp66oG7u5nNeUmy5OPGf5T09+6emF+VAHBhZrZOk0McYmHXgrzxTUk/dPfTyQcdwMW6VNKfSbpR0u8k7TWzg+7OP6hmiLBRoNz9tgu9Z2bHzewqd3/bzK6S9Ns0zd7S5HjFKasl/SLl+BlJQ+7+owUoF7nrLUlrUo5XJ8+lazOcDKEfl3TiIq9F4cqk78jMVkv6Z0mN7v6/wZeLHJJJ37lZUr2ZfVfSMkkfmtmYu/9D8GUjB2TSd4Yl7Xf3dyXJzHol/bEYvZExhlEVp12anHSp5NefpmnTJylmZsuTE8NjyXMys8c1+Yfz4SzUinC9IiliZteaWakmJ3zvOqdNan+ql7TPJzfw2SXp7uTKH9dKikj6dZbqRvjm3XeSQzRfkvSou/971ipGrph333H3Wne/xt2vkfQjSX9L0CgqmfzM6pNUk1x181JJn5L0WpbqLmiEjeL0pKRNZjYk6bbkscwsambPSpK7vyfpW5r8g/uKpMfc/b3kvzZ+XZOrPBwys1fN7IthfAgELzme9Sua/Cb8G0kvuPsRM3vMzD6bbLZDk2Ol45K2Kbm6mbsfkfSCJr9Z/0xSC5PtikcmfSd5XZWkbyS/x7xqZldk+SMgJBn2HRSxDH9mndTkKmavSHpVk3PFXsr2ZyhE7CAOAAAAIBA82QAAAAAQCMIGAAAAgEAQNgAAAAAEgrABAAAAIBCEDQAAAACBIGwAAAAACARhAwAAAEAgCBsAAAAAAvH/LfeRkJAGQuUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 864x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "words = sum([[k] + v for k, v in similar_words.items()], [])\n",
    "wvs = ft_model.wv[words]\n",
    "\n",
    "pca = PCA(n_components=2)\n",
    "np.set_printoptions(suppress=True)\n",
    "P = pca.fit_transform(wvs)\n",
    "labels = words\n",
    "\n",
    "plt.figure(figsize=(12,10))\n",
    "plt.scatter(P[:, 0], P[:, 1], c='lightgreen', edgecolors='g')\n",
    "for label, x, y in zip(labels, P[:, 0], P[:, 1]):\n",
    "    plt.annotate(label, xy=(x+0.01, y+0.01), xytext=(0, 0), textcoords='offset points')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Task 3: Generate document clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reusing the tokenized keywords in cluster for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10, 9)"
      ]
     },
     "execution_count": 331,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load nltk's SnowballStemmer as variabled 'stemmer'\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "stemmer = SnowballStemmer(\"english\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 332,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_stem(text):\n",
    "    # first tokenize by sentence, then by word to ensure that punctuation is caught as it's own token\n",
    "    #tokens = [word for sent in nltk.sent_tokenize(text) for word in nltk.word_tokenize(sent)]\n",
    "    #filtered_tokens = []\n",
    "    # filter out any tokens not containing letters (e.g., numeric tokens, raw punctuation)\n",
    "    #for token in tokens:\n",
    "    #    if re.search('[a-zA-Z]', token):\n",
    "    #        filtered_tokens.append(token)\n",
    "    stems = [stemmer.stem(t) for t in text]\n",
    "    return stems"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    None\n",
       "1    None\n",
       "2    None\n",
       "3    None\n",
       "4    None\n",
       "5    None\n",
       "6    None\n",
       "7    None\n",
       "8    None\n",
       "9    None\n",
       "Name: PaperTextClean, dtype: object"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalvocab_stemmed=[]\n",
    "df.PaperTextClean.apply(lambda x: totalvocab_stemmed.extend(tokenize_and_stem(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31376"
      ]
     },
     "execution_count": 341,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(totalvocab_stemmed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "corpus = [\"welcome to stackoverflow my friend\", \n",
    "          \"my friend, don't worry, you can get help from stackoverflow\"]\n",
    "vectorizer = TfidfVectorizer()\n",
    "matrix = vectorizer.fit_transform(corpus)\n",
    "print(matrix)\n",
    "\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "#define vectorizer parameters\n",
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.8, max_features=200000,\n",
    "                                 min_df=0.2, stop_words='english',\n",
    "                                 use_idf=True, ngram_range=(1,3))\n",
    "\n",
    "%time tfidf_matrix = tfidf_vectorizer.fit_transform(synopses) #fit the vectorizer to synopses\n",
    "\n",
    "print(tfidf_matrix.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, '0.104*\"system\" + 0.072*\"survey\" + 0.071*\"graph\" + 0.043*\"user\" + 0.042*\"trees\" + 0.042*\"eps\" + 0.042*\"time\" + 0.042*\"computer\" + 0.042*\"human\" + 0.042*\"opinion\"')\n",
      "(1, '0.095*\"interface\" + 0.057*\"system\" + 0.056*\"user\" + 0.055*\"human\" + 0.055*\"eps\" + 0.055*\"lab\" + 0.055*\"computer\" + 0.055*\"management\" + 0.055*\"machine\" + 0.054*\"applications\"')\n",
      "(2, '0.072*\"trees\" + 0.043*\"graph\" + 0.042*\"minors\" + 0.042*\"response\" + 0.042*\"user\" + 0.042*\"time\" + 0.042*\"well\" + 0.042*\"widths\" + 0.042*\"quasi\" + 0.042*\"measurement\"')\n",
      "0.3333333354029391\n",
      "[1, 3, 6, 8]\n",
      "[0, 2]\n",
      "[4, 5, 7]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from itertools import chain\n",
    "#https://stackoverflow.com/questions/15016025/how-to-print-the-lda-topics-models-from-gensim-python\n",
    "\"\"\" DEMO \"\"\"\n",
    "documents1 = [\"Human machine interface for lab abc computer applications\",\n",
    "             \"A survey of user opinion of computer system response time\",\n",
    "             \"The EPS user interface management system\",\n",
    "             \"System and human system engineering testing of EPS\",\n",
    "             \"Relation of user perceived response time to error measurement\",\n",
    "             \"The generation of random binary unordered trees\",\n",
    "             \"The intersection graph of paths in trees\",\n",
    "             \"Graph minors IV Widths of trees and well quasi ordering\",\n",
    "             \"Graph minors A survey\"]\n",
    "documents =[(i,documents1[i]) for i in range(len(documents1))]\n",
    "\n",
    "# remove common words and tokenize\n",
    "stoplist = set('for a of the and to in'.split())\n",
    "texts = [[word for word in document[1].lower().split() if word not in stoplist] for document in documents]\n",
    "\n",
    "all_tokens = sum(texts, [])#tokens\n",
    "\n",
    "# remove words that appear only once\n",
    "tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
    "texts1 = [[word for word in text if word not in tokens_once] for text in texts]\n",
    "\n",
    "\n",
    "# Create Dictionary.\n",
    "id2word = corpora.Dictionary(texts)\n",
    "# Creates the Bag of Word corpus.\n",
    "mm = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "# Trains the LDA models.\n",
    "lda = models.ldamodel.LdaModel(corpus=mm, id2word=id2word, num_topics=3, \\\n",
    "                               update_every=1, chunksize=10000, passes=1)\n",
    "\n",
    "# Prints the topics.\n",
    "for top in lda.print_topics():\n",
    "    print(top)\n",
    "\n",
    "\n",
    "# Assigns the topics to the documents in corpus\n",
    "lda_corpus = lda[mm]\n",
    "\n",
    "# Find the threshold, let's set the threshold to be 1/#clusters,\n",
    "# To prove that the threshold is sane, we average the sum of all probabilities:\n",
    "scores = list(chain(*[[score for topic_id,score in topic] for topic in [doc for doc in lda_corpus]]))\n",
    "\n",
    "[lda_corpus[i] for i in range(3)]\n",
    "threshold = sum(scores)/len(scores)\n",
    "\n",
    "print (threshold)\n",
    "print\n",
    "\n",
    "cluster1 = [j[0] for i,j in zip(lda_corpus,documents) if i[0][1] > threshold]\n",
    "cluster2 = [j[0] for i,j in zip(lda_corpus,documents) if i[1][1] > threshold]\n",
    "cluster3 = [j[0] for i,j in zip(lda_corpus,documents) if i[2][1] > threshold]\n",
    "\n",
    "print (cluster1)\n",
    "print (cluster2)\n",
    "print (cluster3)\n",
    "\n",
    "lda.show_topic(1, topn = 5)\n",
    "\n",
    "lda.num_topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "topics_matrix = lda.show_topics(formatted=False, num_words=20)\n",
    "#topics_matrix = np.array(topics_matrix)\n",
    "#[[k for k in i] for i in topics_matrix]\n",
    "#print(topics_matrix)\n",
    "cluster_word_map={key: lda.show_topic(key, topn = 10) for key in range(lda.num_topics)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_word_map={key: lda.show_topic(key, topn = 10) for key in range(lda.num_topics)}\n",
    "cluster_word_map={key:[i[0] for i in val] for key,val in cluster_word_map.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{0: ['system',\n",
       "  'survey',\n",
       "  'graph',\n",
       "  'user',\n",
       "  'trees',\n",
       "  'eps',\n",
       "  'time',\n",
       "  'computer',\n",
       "  'human',\n",
       "  'opinion'],\n",
       " 1: ['interface',\n",
       "  'system',\n",
       "  'user',\n",
       "  'human',\n",
       "  'eps',\n",
       "  'lab',\n",
       "  'computer',\n",
       "  'management',\n",
       "  'machine',\n",
       "  'applications'],\n",
       " 2: ['trees',\n",
       "  'graph',\n",
       "  'minors',\n",
       "  'response',\n",
       "  'user',\n",
       "  'time',\n",
       "  'well',\n",
       "  'widths',\n",
       "  'quasi',\n",
       "  'measurement']}"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cluster_word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('test.json','w') as f:\n",
    "    json.dump(cluster_word_map,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda.save('test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-94-233dc40bc181>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mcommon_texts\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgensim\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcorpora\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdictionary\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mDictionary\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlda\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mldamodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLdaModel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'test' is not defined"
     ]
    }
   ],
   "source": [
    "from gensim.test.utils import common_texts\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "lda = models.ldamodel.LdaModel.load(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv(\"./input/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Id', 'Title', 'EventType', 'PdfName', 'Abstract',\n",
       "       'PaperText', 'AbstractClean', 'PaperTextClean'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df.PaperTextClean.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from gensim import corpora, models, similarities\n",
    "from itertools import chain\n",
    "class document_clustering:\n",
    "    def __init__(self,data):\n",
    "        self.data=data\n",
    "        self.lda_model=None\n",
    "        self.documents_cluster=dict()\n",
    "        self.cluster_word_map=dict()\n",
    "        \n",
    "    def get_document_cluster(self, topic_count=5):\n",
    "        # create a document corpus for LDA\n",
    "        documents =[(i,j) for i,j in zip(self.data.Title, self.data.PaperTextClean)]\n",
    "        \n",
    "        # Make sure to include words which have a minimum length of 3\n",
    "        # NOTE: this is to avoid cases where cleaning removes non alphabetic characters (pg13 -> pg)\n",
    "        document_updated= [[word for word in document[1].lower().split() if len(word)>3 ] for document in documents]\n",
    "\n",
    "        # create list of token\n",
    "        all_tokens = sum(document_updated, [])\n",
    "\n",
    "        # remove words that appear only once\n",
    "        tokens_once = set(word for word in set(all_tokens) if all_tokens.count(word) == 1)\n",
    "\n",
    "        texts = [[word for word in text if word not in tokens_once] for text in document_updated]\n",
    "\n",
    "        # Create Dictionary for word corpora\n",
    "        id2word = corpora.Dictionary(texts)\n",
    "\n",
    "        # Creates the Bag of Word corpus.\n",
    "        bag_of_words = [id2word.doc2bow(text) for text in texts]\n",
    "\n",
    "        # Trains the LDA models.\n",
    "        self.lda_model = models.ldamodel.LdaModel(corpus=bag_of_words, id2word=id2word, num_topics=topic_count, update_every=1, chunksize=10000, passes=1)\n",
    "\n",
    "        # Assigns the topics to the documents in corpus\n",
    "        lda_corpus = self.lda_model[bag_of_words]\n",
    "\n",
    "        # Find threshold for document to be part of cluster, threshold to be 1/#clusters,\n",
    "        # Average the sum of all probabilities:\n",
    "        scores = list(chain(*[[score for topic_id,score in topic] for topic in [doc for doc in lda_corpus]]))\n",
    "        threshold = sum(scores)/len(scores)\n",
    "\n",
    "        # saving the LDA Model\n",
    "        #self.lda_model.save(\"../models/lda_model\")\n",
    "        \n",
    "        # Generate document cluster for each topic\n",
    "        # Document cluster - {cluster_id: [list of documents]}\n",
    "        for i in range(len(document_updated)):\n",
    "            for j in lda_corpus[i]:\n",
    "                if j[1] > threshold:\n",
    "                    key=j[0]\n",
    "                    if key in self.documents_cluster:\n",
    "                        self.documents_cluster[j[0]].append(documents[i][0])\n",
    "                    else:\n",
    "                        self.documents_cluster[j[0]]=[documents[i][0]]      \n",
    "        \n",
    "        # Generate list of words corresponding to cluster\n",
    "        # {cluster_id: [(word, significance of word)]}\n",
    "        self.cluster_word_map={key: self.lda_model.show_topic(key, topn = 10) for key in range(self.lda_model.num_topics)}\n",
    "        #print(self.cluster_word_map)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{4: ['Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing',\n",
       "  'Robust Portfolio Optimization',\n",
       "  'Unlocking neural population non-stationarities using hierarchical dynamics models',\n",
       "  'Bayesian Manifold Learning: The Locally Linear Latent Variable Model (LL-LVM)',\n",
       "  'Fast and Accurate Inference of Plackett–Luce Models',\n",
       "  'Probabilistic Line Searches for Stochastic Optimization',\n",
       "  'Algorithms with Logarithmic or Sublinear Regret for  Constrained Contextual Bandits',\n",
       "  'Automatic Variational Inference in Stan',\n",
       "  'Online Rank Elicitation for Plackett-Luce: A Dueling Bandits Approach',\n",
       "  'Black-box optimization of noisy functions with unknown smoothness',\n",
       "  'Subspace Clustering with Irrelevant Features via Robust Dantzig Selector'],\n",
       " 0: ['Learning with Symmetric Label Noise: The Importance of Being Unhinged',\n",
       "  'Algorithmic Stability and Uniform Generalization',\n",
       "  'Adaptive Low-Complexity Sequential Inference for Dirichlet Process Mixture Models',\n",
       "  'A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements',\n",
       "  'On the Pseudo-Dimension of Nearly Optimal Auctions',\n",
       "  \"Measuring Sample Quality with Stein's Method\",\n",
       "  'Top-k Multiclass SVM',\n",
       "  'Stochastic Online Greedy Learning with Semi-bandit Feedbacks',\n",
       "  'Synaptic Sampling: A Bayesian Approach to Neural Network Plasticity and Rewiring',\n",
       "  'Nonparametric von Mises Estimators for Entropies, Divergences and Mutual Informations',\n",
       "  'Parallelizing MCMC with Random Partition Trees',\n",
       "  'Estimating Mixture Models via Mixtures of Polynomials',\n",
       "  'Learning Theory and Algorithms for Forecasting Non-stationary Time Series',\n",
       "  'A Nonconvex Optimization Framework for Low Rank Matrix Estimation',\n",
       "  'Closed-form Estimators for High-dimensional Generalized Linear Models',\n",
       "  'Tractable Bayesian Network Structure Learning with Bounded Vertex Cover Number',\n",
       "  'Monotone k-Submodular Function Maximization with Size Constraints',\n",
       "  'Online Learning for Adversaries with Memory: Price of Past Mistakes',\n",
       "  'GAP Safe screening rules for sparse multi-task and multi-class models',\n",
       "  'Empirical Localization of Homogeneous Divergences on Discrete Sample Spaces',\n",
       "  'A Generalization of Submodular Cover via the Diminishing Return Property on the Integer Lattice',\n",
       "  'Bidirectional Recurrent Neural Networks as Generative Models',\n",
       "  'Maximum Likelihood Learning With Arbitrary Treewidth via Fast-Mixing Parameter Sets',\n",
       "  'Hessian-free Optimization for Learning Deep Multidimensional Recurrent Neural Networks',\n",
       "  'Large-scale probabilistic predictors with and without guarantees of validity'],\n",
       " 2: ['Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling',\n",
       "  'Space-Time Local Embeddings',\n",
       "  'Galileo: Perceiving Physical Object Properties by Integrating a Physics Engine with Deep Learning',\n",
       "  'Inferring Algorithmic Patterns with Stack-Augmented Recurrent Nets',\n",
       "  'Where are they looking?',\n",
       "  'Bidirectional Recurrent Convolutional Networks for Multi-Frame Super-Resolution',\n",
       "  'Streaming, Distributed Variational Inference for Bayesian Nonparametrics',\n",
       "  'Learning visual biases from human imagination',\n",
       "  'Policy Evaluation Using the Ω-Return',\n",
       "  '3D Object Proposals for Accurate Object Class Detection',\n",
       "  'A Reduced-Dimension fMRI Shared Response Model',\n",
       "  'Individual Planning in Infinite-Horizon Multiagent Settings: Inference, Structure and Scalability',\n",
       "  'Barrier Frank-Wolfe for Marginal Inference',\n",
       "  'Deep learning with Elastic Averaging SGD',\n",
       "  'A Framework for Individualizing Predictions of Disease Trajectories by Exploiting Multi-Resolution Structure',\n",
       "  'Bidirectional Recurrent Neural Networks as Generative Models'],\n",
       " 1: ['Logarithmic Time Online Multiclass prediction',\n",
       "  'Planar Ultrametrics for Image Segmentation',\n",
       "  'Parallel Correlation Clustering on Big Graphs',\n",
       "  'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks',\n",
       "  'Color Constancy by Learning to Predict Chromaticity from Luminance',\n",
       "  'The Pareto Regret Frontier for Bandits',\n",
       "  'Learning visual biases from human imagination',\n",
       "  'Smooth and Strong: MAP Inference with Linear Convergence',\n",
       "  'Optimal Ridge Detection using Coverage Risk',\n",
       "  'Deeply Learning the Messages in Message Passing Inference',\n",
       "  'Accelerated Proximal Gradient Methods for Nonconvex Programming',\n",
       "  'HONOR: Hybrid Optimization for NOn-convex Regularized problems',\n",
       "  'On the Global Linear Convergence of Frank-Wolfe Optimization Variants',\n",
       "  'Attention-Based Models for Speech Recognition',\n",
       "  'Online F-Measure Optimization',\n",
       "  'Tractable Bayesian Network Structure Learning with Bounded Vertex Cover Number',\n",
       "  'Robust Feature-Sample Linear Discriminant Analysis for Brain Disorders Diagnosis',\n",
       "  'Black-box optimization of noisy functions with unknown smoothness',\n",
       "  'Active Learning from Weak and Strong Labelers',\n",
       "  'On the Optimality of Classifier Chain for Multi-label Classification',\n",
       "  'Precision-Recall-Gain Curves: PR Analysis Done Right'],\n",
       " 3: ['Expressing an Image Stream with a Sequence of Natural Sentences',\n",
       "  'Faster R-CNN: Towards Real-Time Object Detection with Region Proposal Networks',\n",
       "  'A Convergent Gradient Descent Algorithm for Rank Minimization and Semidefinite Programming from Random Linear Measurements',\n",
       "  'On the Limitation of Spectral Methods: From the Gaussian Hidden Clique Problem to Rank-One Perturbations of Gaussian Tensors',\n",
       "  'Bounding errors of Expectation-Propagation',\n",
       "  'A fast, universal algorithm to learn parametric nonlinear embeddings',\n",
       "  'Texture Synthesis Using Convolutional Neural Networks',\n",
       "  'Extending Gossip Algorithms to Distributed Estimation of U-statistics',\n",
       "  'Copeland Dueling Bandits',\n",
       "  'Top-k Multiclass SVM',\n",
       "  'Orthogonal NMF through Subspace Exploration',\n",
       "  'Approximating Sparse PCA from Incomplete Data',\n",
       "  'Column Selection via Adaptive Sampling',\n",
       "  'Tensorizing Neural Networks',\n",
       "  'Spectral Learning of Large Structured HMMs for Comparative Epigenomics',\n",
       "  'Deep Knowledge Tracing',\n",
       "  'Rethinking LDA: Moment Matching for Discrete ICA',\n",
       "  'Efficient Compressive Phase Retrieval with Constrained Sensing Vectors',\n",
       "  'Compressive spectral embedding: sidestepping the SVD',\n",
       "  'M-Best-Diverse Labelings for Submodular Energies and Beyond',\n",
       "  'Learning Large-Scale Poisson DAG Models based on OverDispersion Scoring',\n",
       "  'Training Restricted Boltzmann Machine via the ￼Thouless-Anderson-Palmer free energy',\n",
       "  'Character-level Convolutional Networks for Text Classification',\n",
       "  'Recovering Communities in the General Stochastic Block Model Without Knowing the Parameters',\n",
       "  'Deep learning with Elastic Averaging SGD',\n",
       "  'Robust Regression via Hard Thresholding',\n",
       "  'Sparse Local Embeddings for Extreme Multi-label Classification',\n",
       "  'Solving Random Quadratic Systems of Equations Is Nearly as Easy as Solving Linear Systems',\n",
       "  'Sparse PCA via Bipartite Matchings',\n",
       "  'Fast Randomized Kernel Ridge Regression with Statistical Guarantees',\n",
       "  'Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting',\n",
       "  'Quartz: Randomized Dual Coordinate Ascent with Arbitrary Sampling',\n",
       "  'Hessian-free Optimization for Learning Deep Multidimensional Recurrent Neural Networks']}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df1=df[:100]\n",
    "obj=document_clustering(df1)\n",
    "obj.get_document_cluster()\n",
    "obj.documents_cluster\n",
    "#obj.cluster_word_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
