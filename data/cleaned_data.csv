,Id,Title,EventType,PdfName,Abstract,PaperText,AbstractClean,PaperTextClean
0,5677,Double or Nothing: Multiplicative Incentive Mechanisms for Crowdsourcing,Poster,5677-double-or-nothing-multiplicative-incentive-mechanisms-for-crowdsourcing.pdf,"Crowdsourcing has gained immense popularity in machine learning applications for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize workers to answer only the questions that they are sure of and skip the rest. We show that surprisingly, under a mild and natural no-free-lunch requirement, this mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentive-compatible  mechanisms (that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers.  Interestingly, this unique mechanism takes a multiplicative form. The simplicity of the mechanism is an added benefit.  In preliminary experiments involving over several hundred workers, we observe a significant reduction in the error rates under our unique mechanism for the same or lower monetary expenditure.","Double or Nothing: Multiplicative
Incentive Mechanisms for Crowdsourcing
Nihar B. Shah
University of California, Berkeley
nihar@eecs.berkeley.edu

Dengyong Zhou
Microsoft Research
dengyong.zhou@microsoft.com

Abstract
Crowdsourcing has gained immense popularity in machine learning applications
for obtaining large amounts of labeled data. Crowdsourcing is cheap and fast, but
suffers from the problem of low-quality data. To address this fundamental challenge in crowdsourcing, we propose a simple payment mechanism to incentivize
workers to answer only the questions that they are sure of and skip the rest. We
show that surprisingly, under a mild and natural “no-free-lunch” requirement, this
mechanism is the one and only incentive-compatible payment mechanism possible. We also show that among all possible incentive-compatible mechanisms
(that may or may not satisfy no-free-lunch), our mechanism makes the smallest possible payment to spammers. Interestingly, this unique mechanism takes a
“multiplicative” form. The simplicity of the mechanism is an added benefit. In
preliminary experiments involving over several hundred workers, we observe a
significant reduction in the error rates under our unique mechanism for the same
or lower monetary expenditure.

1

Introduction

Complex machine learning tools such as deep learning are gaining increasing popularity and are
being applied to a wide variety of problems. These tools, however, require large amounts of labeled
data [HDY+ 12, RYZ+ 10, DDS+ 09, CBW+ 10]. These large labeling tasks are being performed by
coordinating crowds of semi-skilled workers through the Internet. This is known as crowdsourcing.
Crowdsourcing as a means of collecting labeled training data has now become indispensable to the
engineering of intelligent systems.
Most workers in crowdsourcing are not experts. As a consequence, labels obtained from crowdsourcing typically have a significant amount of error [KKKMF11, VdVE11, WLC+ 10]. Recent
efforts have focused on developing statistical techniques to post-process the noisy labels in order
to improve its quality (e.g., [RYZ+ 10, ZLP+ 15, KOS11, IPSW14]). However, when the inputs to
these algorithms are erroneous, it is difficult to guarantee that the processed labels will be reliable
enough for subsequent use by machine learning or other applications. In order to avoid “garbage in,
garbage out”, we take a complementary approach to this problem: cleaning the data at the time of
collection.
We consider crowdsourcing settings where the workers are paid for their services, such as in the
popular crowdsourcing platforms of Amazon Mechanical Turk and others. These commercial platforms have gained substantial popularity due to their support for a diverse range of tasks for machine
learning labeling, varying from image annotation and text recognition to speech captioning and machine translation. We consider problems that are objective in nature, that is, have a definite answer.
Figure 1a depicts an example of such a question where the worker is shown a set of images, and for
each image, the worker is required to identify if the image depicts the Golden Gate Bridge.
1

Is this the Golden Gate Bridge?

Is this the Golden Gate Bridge?

Yes!

Yes!

No!

No

I’m not sure

(b)!

(a)!

Figure 1: Different interfaces in a crowdsourcing setup: (a) the conventional interface, and (b) with
an option to skip.
Our approach builds on the simple insight that in typical crowdsourcing setups, workers are simply
paid in proportion to the amount of tasks they complete. As a result, workers attempt to answer
questions that they are not sure of, thereby increasing the error rate of the labels. For the questions
that a worker is not sure of, her answers could be very unreliable [WLC+ 10, KKKMF11, VdVE11,
JSV14]. To ensure acquisition of only high-quality labels, we wish to encourage the worker to
skip the questions about which she is unsure, for instance, by providing an explicit “I’m not sure”
option for every question (see Figure 1b). Our goal is to develop payment mechanisms to encourage
the worker to select this option when she is unsure. We will term any payment mechanism that
incentivizes the worker to do so as “incentive compatible”.
In addition to incentive compatibility, preventing spammers is another desirable requirement from
incentive mechanisms in crowdsourcing. Spammers are workers who answer randomly without
regard to the question being asked, in the hope of earning some free money, and are known to exist
in large numbers on crowdsourcing platforms [WLC+ 10, Boh11, KKKMF11, VdVE11]. It is thus
of interest to deter spammers by paying them as low as possible. An intuitive objective, to this end,
is to ensure a zero expenditure on spammers who answer randomly. In this paper, however, we
impose a strictly and significantly weaker condition, and then show that there is one and only one
incentive-compatible mechanism that can satisfy this weak condition. Our requirement, referred to
as the “no-free-lunch” axiom, says that if all the questions attempted by the worker are answered
incorrectly, then the payment must be zero.
We propose a payment mechanism for the aforementioned setting (“incentive compatibility” plus
“no-free-lunch”), and show that surprisingly, this is the only possible mechanism. We also show that
additionally, our mechanism makes the smallest possible payment to spammers among all possible
incentive compatible mechanisms that may or may not satisfy the no-free-lunch axiom. Our payment
mechanism takes a multiplicative form: the evaluation of the worker’s response to each question is
a certain score, and the final payment is a product of these scores. This mechanism has additional
appealing features in that it is simple to compute, and is also simple to explain to the workers. Our
mechanism is applicable to any type of objective questions, including multiple choice annotation
questions, transcription tasks, etc.
In order to test whether our mechanism is practical, and to assess the quality of the final labels
obtained, we conducted experiments on the Amazon Mechanical Turk crowdsourcing platform. In
our preliminary experiments that involved over several hundred workers, we found that the quality
of data improved by two-fold under our unique mechanism, with the total monetary expenditure
being the same or lower as compared to the conventional baseline.

2

Problem Setting

In the crowdsourcing setting that we consider, one or more workers perform a task, where a task
consists of multiple questions. The questions are objective, by which we mean, each question has
precisely one correct answer. Examples of objective questions include multiple-choice classification
questions such as Figure 1, questions on transcribing text from audio or images, etc.
For any possible answer to any question, we define the worker’s confidence about an answer as the
probability, according to her belief, of this answer being correct. In other words, one can assume
that the worker has (in her mind) a probability distribution over all possible answers to a question,
and the confidence for an answer is the probability of that answer being correct. As a shorthand, we
also define the confidence about a question as the confidence for the answer that the worker is most
2

confident about for that question. We assume that the worker’s confidences for different questions
are independent. Our goal is that for every question, the worker should be incentivized to:
1. skip if the confidence is below a certain pre-defined threshold, otherwise:
2. select the answer that she thinks is most confident about.
More formally, let T 2 (0, 1) be a predefined value. The goal is to design payment mechanisms that
incentivize the worker to skip the questions for which her confidence is lower than T , and attempt
those for which her confidence is higher than T . 1 Moreover, for the questions that she attempts to
answer, she must be incentivized to select the answer that she believes is most likely to be correct.
The threshold T may be chosen based on various factors of the problem at hand, for example, on
the downstream machine learning algorithms using the crowdsourced data, or the knowledge of the
statistics of worker abilities, etc. In this paper we assume that the threshold T is given to us.
Let N denote the total number of questions in the task. Among these, we assume the existence of
some “gold standard” questions, that is, a set of questions whose answers are known to the requester.
Let G (1  G  N ) denote the number of gold standard questions. The G gold standard questions
are assumed to be distributed uniformly at random in the pool of N questions (of course, the worker
does not know which G of the N questions form the gold standard). The payment to a worker for
a task is computed after receiving her responses to all the questions in the task. The payment is
based on the worker’s performance on the gold standard questions. Since the payment is based on
known answers, the payments to different workers do not depend on each other, thereby allowing us
to consider the presence of only one worker without any loss in generality.
We will employ the following standard notation. For any positive integer K, the set {1, . . . , K} is
denoted by [K]. The indicator function is denoted by 1, i.e., 1{z} = 1 if z is true, and 0 otherwise.
The notation R+ denotes the set of all non-negative real numbers.
Let x1 , . . . , xG 2 { 1, 0, +1} denote the evaluations of the answers that the worker gives to the G
gold standard questions. Here, “0” denotes that the worker skipped the question, “ 1” denotes that
the worker attempted to answer the question and that answer was incorrect, and “+1” denotes that
the worker attempted to answer the question and that answer was correct. Let f : { 1, 0, +1}G !
R+ denote the payment function, namely, a function that determines the payment to the worker
based on these evaluations x1 , . . . , xG . Note that the crowdsourcing platforms of today mandate the
payments to be non-negative. We will let µ (> 0) denote the budget, i.e., the maximum amount that
can be paid to any individual worker for this task:
max f (x1 , . . . , xG ) = µ.
x1 ,...,xG

The amount µ is thus the amount of compensation paid to a perfect agent for her work. We will
assume this budget condition of µ throughout the rest of the paper.
We assume that the worker attempts to maximize her overall expected payment. In what follows, the
expression ‘the worker’s expected payment’ will refer to the expected payment from the worker’s
point of view, and the expectation will be taken with respect to the worker’s confidences about her
answers and the uniformly random choice of the G gold standard questions among the N questions
in the task. For any question i 2 [N ], let yi = 1 if the worker attempts question i, and set yi = 0
otherwise. Further, for every question i 2 [N ] such that yi 6= 0, let pi be the confidence of the
worker for the answer she has selected for question i, and for every question i 2 [N ] such that
yi = 0, let pi 2 (0, 1) be any arbitrary value. Let E = (✏1 , . . . , ✏G ) 2 { 1, 1}G . Then from the
worker’s perspective, the expected payment for the selected answers and confidence-levels is
!
G
X
X
Y
1+✏i
1 ✏i
1
f (✏1 yj1 , . . . , ✏G yjG ) (pji ) 2 (1 pji ) 2
.
N
G

i=1

(j1 ,...,jG ) E2{ 1,1}G
✓{1,...,N }

In the expression above, the outermost summation corresponds to the expectation with respect to the
randomness arising from the unknown choice of the gold standard questions. The inner summation
corresponds to the expectation with respect to the worker’s beliefs about the correctness of her
responses.
1
In the event that the confidence about a question is exactly equal to T , the worker may be equally incentivized to answer or skip.

3

We will call any payment function f as an incentive-compatible mechanism if the expected payment
of the worker under this payment function is strictly maximized when the worker responds in the
manner desired.2

3

Main results: Incentive-compatible mechanism and guarantees

In this section, we present the main results of the paper, namely, the design of incentive-compatible
mechanisms with practically useful properties. To this end, we impose the following natural requirement on the payment function f that is motivated by the practical considerations of budget
constraints and discouraging spammers and miscreants [Boh11, KKKMF11, VdVE11, WLC+ 10].
We term this requirement as the “no-free-lunch axiom”:
Axiom 1 (No-free-lunch axiom). If all the answers attempted by the worker in the gold standard are
wrong, then the payment is zero. More formally, for every set of evaluations (x1 , . . . , xG ) that satisfy
PG
PG
0 < i=1 1{xi 6= 0} = i=1 1{xi = 1}, we require the payment to satisfy f (x1 , . . . , xG ) = 0.

Observe that no-free-lunch is an extremely mild requirement. In fact, it is significantly weaker than
imposing a zero payment on workers who answer randomly. For instance, if the questions are of
binary-choice format, then randomly choosing among the two options for each question would result
in 50% of the answers being correct in expectation, while the no-free-lunch axiom is applicable only
when none of them turns out to be correct.
3.1

Proposed “Multiplicative” Mechanism

We now present our proposed payment mechanism in Algorithm 1.
Algorithm 1 “Multiplicative” incentive-compatible mechanism
• Inputs: Threshold T , Budget µ, Evaluations (x1 , . . . , xG ) 2 { 1, 0, +1}G of the worker’s answers to the G gold standard questions
PG
PG
• Let C = i=1 1{xi = 1} and W = i=1 1{xi = 1}
• The payment is

f (x1 , . . . , xG ) = µT G

C

1{W = 0}.

The proposed mechanism has a multiplicative form: each answer in the gold standard is given a
score based on whether it was correct (score = T1 ), incorrect (score = 0) or skipped (score = 1),
and the final payment is simply a product of these scores (scaled by µ). The mechanism is easy to
describe to workers: For instance, if T = 12 , G = 3 and µ = 80 cents, then the description reads:
“The reward starts at 10 cents. For every correct answer in the 3 gold standard questions,
the reward will double. However, if any of these questions are answered incorrectly, then
the reward will become zero. So please use the ‘I’m not sure’ option wisely.”
Observe how this payment rule is similar to the popular ‘double or nothing’ paradigm [Dou14].
The algorithm makes a zero payment if one or more attempted answers in the gold standard are
wrong. Note that this property is significantly stronger than the property of no-free-lunch which
we originally required, where we wanted a zero payment only when all attempted answers were
wrong. Surprisingly, as we prove shortly, Algorithm 1 is the only incentive-compatible mechanism
that satisfies no-free-lunch.
The following theorem shows that the proposed payment mechanism indeed incentivizes a worker
to skip the questions for which her confidence is below T , while answering those for which her
confidence is greater than T . In the latter case, the worker is incentivized to select the answer which
she thinks is most likely to be correct.
Theorem 1. The payment mechanism of Algorithm 1 is incentive-compatible and satisfies the nofree-lunch condition.
2
Such a payment function that is based on gold standard questions is also called a “strictly proper scoring
rule” [GR07].

4

The proof of Theorem 1 is presented in Appendix A. It is easy to see that the mechanism satisfies nofree-lunch. The proof of incentive compatibility is also not hard: We consider any arbitrary worker
(with arbitrary belief distributions), and compute the expected payment for that worker for the case
when her choices in the task follow the requirements. We then show that any other choice leads to a
strictly smaller expected payment.
While we started out with a very weak condition of no-free-lunch of making a zero payment when
all attempted answers are wrong, the mechanism proposed in Algorithm 1 is significantly more
strict and makes a zero payment when any of the attempted answers is wrong. A natural question
that arises is: can we design an alternative mechanism satisfying incentive compatibility and nofree-lunch that operates somewhere in between?
3.2

Uniqueness of the Mechanism

In the previous section we showed that our proposed multiplicative mechanism is incentive compatible and satisfies the intuitive requirement of no-free-lunch. It turns out, perhaps surprisingly, that
this mechanism is unique in this respect.
Theorem 2. The payment mechanism of Algorithm 1 is the only incentive-compatible mechanism
that satisfies the no-free-lunch condition.
Theorem 2 gives a strong result despite imposing very weak requirements. To see this, recall our earlier discussion on deterring spammers, that is, incurring a low expenditure on workers who answer
randomly. For instance, when the task comprises binary-choice questions, one may wish to design
mechanisms which make a zero payment when the responses to 50% or more of the questions in the
gold standard are incorrect. The no-free-lunch axiom is a much weaker requirement, and the only
mechanism that can satisfy this requirement is the mechanism of Algorithm 1.
The proof of Theorem 2 is available in Appendix B. The proof relies on the following key lemma
that establishes a condition that any incentive-compatible mechanism must necessarily satisfy. The
lemma applies to any incentive-compatible mechanism and not just to those satisfying no-free-lunch.
Lemma. Any incentive-compatible payment mechanism f must satisfy, for every i 2 {1, . . . , G}
and every (y1 , . . . , yi 1 , yi+1 , . . . , yG ) 2 { 1, 0, 1}G 1 ,
T f (y1 , . . . , yi

1 , 1, yi+1 , . . . , yG )

+ (1

T )f (y1 , . . . , yi 1 , 1, yi+1 , . . . , yG )
= f (y1 , . . . , yi 1 , 0, yi+1 , . . . , yG ).

The proof of this lemma is provided in Appendix C. Given this lemma, the proof of Theorem 2 is
then completed via an induction on the number of skipped questions.
3.3

Optimality against Spamming Behavior

As discussed earlier, crowdsouring tasks, especially those with multiple choice questions, often
encounter spammers who answer randomly without heed to the question being asked. For instance,
under a binary-choice setup, a spammer will choose one of the two options uniformly at random for
every question. A highly desirable objective in crowdsourcing settings is to deter spammers. To this
end, one may wish to impose a condition of zero payment when the responses to 50% or more of
the attempted questions in the gold standard are incorrect. A second desirable metric could be to
minimize the expenditure on a worker who simply skips all questions. While the aforementioned
requirements were deterministic functions of the worker’s responses, one may alternatively wish to
impose requirements that depend on the distribution of the worker’s answering process. For instance,
a third desirable feature would be to minimize the expected payment to a worker who answers all
questions uniformly at random. We now show that interestingly, our unique multiplicative payment
mechanism simultaneously satisfies all these requirements. The result is stated assuming a multiplechoice setup, but extends trivially to non-multiple-choice settings.
Theorem 3.A (Distributional). Consider any value A 2 {0, . . . , G}. Among all incentivecompatible mechanisms (that may or may not satisfy no-free-lunch), Algorithm 1 strictly minimizes
the expenditure on a worker who skips some A of the questions in the the gold standard, and chooses
answers to the remaining (G A) questions uniformly at random.
5

Theorem 3.B (Deterministic). Consider any value B 2 (0, 1]. Among all incentive-compatible
mechanisms (that may or may not satisfy no-free-lunch), Algorithm 1 strictly minimizes the expenditure on a worker who gives incorrect answers to a fraction B or more of the questions attempted
in the gold standard.
The proof of Theorem 3 is presented in Appendix D. We see from this result that the multiplicative
payment mechanism of Algorithm 1 thus possesses very useful properties geared to deter spammers,
while ensuring that a good worker will be paid a high enough amount.
To illustrate this point, let us compare the mechanism of Algorithm 1 with the popular additive class
of payment mechanisms.
Example 1. Consider the popular class of “additive” mechanisms, where the payments to a worker
are added across the gold standard questions. This additive payment mechanism offers a reward of
µ
µT
G for every correct answer in the gold standard, G for every question skipped, and 0 for every
incorrect answer. Importantly, the final payment to the worker is the sum of the rewards across the
G gold standard questions. One can verify that this additive mechanism is incentive compatible.
One can also see that that as guaranteed by our theory, this additive payment mechanism does not
satisfy the no-free-lunch axiom.
Suppose each question involves choosing from two options. Let us compute the expenditure that
these two mechanisms make under a spamming behavior of choosing the answer randomly to each
question. Given the 50% likelihood of each question being correct, on can compute that the additive
mechanism makes a payment of µ2 in expectation. On the other hand, our mechanism pays an
expected amount of only µ2 G . The payment to spammers thus reduces exponentially with the
number of gold standard questions under our mechanism, whereas it does not reduce at all in the
additive mechanism.
Now, consider a different means of exploiting the mechanism(s) where the worker simply skips all
questions. To this end, observe that if a worker skips all the questions then the additive payment
mechanism will incur an expenditure of µT . On the other hand, the proposed payment mechanism
of Algorithm 1 pays an exponentially smaller amount of µT G (recall that T < 1).

4

Simulations and Experiments

In this section, we present synthetic simulations and real-world experiments to evaluate the effects
of our setting and our mechanism on the final label quality.
4.1

Synthetic Simulations

We employ synthetic simulations to understand the effects of various kinds of labeling errors in
crowdsourcing. We consider binary-choice questions in this set of simulations. Whenever a worker
answers a question, her confidence for the correct answer is drawn from a distribution P independent
of all else. We investigate the effects of the following five choices of the distribution P:
•
•
•
•
•

The uniform distribution on the support [0.5, 1].
A triangular distribution with lower end-point 0.2, upper end-point 1 and a mode of 0.6.
A beta distribution with parameter values ↵ = 5 and = 1.
The hammer-spammer distribution [KOS11], that is, uniform on the discrete set {0.5, 1}.
A truncated Gaussian distribution: a truncation of N (0.75, 0.5) to the interval [0, 1].

When a worker has a confidence p (drawn from the distribution P) and attempts the question, the
probability of making an error equals (1 p).
We compare (a) the setting where workers attempt every question, with (b) the setting where workers
skip questions for which their confidence is below a certain threshold T . In this set of simulations,
we set T = 0.75. In either setting, we aggregate the labels obtained from the workers for each
question via a majority vote on the two classes. Ties are broken by choosing one of the two options
uniformly at random.
6

Figure 2: Error under different interfaces for synthetic simulations of five distributions of the workers’ error probabilities.

Figure 2 depicts the results from these simulations. Each bar represents the fraction of questions that
are labeled incorrectly, and is an average across 50,000 trials. (The standard error of the mean is too
small to be visible.) We see that the skip-based setting consistently outperforms the conventional
setting, and the gains obtained are moderate to high depending on the underlying distribution of the
workers’ errors. In particular, the gains are quite striking under the hammer-spammer model: this
result is not surprising since the mechanism (ideally) screens the spammers out and leaves only the
hammers who answer perfectly.

4.2

Experiments on Amazon Mechanical Turk

We conducted preliminary experiments on the Amazon Mechanical Turk commercial crowdsourcing
platform (mturk.com) to evaluate our proposed scheme in real-world scenarios. The complete
data, including the interface presented to the workers in each of the tasks, the results obtained from
the workers, and the ground truth solutions, are available on the website of the first author.
Goal. Before delving into details, we first note certain caveats relating to such a study of mechanism design on crowdsourcing platforms. When a worker encounters a mechanism for only a
small amount of time (a handful of tasks in typical research experiments) and for a small amount of
money (at most a few dollars in typical crowdsourcing tasks), we cannot expect the worker to completely understand the mechanism and act precisely as required. For instance, we wouldn’t expect
our experimental results to change significantly even upon moderate modifications in the promised
amounts, and furthermore, we do expect the outcomes to be noisy. Incentive compatibility kicks
in when the worker encounters a mechanism across a longer term, for example, when a proposed
mechanism is adopted as a standard for a platform, or when higher amounts are involved. This is
when we would expect workers or others (e.g., bloggers or researchers) to design strategies that can
game the mechanism. The theoretical guarantee of incentive compatibility or strict properness then
prevents such gaming in the long run.
We thus regard these experiments as preliminary. Our intentions towards this experimental exercise
were (a) to evaluate the potential of our algorithms to work in practice, and (b) to investigate the
effect of the proposed algorithms on the net error in the collected labelled data.
Experimental setup. We conducted the five following experiments (“tasks”) on Amazon Mechanical Turk: (a) identifying the golden gate bridge from pictures, (b) identifying the breeds of dogs
from pictures, (c) identifying heads of countries, (d) identifying continents to which flags belong,
and (e) identifying the textures in displayed images. Each of these tasks comprised 20 to 126 multi7

Figure 3: Error under different interfaces and mechanisms for five experiments conducted on Mechanical Turk.
ple choice questions.3 For each experiment, we compared (i) a baseline setting (Figure 1a) with an
additive payment mechanism that pays a fixed amount per correct answer, and (ii) our skip-based
setting (Figure 1b) with the multiplicative mechanism of Algorithm 1. For each experiment, and for
each of the two settings, we had 35 workers independently perform the task.
Upon completion of the tasks on Amazon Mechanical Turk, we aggregated the data in the following
manner. For each mechanism in each experiment, we subsampled 3, 5, 7, 9 and 11 workers, and
took a majority vote of their responses. We averaged the accuracy across all questions and across
1, 000 iterations of this subsample-and-aggregate procedure.
Results. Figure 3 reports the error in the aggregate data in the five experiments. We see that in
most cases, our skip-based setting results in a higher quality data, and in many of the instances, the
reduction is two-fold or higher. All in all, in the experiments, we observed a substantial reduction in
the amount of error in the labelled data while expending the same or lower amounts and receiving
no negative comments from the workers. These observations suggest that our proposed skip-based
setting coupled with our multiplicative payment mechanisms have potential to work in practice; the
underlying fundamental theory ensures that the system cannot be gamed in the long run.

5

Discussion and Conclusions

In an extended version of this paper [SZ14], we generalize the “skip-based” setting considered here
to one where we also elicit the workers’ confidence about their answers. Moreover, in a companion
paper [SZP15], we construct mechanisms to elicit the support of worker’s beliefs.
Our mechanism offers some additional benefits. The pattern of skips of the workers provide a reasonable estimate of the difficulty of each question. In practice, the questions that are estimated to
be more difficult may now be delegated to an expert or to additional non-expert workers. Secondly,
the theoretical guarantees of our mechanism may allow for better post-processing of the data, incorporating the confidence information and improving the overall accuracy. Developing statistical
aggregation algorithms or augmenting existing ones (e.g., [RYZ+ 10, KOS11, LPI12, ZLP+ 15]) for
this purpose is a useful direction of research. Thirdly, the simplicity of our mechanisms may facilitate an easier adoption among the workers. In conclusion, given the uniqueness and optimality
in theory, simplicity, and good performance observed in practice, we envisage our multiplicative
payment mechanisms to be of interest to practitioners as well as researchers who employ crowdsourcing.

3
See the extended version of this paper [SZ14] for additional experiments involving free-form responses,
such as text transcription.

8

References
[Boh11]

John Bohannon. Social science for pennies. Science, 334(6054):307–307, 2011.

[CBW 10]

Andrew Carlson, Justin Betteridge, Richard C Wang, Estevam R Hruschka Jr, and
Tom M Mitchell. Coupled semi-supervised learning for information extraction. In
ACM WSDM, pages 101–110, 2010.

[DDS+ 09]

Jia Deng, Wei Dong, Richard Socher, Li-Jia Li, Kai Li, and Li Fei-Fei. Imagenet: A
large-scale hierarchical image database. In IEEE Conference on Computer Vision and
Pattern Recognition, pages 248–255, 2009.

[Dou14]

Double or Nothing. http://wikipedia.org/wiki/Double_or_nothing,
2014. Last accessed: July 31, 2014.

[GR07]

Tilmann Gneiting and Adrian E Raftery. Strictly proper scoring rules, prediction, and
estimation. Journal of the American Statistical Association, 102(477):359–378, 2007.

[HDY+ 12]

Geoffrey Hinton, Li Deng, Dong Yu, George E Dahl, Abdel-rahman Mohamed,
Navdeep Jaitly, Andrew Senior, Vincent Vanhoucke, Patrick Nguyen, Tara N Sainath,
et al. Deep neural networks for acoustic modeling in speech recognition: The shared
views of four research groups. IEEE Signal Processing Magazine, 29(6):82–97, 2012.
Panagiotis G Ipeirotis, Foster Provost, Victor S Sheng, and Jing Wang. Repeated
labeling using multiple noisy labelers. Data Mining and Knowledge Discovery,
28(2):402–441, 2014.

+

[IPSW14]
[JSV14]

Srikanth Jagabathula, Lakshminarayanan Subramanian, and Ashwin Venkataraman.
Reputation-based worker filtering in crowdsourcing. In Advances in Neural Information Processing Systems 27, pages 2492–2500, 2014.

[KKKMF11] Gabriella Kazai, Jaap Kamps, Marijn Koolen, and Natasa Milic-Frayling. Crowdsourcing for book search evaluation: impact of HIT design on comparative system
ranking. In ACM SIGIR, pages 205–214, 2011.
[KOS11]

David R Karger, Sewoong Oh, and Devavrat Shah. Iterative learning for reliable
crowdsourcing systems. In Advances in neural information processing systems, pages
1953–1961, 2011.

[LPI12]

Qiang Liu, Jian Peng, and Alexander T Ihler. Variational inference for crowdsourcing.
In NIPS, pages 701–709, 2012.

[RYZ+ 10]

Vikas C Raykar, Shipeng Yu, Linda H Zhao, Gerardo Hermosillo Valadez, Charles
Florin, Luca Bogoni, and Linda Moy. Learning from crowds. The Journal of Machine
Learning Research, 11:1297–1322, 2010.

[SZ14]

Nihar B Shah and Dengyong Zhou. Double or nothing: Multiplicative incentive
mechanisms for crowdsourcing. arXiv:1408.1387, 2014.

[SZP15]

Nihar B Shah, Dengyong Zhou, and Yuval Peres. Approval voting and incentives in
crowdsourcing. In International Conference on Machine Learning (ICML), 2015.

[VdVE11]

Jeroen Vuurens, Arjen P de Vries, and Carsten Eickhoff. How much spam can you
take? An analysis of crowdsourcing results to increase accuracy. In ACM SIGIR
Workshop on Crowdsourcing for Information Retrieval, pages 21–26, 2011.

[WLC+ 10]

Paul Wais, Shivaram Lingamneni, Duncan Cook, Jason Fennell, Benjamin Goldenberg, Daniel Lubarov, David Marin, and Hari Simons. Towards building a highquality workforce with Mechanical Turk. NIPS workshop on computational social
science and the wisdom of crowds, 2010.

[ZLP+ 15]

Dengyong Zhou, Qiang Liu, John C Platt, Christopher Meek, and Nihar B
Shah. Regularized minimax conditional entropy for crowdsourcing. arXiv preprint
arXiv:1503.07240, 2015.

9

",crowdsourc gain immens popular machin learn applic obtain larg amount label datum crowdsourc cheap fast suffer problem lowqual datum address fundament challeng crowdsourc propos simpl payment mechan incentiv worker answer question sure skip rest show surprisingli mild natur nofreelunch requir mechan one incentivecompat payment mechan possibl also show among possibl incentivecompat mechan may may satisfi nofreelunch mechan make small possibl payment spammer interestingli uniqu mechan take multipl form simplic mechan add benefit preliminari experi involv sever hundr worker observ signific reduct error rate uniqu mechan low monetari expenditur,doubl noth multipl incent mechan crowdsourc nihar b shah univers california berkeley nihareec berkeley edu dengyong zhou microsoft research dengyong zhoumicrosoft com abstract crowdsourc gain immens popular machin learn applic obtain larg amount label datum crowdsourc cheap fast suffer problem lowqual datum address fundament challeng crowdsourc propos simpl payment mechan incentiv worker answer question sure skip rest show surprisingli mild natur nofreelunch requir mechan one incentivecompat payment mechan possibl also show among possibl incentivecompat mechan may may satisfi nofreelunch mechan make small possibl payment spammer interestingli uniqu mechan take multipl form simplic mechan add benefit preliminari experi involv sever hundr worker observ signific reduct error rate uniqu mechan low monetari expenditur introduct complex machin learn tool deep learn gain increas popular appli wide varieti problem tool howev requir larg amount label datum [ hdi ryz dd cbw ] larg label task perform coordin crowd semiskil worker internet know crowdsourc crowdsourc mean collect label train datum becom indispens engin intellig system worker crowdsourc expert consequ label obtain crowdsourc typic signific amount error [ kkkmf vdve wlc ] recent effort focu develop statist techniqu postprocess noisi label order improv qualiti e g [ ryz zlp ko ipsw ] howev input algorithm erron difficult guarante process label reliabl enough subsequ use machin learn applic order avoid garbag garbag take complementari approach problem clean datum time collect consid crowdsourc set worker pay servic popular crowdsourc platform amazon mechan turk other commerci platform gain substanti popular due support divers rang task machin learn label vari imag annot text recognit speech caption machin translat consid problem object natur definit answer figur depict exampl question worker show set imag imag worker requir identifi imag depict golden gate bridg golden gate bridg golden gate bridg ye ye i be sure b figur differ interfac crowdsourc setup convent interfac b option skip approach build simpl insight typic crowdsourc setup worker simpli pay proport amount task complet result worker attempt answer question sure therebi increas error rate label question worker sure answer could unreli [ wlc kkkmf vdve jsv ] ensur acquisit highqual label wish encourag worker skip question unsur instanc provid explicit i be sure option everi question see figur b goal develop payment mechan encourag worker select option unsur term payment mechan incentiviz worker incent compat addit incent compat prevent spammer anoth desir requir incent mechan crowdsourc spammer worker answer randomli without regard question ask hope earn free money know exist larg number crowdsourc platform [ wlc boh kkkmf vdve ] thu interest deter spammer pay low possibl intuit object end ensur zero expenditur spammer answer randomli paper howev impos strictli significantli weak condit show one one incentivecompat mechan satisfi weak condit requir refer nofreelunch axiom say question attempt worker answer incorrectli payment must zero propos payment mechan aforement set incent compat plu nofreelunch show surprisingli possibl mechan also show addit mechan make small possibl payment spammer among possibl incent compat mechan may may satisfi nofreelunch axiom payment mechan take multipl form evalu worker respons question certain score final payment product score mechan addit appeal featur simpl comput also simpl explain worker mechan applic type object question includ multipl choic annot question transcript task etc order test whether mechan practic assess qualiti final label obtain conduct experi amazon mechan turk crowdsourc platform preliminari experi involv sever hundr worker find qualiti datum improv twofold uniqu mechan total monetari expenditur lower compar convent baselin problem set crowdsourc set consid one worker perform task task consist multipl question question object mean question precis one correct answer exampl object question includ multiplechoic classif question figur question transcrib text audio imag etc possibl answer question defin worker confid answer probabl accord belief answer correct word one assum worker mind probabl distribut possibl answer question confid answer probabl answer correct shorthand also defin confid question confid answer worker confid question assum worker confid differ question independ goal everi question worker incentiviz skip confid certain predefin threshold otherwis select answer think confid formal let predefin valu goal design payment mechan incentiv worker skip question confid low attempt confid high moreov question attempt answer must incentiviz select answer believ like correct threshold may chosen base variou factor problem hand exampl downstream machin learn algorithm use crowdsourc datum knowledg statist worker abil etc paper assum threshold give us let n denot total number question task among assum exist gold standard question set question whose answer know request let g g n denot number gold standard question g gold standard question assum distribut uniformli random pool n question cours worker know g n question form gold standard payment worker task comput receiv respons question task payment base worker perform gold standard question sinc payment base known answer payment differ worker depend therebi allow us consid presenc one worker without loss gener employ follow standard notat posit integ k set k denot [ k ] indic function denot e z z true otherwis notat r denot set nonneg real number let x xg denot evalu answer worker give g gold standard question denot worker skip question denot worker attempt answer question answer incorrect denot worker attempt answer question answer correct let f g r denot payment function name function determin payment worker base evalu x xg note crowdsourc platform today mandat payment nonneg let denot budget e maximum amount pay individu worker task max f x xg x xg amount thu amount compens pay perfect agent work assum budget condit throughout rest paper assum worker attempt maxim overal expect payment follow express worker expect payment refer expect payment worker point view expect take respect worker confid answer uniformli random choic g gold standard question among n question task question [ n ] let yi worker attempt question set yi otherwis everi question [ n ] yi let pi confid worker answer select question everi question [ n ] yi let pi arbitrari valu let e g g worker perspect expect payment select answer confidencelevel g x x f yj g yjg pji pji n g j jg e g n express outermost summat correspond expect respect random aris unknown choic gold standard question inner summat correspond expect respect worker belief correct respons event confid question exactli equal worker may equal incentiviz answer skip call payment function f incentivecompat mechan expect payment worker payment function strictli maxim worker respond manner desir main result incentivecompat mechan guarante section present main result paper name design incentivecompat mechan practic use properti end impos follow natur requir payment function f motiv practic consider budget constraint discourag spammer miscreant [ boh kkkmf vdve wlc ] term requir nofreelunch axiom axiom nofreelunch axiom answer attempt worker gold standard wrong payment zero formal everi set evalu x xg satisfi pg pg xi xi requir payment satisfi f x xg observ nofreelunch extrem mild requir fact significantli weak impos zero payment worker answer randomli instanc question binarychoic format randomli choos among two option question would result answer correct expect nofreelunch axiom applic none turn correct propos multipl mechan present propos payment mechan algorithm algorithm multipl incentivecompat mechan input threshold budget evalu x xg g worker answer g gold standard question pg pg let c xi w xi payment f x xg g c w propos mechan multipl form answer gold standard give score base whether correct score incorrect score skip score final payment simpli product score scale mechan easi describ worker instanc g cent descript read reward start cent everi correct answer gold standard question reward doubl howev question answer incorrectli reward becom zero pleas use i be sure option wise observ payment rule similar popular doubl noth paradigm [ dou ] algorithm make zero payment one attempt answer gold standard wrong note properti significantli strong properti nofreelunch origin requir want zero payment attempt answer wrong surprisingli prove shortli algorithm incentivecompat mechan satisfi nofreelunch follow theorem show propos payment mechan inde incentiviz worker skip question confid answer confid great latter case worker incentiviz select answer think like correct theorem payment mechan algorithm incentivecompat satisfi nofreelunch condit payment function base gold standard question also call strictli proper score rule [ gr ] proof theorem present appendix easi see mechan satisfi nofreelunch proof incent compat also hard consid arbitrari worker arbitrari belief distribut comput expect payment worker case choic task follow requir show choic lead strictli small expect payment start weak condit nofreelunch make zero payment attempt answer wrong mechan propos algorithm significantli strict make zero payment attempt answer wrong natur question aris design altern mechan satisfi incent compat nofreelunch oper somewher uniqu mechan previou section show propos multipl mechan incent compat satisfi intuit requir nofreelunch turn perhap surprisingli mechan uniqu respect theorem payment mechan algorithm incentivecompat mechan satisfi nofreelunch condit theorem give strong result despit impos weak requir see recal earli discuss deter spammer incur low expenditur worker answer randomli instanc task compris binarychoic question one may wish design mechan make zero payment respons question gold standard incorrect nofreelunch axiom much weak requir mechan satisfi requir mechan algorithm proof theorem avail appendix b proof reli follow key lemma establish condit incentivecompat mechan must necessarili satisfi lemma appli incentivecompat mechan satisfi nofreelunch lemma incentivecompat payment mechan f must satisfi everi g everi yi yi yg g f yi yi yg f yi yi yg f yi yi yg proof lemma provid appendix c give lemma proof theorem complet via induct number skip question optim spamm behavior discuss earli crowdsour task especi multipl choic question often encount spammer answer randomli without heed question ask instanc binarychoic setup spammer choos one two option uniformli random everi question highli desir object crowdsourc set deter spammer end one may wish impos condit zero payment respons attempt question gold standard incorrect second desir metric could minim expenditur worker simpli skip question aforement requir determinist function worker respons one may altern wish impos requir depend distribut worker answer process instanc third desir featur would minim expect payment worker answer question uniformli random show interestingli uniqu multipl payment mechan simultan satisfi requir result state assum multiplechoic setup extend trivial nonmultiplechoic set theorem distribut consid valu g among incentivecompat mechan may may satisfi nofreelunch algorithm strictli minim expenditur worker skip question gold standard choos answer remain g question uniformli random theorem b determinist consid valu b ] among incentivecompat mechan may may satisfi nofreelunch algorithm strictli minim expenditur worker give incorrect answer fraction b question attempt gold standard proof theorem present appendix see result multipl payment mechan algorithm thu possess use properti gear deter spammer ensur good worker pay high enough amount illustr point let us compar mechan algorithm popular addit class payment mechan exampl consid popular class addit mechan payment worker add across gold standard question addit payment mechan offer reward g everi correct answer gold standard g everi question skip everi incorrect answer importantli final payment worker sum reward across g gold standard question one verifi addit mechan incent compat one also see guarante theori addit payment mechan satisfi nofreelunch axiom suppos question involv choos two option let us comput expenditur two mechan make spamm behavior choos answer randomli question give likelihood question correct comput addit mechan make payment expect hand mechan pay expect amount g payment spammer thu reduc exponenti number gold standard question mechan wherea reduc addit mechan consid differ mean exploit mechan worker simpli skip question end observ worker skip question addit payment mechan incur expenditur hand propos payment mechan algorithm pay exponenti small amount g recal simul experi section present synthet simul realworld experi evalu effect set mechan final label qualiti synthet simul employ synthet simul understand effect variou kind label error crowdsourc consid binarychoic question set simul whenev worker answer question confid correct answer draw distribut p independ els investig effect follow five choic distribut p uniform distribut support [ ] triangular distribut low endpoint upper endpoint mode beta distribut paramet valu hammerspamm distribut [ ko ] uniform discret set truncat gaussian distribut truncat n interv [ ] worker confid p draw distribut p attempt question probabl make error equal p compar set worker attempt everi question b set worker skip question confid certain threshold set simul set either set aggreg label obtain worker question via major vote two class tie break choos one two option uniformli random figur error differ interfac synthet simul five distribut worker error probabl figur depict result simul bar repres fraction question label incorrectli averag across trial standard error mean small visibl see skipba set consist outperform convent set gain obtain moder high depend underli distribut worker error particular gain quit strike hammerspamm model result surpris sinc mechan ideal screen spammer leaf hammer answer perfectli experi amazon mechan turk conduct preliminari experi amazon mechan turk commerci crowdsourc platform mturk com evalu propos scheme realworld scenario complet datum includ interfac present worker task result obtain worker grind truth solut avail websit first author goal delv detail first note certain caveat relat studi mechan design crowdsourc platform worker encount mechan small amount time hand task typic research experi small amount money dollar typic crowdsourc task can not expect worker complet understand mechan act precis requir instanc would not expect experiment result chang significantli even upon moder modif promis amount furthermor expect outcom noisi incent compat kick worker encount mechan across long term exampl propos mechan adopt standard platform high amount involv would expect worker other e g blogger research design strategi game mechan theoret guarante incent compat strict proper prevent game long run thu regard experi preliminari intent toward experiment exercis evalu potenti algorithm work practic b investig effect propos algorithm net error collect label datum experiment setup conduct five follow experi task amazon mechan turk identifi golden gate bridg pictur b identifi breed dog pictur c identifi head countri identifi contin flag belong e identifi textur display imag task compris multi figur error differ interfac mechan five experi conduct mechan turk ple choic question experi compar baselin set figur addit payment mechan pay fix amount per correct answer ii skipba set figur b multipl mechan algorithm experi two set worker independ perform task upon complet task amazon mechan turk aggreg datum follow manner mechan experi subsampl worker take major vote respons averag accuraci across question across iter subsampleandaggreg procedur result figur report error aggreg datum five experi see case skipba set result high qualiti datum mani instanc reduct twofold high experi observ substanti reduct amount error label datum expend low amount receiv neg comment worker observ suggest propos skipba set coupl multipl payment mechan potenti work practic underli fundament theori ensur system can not game long run discuss conclus extend version paper [ sz ] gener skipba set consid one also elicit worker confid answer moreov companion paper [ szp ] construct mechan elicit support worker belief mechan offer addit benefit pattern skip worker provid reason estim difficulti question practic question estim difficult may deleg expert addit nonexpert worker secondli theoret guarante mechan may allow better postprocess datum incorpor confid inform improv overal accuraci develop statist aggreg algorithm augment exist one e g [ ryz ko lpi zlp ] purpos use direct research thirdli simplic mechan may facilit easi adopt among worker conclus give uniqu optim theori simplic good perform observ practic envisag multipl payment mechan interest practition well research employ crowdsourc see extend version paper [ sz ] addit experi involv freeform respons text transcript refer [ boh ] john bohannon social scienc penni scienc [ cbw ] andrew carlson justin betteridg richard c wang estevam r hruschka jr tom mitchel coupl semisupervis learn inform extract acm wsdm page [ dd ] jia deng wei dong richard socher lijia li kai li li feifei imagenet largescal hierarch imag databas ieee confer comput vision pattern recognit page [ dou ] doubl noth httpwikipedia orgwikidouble_or_noth last access juli [ gr ] tilmann gneit adrian e rafteri strictli proper score rule predict estim journal american statist associ [ hdi ] geoffrey hinton li deng dong yu georg e dahl abdelrahman moham navdeep jaitli andrew senior vincent vanhouck patrick nguyen tara n sainath et al deep neural network acoust model speech recognit share view four research group ieee signal process magazin panagioti g ipeiroti foster provost victor sheng jing wang repeat label use multipl noisi label datum mine knowledg discoveri [ ipsw ] [ jsv ] srikanth jagabathula lakshminarayanan subramanian ashwin venkataraman reputationba worker filter crowdsourc advanc neural inform process system page [ kkkmf ] gabriella kazai jaap kamp marijn koolen natasa milicfrayl crowdsourc book search evalu impact hit design compar system rank acm sigir page [ ko ] david r karger sewoong oh devavrat shah iter learn reliabl crowdsourc system advanc neural inform process system page [ lpi ] qiang liu jian peng alexand ihler variat infer crowdsourc nip page [ ryz ] vika c raykar shipeng yu linda h zhao gerardo hermosillo valadez charl florin luca bogoni linda moy learn crowd journal machin learn research [ sz ] nihar b shah dengyong zhou doubl noth multipl incent mechan crowdsourc arxiv [ szp ] nihar b shah dengyong zhou yuval per approv vote incent crowdsourc intern confer machin learn icml [ vdve ] jeroen vuuren arjen p de vrie carsten eickhoff much spam take analysi crowdsourc result increas accuraci acm sigir workshop crowdsourc inform retriev page [ wlc ] paul wai shivaram lingamneni duncan cook jason fennel benjamin goldenberg daniel lubarov david marin hari simon toward build highqual workforc mechan turk nip workshop comput social scienc wisdom crowd [ zlp ] dengyong zhou qiang liu john c platt christoph meek nihar b shah regular minimax condit entropi crowdsourc arxiv preprint arxiv
1,5941,Learning with Symmetric Label Noise: The Importance of Being Unhinged,Spotlight,5941-learning-with-symmetric-label-noise-the-importance-of-being-unhinged.pdf,"Convex potential minimisation is the de facto approach to binary classification. However, Long and Servedio [2008] proved that under symmetric label noise (SLN), minimisation of any convex potential over a linear function class can result in classification performance equivalent to random guessing. This ostensibly shows that convex losses are not SLN-robust. In this paper, we propose a convex, classification-calibrated loss and prove that it is SLN-robust. The loss avoids the Long and Servedio [2008] result by virtue of being negatively unbounded. The loss is a modification of the hinge loss, where one does not clamp at zero; hence, we call it the unhinged loss. We show that the optimal unhinged solution is equivalent to that of a strongly regularised SVM, and is the limiting solution for any convex potential; this implies that strong l2 regularisation makes most standard learners SLN-robust. Experiments confirm the unhinged loss’ SLN-robustness.","Learning with Symmetric Label Noise: The
Importance of Being Unhinged

Brendan van Rooyen∗,†
∗

Aditya Krishna Menon†,∗

The Australian National University

†

Robert C. Williamson∗,†

National ICT Australia

{ brendan.vanrooyen, aditya.menon, bob.williamson }@nicta.com.au

Abstract
Convex potential minimisation is the de facto approach to binary classification.
However, Long and Servedio [2010] proved that under symmetric label noise
(SLN), minimisation of any convex potential over a linear function class can result in classification performance equivalent to random guessing. This ostensibly
shows that convex losses are not SLN-robust. In this paper, we propose a convex,
classification-calibrated loss and prove that it is SLN-robust. The loss avoids the
Long and Servedio [2010] result by virtue of being negatively unbounded. The
loss is a modification of the hinge loss, where one does not clamp at zero; hence,
we call it the unhinged loss. We show that the optimal unhinged solution is equivalent to that of a strongly regularised SVM, and is the limiting solution for any
convex potential; this implies that strong `2 regularisation makes most standard
learners SLN-robust. Experiments confirm the unhinged loss’ SLN-robustness is
borne out in practice. So, with apologies to Wilde [1895], while the truth is rarely
pure, it can be simple.

1

Learning with symmetric label noise

Binary classification is the canonical supervised learning problem. Given an instance space X, and
samples from some distribution D over X × {±1}, the goal is to learn a scorer s : X → R with low
misclassification error on future samples drawn from D. Our interest is in the more realistic scenario
where the learner observes samples from some corruption D of D, where labels have some constant
probability of being flipped, and the goal is still to perform well with respect to D. This problem is
known as learning from symmetric label noise (SLN learning) [Angluin and Laird, 1988].
Long and Servedio [2010] showed that there exist linearly separable D where, when the learner
observes some corruption D with symmetric label noise of any nonzero rate, minimisation of any
convex potential over a linear function class results in classification performance on D that is equivalent to random guessing. Ostensibly, this establishes that convex losses are not “SLN-robust” and
motivates the use of non-convex losses [Stempfel and Ralaivola, 2009, Masnadi-Shirazi et al., 2010,
Ding and Vishwanathan, 2010, Denchev et al., 2012, Manwani and Sastry, 2013].
In this paper, we propose a convex loss and prove that it is SLN-robust. The loss avoids the result
of Long and Servedio [2010] by virtue of being negatively unbounded. The loss is a modification of the hinge loss where one does not clamp at zero; thus, we call it the unhinged loss. This
loss has several appealing properties, such as being the unique convex loss satisfying a notion of
“strong” SLN-robustness (Proposition 5), being classification-calibrated (Proposition 6), consistent
when minimised on D (Proposition 7), and having an simple optimal solution that is the difference
of two kernel means (Equation 8). Finally, we show that this optimal solution is equivalent to that of
a strongly regularised SVM (Proposition 8), and any twice-differentiable convex potential (Proposition 9), implying that strong `2 regularisation endows most standard learners with SLN-robustness.
1

The classifier resulting from minimising the unhinged loss is not new [Devroye et al., 1996, Chapter 10], [Schölkopf and Smola, 2002, Section 1.2], [Shawe-Taylor and Cristianini, 2004, Section
5.1]. However, establishing this classifier’s (strong) SLN-robustness, uniqueness thereof, and its
equivalence to a highly regularised SVM solution, to our knowledge is novel.

2

Background and problem setup

Fix an instance space X. We denote by D a distribution over X × {±1}, with random variables
(X, Y) ∼ D. Any D may be expressed via the class-conditionals (P, Q) = (P(X | Y = 1), P(X |
Y = −1)) and base rate π = P(Y = 1), or via the marginal M = P(X) and class-probability
function η : x 7→ P(Y = 1 | X = x). We interchangeably write D as DP,Q,π or DM,η .
2.1

Classifiers, scorers, and risks

A scorer is any function s : X → R. A loss is any function ` : {±1} × R → R. We use `−1 , `1 to
refer to `(−1, ·) and `(1, ·). The `-conditional risk L` : [0, 1] × R → R is defined as L` : (η, v) 7→
η · `1 (v) + (1 − η) · `−1 (v). Given a distribution D, the `-risk of a scorer s is defined as
.

LD
` (s) =

[`(Y, s(X))] ,

E

(X,Y)∼D

(1)

D
so that LD
` (s) = E [L` (η(X), s(X))]. For a set S, L` (S) is the set of `-risks for all scorers in S.
X∼M

A function class is any F ⊆ RX . Given some F, the set of restricted Bayes-optimal scorers for a
loss ` are those scorers in F that minimise the `-risk:
.

SD,F,∗
= Argmin LD
` (s).
`
s∈F

The set of (unrestricted) Bayes-optimal scorers is SD,∗
= SD,F,∗
for F = RX . The restricted
`
`
`-regret of a scorer is its excess risk over that of any restricted Bayes-optimal scorer:
.

D
regretD,F
(s) = LD
` (s) − inf L` (t).
`
t∈F

Binary classification is concerned with the zero-one loss, `01 : (y, v) 7→ Jyv < 0K + 21 Jv = 0K.
A loss ` is classification-calibrated if all its Bayes-optimal scorers are also optimal for zero-one
loss: (∀D) SD,∗
⊆ SD,∗
01 . A convex potential is any loss ` : (y, v) 7→ φ(yv), where φ : R → R+ is
`
convex, non-increasing, differentiable with φ0 (0) < 0, and φ(+∞) = 0 [Long and Servedio, 2010,
Definition 1]. All convex potentials are classification-calibrated [Bartlett et al., 2006, Theorem 2.1].
2.2

Learning with symmetric label noise (SLN learning)

The problem of learning with symmetric label noise (SLN learning) is the following [Angluin and
Laird, 1988, Kearns, 1998, Blum and Mitchell, 1998, Natarajan et al., 2013]. For some notional
“clean” distribution D, which we would like to observe, we instead observe samples from some
corrupted distribution SLN(D, ρ), for some ρ ∈ [0, 1/2). The distribution SLN(D, ρ) is such that
the marginal distribution of instances is unchanged, but each label is independently flipped with
probability ρ. The goal is to learn a scorer from these corrupted samples such that LD
01 (s) is small.
For any quantity in D, we denote its corrupted counterparts in SLN(D, ρ) with a bar, e.g. M for
the corrupted marginal distribution, and η for the corrupted class-probability function; additionally,
when ρ is clear from context, we will occasionally refer to SLN(D, ρ) by D. It is easy to check that
the corrupted marginal distribution M = M , and [Natarajan et al., 2013, Lemma 7]
(∀x ∈ X) η(x) = (1 − 2ρ) · η(x) + ρ.

3

(2)

SLN-robustness: formalisation

We consider learners (`, F) for a loss ` and a function class F, with learning being the search for
some s ∈ F that minimises the `-risk. Informally, (`, F) is “robust” to symmetric label noise (SLNrobust) if minimising ` over F gives the same classifier on both the clean distribution D, which
2

the learner would like to observe, and SLN(D, ρ) for any ρ ∈ [0, 1/2), which the learner actually
observes. We now formalise this notion, and review what is known about SLN-robust learners.
3.1

SLN-robust learners: a formal definition

For some fixed instance space X, let ∆ denote the set of distributions on X × {±1}. Given a notional
“clean” distribution D, Nsln : ∆ → 2∆ returns the set of possible corrupted versions of D the learner
may observe, where labels are flipped with unknown probability ρ:



1
Nsln : D 7→ SLN(D, ρ) | ρ ∈ 0,
.
2
Equipped with this, we define our notion of SLN-robustness.
Definition 1 (SLN-robustness). We say that a learner (`, F) is SLN-robust if
D,F,∗
D,F,∗
(∀D ∈ ∆) (∀D ∈ Nsln (D)) LD
) = LD
).
01 (S`
01 (S`

(3)

That is, SLN-robustness requires that for any level of label noise in the observed distribution D, the
classification performance (wrt D) of the learner is the same as if the learner directly observes D.
Unfortunately, a widely adopted class of learners is not SLN-robust, as we will now see.
3.2

Convex potentials with linear function classes are not SLN-robust

Fix X = Rd , and consider learners with a convex potential `, and a function class of linear scorers
Flin = {x 7→ hw, xi | w ∈ Rd }.
This captures e.g. the linear SVM and logistic regression, which are widely studied in theory and
applied in practice. Disappointingly, these learners are not SLN-robust: Long and Servedio [2010,
Theorem 2] give an example where, when learning under symmetric label noise, for any convex
potential `, the corrupted `-risk minimiser over Flin has classification performance equivalent to
random guessing on D. This implies that (`, Flin ) is not SLN-robust1 as per Definition 1.
Proposition 1 (Long and Servedio [2010, Theorem 2]). Let X = Rd for any d ≥ 2. Pick any convex
potential `. Then, (`, Flin ) is not SLN-robust.
3.3

The fallout: what learners are SLN-robust?

In light of Proposition 1, there are two ways to proceed in order to obtain SLN-robust learners: either
we change the class of losses `, or we change the function class F.
The first approach has been pursued in a large body of work that embraces non-convex losses
[Stempfel and Ralaivola, 2009, Masnadi-Shirazi et al., 2010, Ding and Vishwanathan, 2010,
Denchev et al., 2012, Manwani and Sastry, 2013]. While such losses avoid the conditions of Proposition 1, this does not automatically imply that they are SLN-robust when used with Flin . In Appendix
B, we present evidence that some of these losses are in fact not SLN-robust when used with Flin .
The second approach is to consider suitably rich F that contains the Bayes-optimal scorer for D,
e.g. by employing a universal kernel. With this choice, one can still use a convex potential loss, and
in fact, owing to Equation 2, any classification-calibrated loss.
Proposition 2. Pick any classification-calibrated `. Then, (`, RX ) is SLN-robust.
Both approaches have drawbacks. The first approach has a computational penalty, as it requires
optimising a non-convex loss. The second approach has a statistical penalty, as estimation rates
with a rich F will require a larger sample size. Thus, it appears that SLN-robustness involves a
computational-statistical tradeoff. However, there is a variant of the first option: pick a loss that is
convex, but not a convex potential. Such a loss would afford the computational and statistical advantages of minimising convex risks with linear scorers. Manwani and Sastry [2013] demonstrated
that square loss, `(y, v) = (1 − yv)2 , is one such loss. We will show that there is a simpler loss that
is convex and SLN-robust, but is not in the class of convex potentials by virtue of being negatively
unbounded. To derive this loss, we first re-interpret robustness via a noise-correction procedure.
1
Even if we were content with a difference of  ∈ [0, 1/2] between the clean and corrupted minimisers’
performance, Long and Servedio [2010, Theorem 2] implies that in the worst case  = 1/2.

3

4

A noise-corrected loss perspective on SLN-robustness

We now re-express SLN-robustness to reason about optimal scorers on the same distribution, but
with two different losses. This will help characterise a set of “strongly SLN-robust” losses.
4.1

Reformulating SLN-robustness via noise-corrected losses

Given any ρ ∈ [0, 1/2), Natarajan et al. [2013, Lemma 1] showed how to associate with a loss ` a
D
noise-corrected counterpart ` such that LD
` (s) = L` (s). The loss ` is defined as follows.
Definition 2 (Noise-corrected loss). Given any loss ` and ρ ∈ [0, 1/2), the noise-corrected loss ` is
(∀y ∈ {±1}) (∀v ∈ R) `(y, v) =

(1 − ρ) · `(y, v) − ρ · `(−y, v)
.
1 − 2ρ

(4)

Since ` depends on the unknown parameter ρ, it is not directly usable to design an SLN-robust
learner. Nonetheless, it is a useful theoretical device, since, by construction, for any F, SD,F,∗
=
`
SD,F,∗
= SD,F,∗
. This means that a sufficient condition for (`, F) to be SLN-robust is for SD,F,∗
.
`
`
`
Ghosh et al. [2015, Theorem 1] proved a sufficient condition on ` such that this holds, namely,
(∃C ∈ R)(∀v ∈ R) `1 (v) + `−1 (v) = C.
(5)
Interestingly, Equation 5 is necessary for a stronger notion of robustness, which we now explore.
4.2

Characterising a stronger notion of SLN-robustness

As the first step towards a stronger notion of robustness, we rewrite (with a slight abuse of notation)
LD
` (s) =

E

(X,Y)∼D

[`(Y, s(X))] =

E

(Y,S)∼R(D,s)

.

[`(Y, S)] = L` (R(D, s)),

where R(D, s) is a distribution over labels and scores. Standard SLN-robustness requires that label
noise does not change the `-risk minimisers, i.e. that if s is such that L` (R(D, s)) ≤ L` (R(D, s0 ))
for all s0 , the same relation holds with D in place of D. Strong SLN-robustness strengthens this
notion by requiring that label noise does not affect the ordering of all pairs of joint distributions over
labels and scores. (This of course trivially implies SLN-robustness.) As with the definition of D,
given a distribution R over labels and scores, let R be the corresponding distribution where labels
are flipped with probability ρ. Strong SLN-robustness can then be made precise as follows.
Definition 3 (Strong SLN-robustness). Call a loss ` strongly SLN-robust if for every ρ ∈ [0, 1/2),
(∀R, R0 ) L` (R) ≤ L` (R0 ) ⇐⇒ L` (R) ≤ L` (R0 ).
We now re-express strong SLN-robustness using a notion of order equivalence of loss pairs, which
simply requires that two losses order all distributions over labels and scores identically.
˜ order equivalent if
Definition 4 (Order equivalent loss pairs). Call a pair of losses (`, `)
(∀R, R0 ) L` (R) ≤ L` (R0 ) ⇐⇒ L`˜(R) ≤ L`˜(R0 ).
Clearly, order equivalence of (`, `) implies SD,F,∗
= SD,F,∗
, which in turn implies SLN-robustness.
`
`
It is thus not surprising that we can relate order equivalence to strong SLN-robustness of `.
Proposition 3. A loss ` is strongly SLN-robust iff for every ρ ∈ [0, 1/2), (`, `) are order equivalent.
This connection now lets us exploit a classical result in decision theory about order equivalent losses
being affine transformations of each other. Combined with the definition of `, this lets us conclude
that the sufficient condition of Equation 5 is also necessary for strong SLN-robustness of `.
Proposition 4. A loss ` is strongly SLN-robust if and only if it satisfies Equation 5.
We now return to our original goal, which was to find a convex ` that is SLN-robust for Flin (and
ideally more general function classes). The above suggests that to do so, it is reasonable to consider
those losses that satisfy Equation 5. Unfortunately, it is evident that if ` is convex, non-constant, and
bounded below by zero, then it cannot possibly be admissible in this sense. But we now show that
removing the boundedness restriction allows for the existence of a convex admissible loss.
4

5

The unhinged loss: a convex, strongly SLN-robust loss

Consider the following simple, but non-standard convex loss:
unh
`unh
1 (v) = 1 − v and `−1 (v) = 1 + v.

Compared to the hinge loss, the loss does not clamp at zero, i.e. it does not have a hinge. (Thus, peculiarly, it is negatively unbounded, an issue we discuss in §5.3.) Thus, we call this the unhinged loss2 .
The loss has a number of attractive properties, the most immediate being is its SLN-robustness.
5.1

The unhinged loss is strongly SLN-robust

unh
unh
Since `unh
is strongly SLN-robust, and thus that
1 (v) + `−1 (v) = 2, Proposition 4 implies that `
unh
(` , F) is SLN-robust for any F. Further, the following uniqueness property is not hard to show.
Proposition 5. Pick any convex loss `. Then,

(∃C ∈ R) `1 (v) + `−1 (v) = C ⇐⇒ (∃A, B, D ∈ R) `1 (v) = −A · v + B, `−1 (v) = A · v + D.
That is, up to scaling and translation, `unh is the only convex loss that is strongly SLN-robust.
Returning to the case of linear scorers, the above implies that (`unh , Flin ) is SLN-robust. This does
not contradict Proposition 1, since `unh is not a convex potential as it is negatively unbounded. Intuitively, this property allows the loss to offset the penalty incurred by instances that are misclassified
with high margin by awarding a “gain” for instances that correctly classified with high margin.
5.2

The unhinged loss is classification calibrated

SLN-robustness is by itself insufficient for a learner to be useful. For example, a loss that is uniformly zero is strongly SLN-robust, but is useless as it is not classification-calibrated. Fortunately,
the unhinged loss is classification-calibrated, as we now establish. For technical reasons (see §5.3),
we operate with FB = [−B, +B]X , the set of scorers with range bounded by B ∈ [0, ∞).
Proposition 6. Fix ` = `unh . For any DM,η , B ∈ [0, ∞), S`D,FB ,∗ = {x 7→ B · sign(2η(x) − 1)}.
Thus, for every B ∈ [0, ∞), the restricted Bayes-optimal scorer over FB has the same sign as the
Bayes-optimal classifier for 0-1 loss. In the limiting case where F = RX , the optimal scorer is
attainable if we operate over the extended reals R ∪ {±∞}, so that `unh is classification-calibrated.
5.3

Enforcing boundedness of the loss

While the classification-calibration of `unh is encouraging, Proposition 6 implies that its (unrestricted) Bayes-risk is −∞. Thus, the regret of every non-optimal scorer s is identically +∞, which
hampers analysis of consistency. In orthodox decision theory, analogous theoretical issues arise
when attempting to establish basic theorems with unbounded losses [Ferguson, 1967, pg. 78].
We can side-step this issue by restricting attention to bounded scorers, so that `unh is effectively
bounded. By Proposition 6, this does not affect the classification-calibration of the loss. In the context of linear scorers, boundedness of scorers can be achieved by regularisation:
instead of work√
ing with Flin , one can instead use Flin,λ = {x 7→ hw, xi | ||w||2 ≤ 1/ λ}, where λ > 0, so
that Flin,λ ⊆ FR/√λ for R = supx∈X ||x||2 . Observe that as (`unh , F) is SLN-robust for any F,
(`unh , Flin,λ ) is SLN-robust for any λ > 0. As we shall see in §6.3, working with Flin,λ also lets us
establish SLN-robustness of the hinge loss when λ is large.
5.4

Unhinged loss minimisation on corrupted distribution is consistent

Using bounded scorers makes it possible to establish a surrogate regret bound for the unhinged loss.
This shows classification consistency of unhinged loss minimisation on the corrupted distribution.
2
This loss has been considered in Sriperumbudur et al. [2009], Reid and Williamson [2011] in the context
of maximum mean discrepancy; see the Appendix. The analysis of its SLN-robustness is to our knowledge
novel.

5

Proposition 7. Fix ` = `unh . Then, for any D, ρ ∈ [0, 1/2), B ∈ [1, ∞), and scorer s ∈ FB ,
1
D,FB
regretD
(s) =
· regret`D,FB (s).
01 (s) ≤ regret`
1 − 2ρ
Standard rates of convergence via generalisation bounds are also trivial to derive; see the Appendix.

6

Learning with the unhinged loss and kernels

We now show that the optimal solution for the unhinged loss when employing regularisation and
kernelised scorers has a simple form. This sheds further light on SLN-robustness and regularisation.
6.1

The centroid classifier optimises the unhinged loss

Consider minimising the unhinged
risk over the class of kernelised scorers FH,λ = {s : x 7→
√
hw, Φ(x)iH | ||w||H ≤ 1/ λ} for some λ > 0, where Φ : X → H is a feature mapping into a
reproducing kernel Hilbert space H with kernel k. Equivalently, given a distribution3 D, we want
λ
∗
wunh,λ
= argmin E [1 − Y · hw, Φ(X)i] + hw, wiH .
(6)
2
(X,Y)∼D
w∈H
The first-order optimality condition implies that
1
∗
(7)
wunh,λ
= · E [Y · Φ(X)] ,
λ (X,Y)∼D
which is the kernel mean map of D [Smola et al., 2007], and thus the optimal unhinged scorer is


1
1
s∗unh,λ : x 7→ · E [Y · k(X, x)] = x 7→ · π · E [k(X, x)] − (1 − π) · E [k(X, x)] .
X∼P
X∼Q
λ (X,Y)∼D
λ
(8)
From Equation 8, the unhinged solution is equivalent to a nearest centroid classifier [Manning et al.,
2008, pg. 181] [Tibshirani et al., 2002] [Shawe-Taylor and Cristianini, 2004, Section 5.1]. Equation
8 gives a simple way to understand the SLN-robustness of (`unh , FH,λ ), as the optimal scorers on
the clean and corrupted distributions only differ by a scaling (see the Appendix):


1
· E
Y · k(X, x) .
(9)
(∀x ∈ X) E [Y · k(X, x)] =
1 − 2ρ (X,Y)∼D
(X,Y)∼D
Interestingly, Servedio [1999, Theorem 4] established that a nearest centroid classifier (which they
termed “AVERAGE ”) is robust to a general class of label noise, but required the assumption that
M is uniform over the unit sphere. Our result establishes that SLN robustness of the classifier
holds without any assumptions on M . In fact, Ghosh et al. [2015, Theorem 1] lets one quantify the
unhinged loss’ performance under a more general noise model; see the Appendix for discussion.
6.2

Practical considerations

We note several points relating to practical usage of the unhinged loss with kernelised scorers. First,
cross-validation is not required to select λ, since changing λ only changes the magnitude of scores,
not their sign. Thus, for the purposes of classification, one can simply use λ = 1.
Second, we can easily extend the scorers to use a bias regularised with strength 0 < λb 6= λ. Tuning
λb is equivalent to computing s∗unh,λ as per Equation 8, and tuning a threshold on a holdout set.
∗
Third, when H = Rd for d small, we can store wunh,λ
explicitly, and use this to make predictions.
For high (or infinite) dimensional H, we can either make predictions directly via Equation 8, or
use random Fourier features [Rahimi and Recht, 2007] to (approximately) embed H into some low∗
dimensional Rd , and then store wunh,λ
as usual. (The latter requires a translation-invariant kernel.)
∗
We now show that under some assumptions, wunh,λ
coincides with the solution of two established
methods; the Appendix discusses some further relationships, e.g. to the maximum mean discrepancy.
3

Given a training sample S ∼ Dn , we can use plugin estimates as appropriate.

6

6.3

Equivalence to a highly regularised SVM and other convex potentials

There is an interesting equivalence between the unhinged solution and that of a highly regularised
SVM. This has been noted in e.g. Hastie et al. [2004, Section 6], which showed how SVMs approach
a nearest centroid classifier, which is of course the optimal unhinged solution.
Proposition 8. Pick any D and Φ : X → H with R = supx∈X ||Φ(x)||H < ∞. For any λ > 0, let
∗
whinge,λ
= argmin
w∈H

E

(X,Y)∼D

[max(0, 1 − Y · hw, Φ(x)iH )] +

λ
hw, wiH
2

∗
∗
be the soft-margin SVM solution. Then, if λ ≥ R2 , whinge,λ
= wunh,λ
.

Since (`unh , FH,λ ) is SLN-robust, it follows that for `hinge : (y, v) 7→ max(0, 1−yv), (`hinge , FH,λ )
is similarly SLN-robust provided λ is sufficiently large. That is, strong `2 regularisation (and a
bounded feature map) endows the hinge loss with SLN-robustness4 . Proposition 8 can be generalised
∗
to show that wunh,λ
is the limiting solution of any twice differentiable convex potential. This shows
that strong `2 regularisation endows most learners with SLN-robustness. Intuitively, with strong
regularisation, one only considers the behaviour of a loss near zero; since a convex potential φ has
φ0 (0) < 0, it will behave similarly to its linear approximation around zero, viz. the unhinged loss.
Proposition 9. Pick any D, bounded feature mapping Φ : X → H, and twice differentiable convex
∗
potential φ with φ00 ([−1, 1]) bounded. Let wφ,λ
be the minimiser of the regularised φ risk. Then,

2
∗
 w ∗

wunh,λ


φ,λ
lim  ∗
−
 = 0.
∗
λ→∞  ||wφ,λ ||H
||wunh,λ
||H 
H

6.4

Equivalence to Fisher Linear Discriminant with whitened data

For binary classification on DM,η , the Fisher Linear Discriminant (FLD) finds a weight vector proportional to the minimiser of square loss `sq : (y, v) 7→ (1 − yv)2 [Bishop, 2006, Section 4.1.5],
∗
wsq,λ
= (EX∼M [XXT ] + λI)−1 · E(X,Y)∼D [Y · X].

(10)

∗
wsq,λ

is only changed by a scaling
By Equation 9, and the fact that the corrupted marginal M = M ,
factor under label noise. This provides an alternate proof of the fact that (`sq , Flin ) is SLN-robust5
∗
[Manwani and Sastry, 2013, Theorem 2]. Clearly, the unhinged loss solution wunh,λ
is equivalent to
 T
∗
the FLD and square loss solution wsq,λ when the input data is whitened i.e. E XX = I. With
X∼M

a well-specified F, e.g. with a universal kernel, both the unhinged and square loss asymptotically
recover the optimal classifier, but the unhinged loss does not require a matrix inversion. With a
misspecified F, one cannot in general argue for the superiority of the unhinged loss over square loss,
or vice-versa, as there is no universally good surrogate to the 0-1 loss [Reid and Williamson, 2010,
Appendix A]; the Appendix illustrate examples where both losses may underperform.

7

SLN-robustness of unhinged loss: empirical illustration

We now illustrate that the unhinged loss’ SLN-robustness is empirically manifest. We reiterate
that with high regularisation, the unhinged solution is equivalent to an SVM (and in the limit any
classification-calibrated loss) solution. Thus, we do not aim to assert that the unhinged loss is
“better” than other losses, but rather, to demonstrate that its SLN-robustness is not purely theoretical.
We first show that the unhinged risk minimiser performs well on the example of Long
and Servedio [2010] (henceforth LS10). Figure 1 shows the distribution D, where X =
{(1, 0), (γ, 5γ), (γ, −γ)} ⊂ R2 , with marginal distribution M = { 14 , 14 , 12 } and all three instances
are deterministically positive. We pick γ = 1/2. The unhinged minimiser perfectly classifies all
three points, regardless of the level of label noise (Figure 1). The hinge minimiser is perfect when
there is no noise, but with even a small amount of noise, achieves a 50% error rate.
4
5

Long and Servedio [2010, Section 6] show that `1 regularisation does not endow SLN-robustness.
Square loss escapes the result of Long and Servedio [2010] since it is not monotone decreasing.

7

1

Unhinged
Hinge 0% noise
Hinge 1% noise

0.5

0.5

ρ
ρ
ρ
ρ
ρ
ρ

1

−0.5

=
=
=
=
=
=

0
0.1
0.2
0.3
0.4
0.49

Hinge

t-logistic

Unhinged

0.00 ± 0.00
0.15 ± 0.27
0.21 ± 0.30
0.38 ± 0.37
0.42 ± 0.36
0.47 ± 0.38

0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.22 ± 0.08
0.22 ± 0.08
0.39 ± 0.23

0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.34 ± 0.48

Table 1: Mean and standard deviation of the 01 error over 125 trials on LS10. Grayed cells
denote the best performer at that noise rate.

−1

Figure 1: LS10 dataset.

We next consider empirical risk minimisers from a random training sample: we construct a training
set of 800 instances, injected with varying levels of label noise, and evaluate classification performance on a test set of 1000 instances. We compare the hinge, t-logistic (for t = 2) [Ding and
Vishwanathan, 2010] and unhinged minimisers using a linear scorer without a bias term, and regularisation strength λ = 10−16 . From Table 1, even at 40% label noise, the unhinged classifier is able
to find a perfect solution. By contrast, both other losses suffer at even moderate noise rates.
We next report results on some UCI datasets, where we additionally tune a threshold so as to ensure
the best training set 0-1 accuracy. Table 2 summarises results on a sample of four datasets. (The
Appendix contains results with more datasets, performance metrics, and losses.) Even at noise close
to 50%, the unhinged loss is often able to learn a classifier with some discriminative power.

ρ
ρ
ρ
ρ
ρ
ρ

=
=
=
=
=
=

0
0.1
0.2
0.3
0.4
0.49

Hinge

t-Logistic

Unhinged

0.00 ± 0.00
0.01 ± 0.03
0.06 ± 0.12
0.17 ± 0.20
0.35 ± 0.24
0.60 ± 0.20

0.00 ± 0.00
0.01 ± 0.03
0.04 ± 0.05
0.09 ± 0.11
0.24 ± 0.16
0.49 ± 0.20

0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.01
0.02 ± 0.07
0.13 ± 0.22
0.45 ± 0.33

ρ
ρ
ρ
ρ
ρ
ρ

=
=
=
=
=
=

0
0.1
0.2
0.3
0.4
0.49

Hinge

t-Logistic

Unhinged

0.05 ± 0.00
0.06 ± 0.01
0.06 ± 0.01
0.08 ± 0.04
0.14 ± 0.10
0.45 ± 0.26

0.05 ± 0.00
0.07 ± 0.02
0.08 ± 0.03
0.11 ± 0.05
0.24 ± 0.13
0.49 ± 0.16

0.05 ± 0.00
0.05 ± 0.00
0.05 ± 0.00
0.05 ± 0.01
0.09 ± 0.10
0.46 ± 0.30

(a) iris.

ρ
ρ
ρ
ρ
ρ
ρ

=
=
=
=
=
=

0
0.1
0.2
0.3
0.4
0.49

(b) housing.

Hinge

t-Logistic

Unhinged

0.00 ± 0.00
0.10 ± 0.08
0.19 ± 0.11
0.31 ± 0.13
0.39 ± 0.13
0.50 ± 0.16

0.00 ± 0.00
0.11 ± 0.02
0.15 ± 0.02
0.22 ± 0.03
0.33 ± 0.04
0.48 ± 0.04

0.00 ± 0.00
0.00 ± 0.00
0.00 ± 0.00
0.01 ± 0.00
0.02 ± 0.02
0.34 ± 0.21

ρ
ρ
ρ
ρ
ρ
ρ

(c) usps0v7.

=
=
=
=
=
=

0
0.1
0.2
0.3
0.4
0.49

Hinge

t-Logistic

Unhinged

0.05 ± 0.00
0.15 ± 0.03
0.21 ± 0.03
0.25 ± 0.03
0.31 ± 0.05
0.48 ± 0.09

0.04 ± 0.00
0.24 ± 0.00
0.24 ± 0.00
0.24 ± 0.00
0.24 ± 0.00
0.40 ± 0.24

0.19 ± 0.00
0.19 ± 0.01
0.19 ± 0.01
0.19 ± 0.03
0.22 ± 0.05
0.45 ± 0.08

(d) splice.

Table 2: Mean and standard deviation of the 0-1 error over 125 trials on UCI datasets.

8

Conclusion and future work

We proposed a convex, classification-calibrated loss, proved that is robust to symmetric label noise
(SLN-robust), showed it is the unique loss that satisfies a notion of strong SLN-robustness, established that it is optimised by the nearest centroid classifier, and showed that most convex potentials,
such as the SVM, are also SLN-robust when highly regularised. So, with apologies to Wilde [1895]:
While the truth is rarely pure, it can be simple.
Acknowledgments
NICTA is funded by the Australian Government through the Department of Communications and
the Australian Research Council through the ICT Centre of Excellence Program. The authors thank
Cheng Soon Ong for valuable comments on a draft of this paper.
8

References
Dana Angluin and Philip Laird. Learning from noisy examples. Machine Learning, 2(4):343–370, 1988.
Peter L. Bartlett, Michael I. Jordan, and Jon D. McAuliffe. Convexity, classification, and risk bounds. Journal
of the American Statistical Association, 101(473):138 – 156, 2006.
Christopher M Bishop. Pattern Recognition and Machine Learning. Springer-Verlag New York, Inc., 2006.
Avrim Blum and Tom Mitchell. Combining labeled and unlabeled data with co-training. In Conference on
Computational Learning Theory (COLT), pages 92–100, 1998.
Vasil Denchev, Nan Ding, Hartmut Neven, and S.V.N. Vishwanathan. Robust classification with adiabatic
quantum optimization. In International Conference on Machine Learning (ICML), pages 863–870, 2012.
Luc Devroye, László Györfi, and Gábor Lugosi. A Probabilistic Theory of Pattern Recognition. Springer, 1996.
Nan Ding and S.V.N. Vishwanathan. t-logistic regression. In Advances in Neural Information Processing
Systems (NIPS), pages 514–522. Curran Associates, Inc., 2010.
Thomas S. Ferguson. Mathematical Statistics: A Decision Theoretic Approach. Academic Press, 1967.
Aritra Ghosh, Naresh Manwani, and P. S. Sastry. Making risk minimization tolerant to label noise. Neurocomputing, 160:93 – 107, 2015.
Trevor Hastie, Saharon Rosset, Robert Tibshirani, and Ji Zhu. The entire regularization path for the support
vector machine. Journal of Machine Learning Research, 5:1391–1415, December 2004. ISSN 1532-4435.
Michael Kearns. Efficient noise-tolerant learning from statistical queries. Journal of the ACM, 5(6):392–401,
November 1998.
Philip M. Long and Rocco A. Servedio. Random classification noise defeats all convex potential boosters.
Machine Learning, 78(3):287–304, 2010. ISSN 0885-6125.
Christopher D. Manning, Prabhakar Raghavan, and Hinrich Schütze. Introduction to Information Retrieval.
Cambridge University Press, New York, NY, USA, 2008. ISBN 0521865719, 9780521865715.
Naresh Manwani and P. S. Sastry. Noise tolerance under risk minimization. IEEE Transactions on Cybernetics,
43(3):1146–1151, June 2013.
Hamed Masnadi-Shirazi, Vijay Mahadevan, and Nuno Vasconcelos. On the design of robust classifiers for
computer vision. In IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 2010.
Nagarajan Natarajan, Inderjit S. Dhillon, Pradeep D. Ravikumar, and Ambuj Tewari. Learning with noisy
labels. In Advances in Neural Information Processing Systems (NIPS), pages 1196–1204, 2013.
Ali Rahimi and Benjamin Recht. Random features for large-scale kernel machines. In Advances in Neural
Information Processing Systems (NIPS), pages 1177–1184, 2007.
Mark D. Reid and Robert C. Williamson. Composite binary losses. Journal of Machine Learning Research,
11:2387–2422, December 2010.
Mark D Reid and Robert C Williamson. Information, divergence and risk for binary experiments. Journal of
Machine Learning Research, 12:731–817, Mar 2011.
Bernhard Schölkopf and Alexander J Smola. Learning with kernels, volume 129. MIT Press, 2002.
Rocco A. Servedio. On PAC learning using Winnow, Perceptron, and a Perceptron-like algorithm. In Conference on Computational Learning Theory (COLT), 1999.
John Shawe-Taylor and Nello Cristianini. Kernel Methods for Pattern Analysis. Cambridge Uni. Press, 2004.
Alex Smola, Arthur Gretton, Le Song, and Bernhard Schölkopf. A Hilbert space embedding for distributions.
In Algorithmic Learning Theory (ALT), 2007.
Bharath K. Sriperumbudur, Kenji Fukumizu, Arthur Gretton, Gert R. G. Lanckriet, and Bernhard Schölkopf.
Kernel choice and classifiability for RKHS embeddings of probability distributions. In Advances in Neural
Information Processing Systems (NIPS), 2009.
Guillaume Stempfel and Liva Ralaivola. Learning SVMs from sloppily labeled data. In Artificial Neural
Networks (ICANN), volume 5768, pages 884–893. Springer Berlin Heidelberg, 2009.
Robert Tibshirani, Trevor Hastie, Balasubramanian Narasimhan, and Gilbert Chu. Diagnosis of multiple cancer
types by shrunken centroids of gene expression. Proceedings of the National Academy of Sciences, 99(10):
6567–6572, 2002.
Oscar Wilde. The Importance of Being Earnest, 1895.

9

",convex potenti minimis de facto approach binari classif howev long servedio [ ] prove symmetr label nois sln minimis convex potenti linear function class result classif perform equival random guess ostens show convex loss slnrobust paper propos convex classificationcalibrat loss prove slnrobust loss avoid long servedio [ ] result virtu neg unbound loss modif hing loss one clamp zero henc call unhing loss show optim unhing solut equival strongli regularis svm limit solut convex potenti impli strong l regularis make standard learner slnrobust experi confirm unhing loss slnrobust,learn symmetr label nois import unhing brendan van rooyen aditya krishna menon australian nation univers robert c williamson nation ict australia brendan vanrooyen aditya menon bob williamson nicta com au abstract convex potenti minimis de facto approach binari classif howev long servedio [ ] prove symmetr label nois sln minimis convex potenti linear function class result classif perform equival random guess ostens show convex loss slnrobust paper propos convex classificationcalibrat loss prove slnrobust loss avoid long servedio [ ] result virtu neg unbound loss modif hing loss one clamp zero henc call unhing loss show optim unhing solut equival strongli regularis svm limit solut convex potenti impli strong ` regularis make standard learner slnrobust experi confirm unhing loss slnrobust bear practic apolog wild [ ] truth rare pure simpl learn symmetr label nois binari classif canon supervis learn problem give instanc space x sampl distribut x goal learn scorer x r low misclassif error futur sampl draw interest realist scenario learner observ sampl corrupt label constant probabl flip goal still perform well respect problem know learn symmetr label nois sln learn [ angluin laird ] long servedio [ ] show exist linearli separ learner observ corrupt symmetr label nois nonzero rate minimis convex potenti linear function class result classif perform equival random guess ostens establish convex loss slnrobust motiv use nonconvex loss [ stempfel ralaivola masnadishirazi et al d vishwanathan denchev et al manwani sastri ] paper propos convex loss prove slnrobust loss avoid result long servedio [ ] virtu neg unbound loss modif hing loss one clamp zero thu call unhing loss loss sever appeal properti uniqu convex loss satisfi notion strong slnrobust proposit classificationcalibrat proposit consist minimis proposit simpl optim solut differ two kernel mean equat final show optim solut equival strongli regularis svm proposit twicedifferenti convex potenti proposit impli strong ` regularis endow standard learner slnrobust classifi result minimis unhing loss new [ devroy et al chapter ] [ scholkopf smola section ] [ shawetaylor cristianini section ] howev establish classifi strong slnrobust uniqu thereof equival highli regularis svm solut knowledg novel background problem setup fix instanc space x denot distribut x random variabl x may express via classcondit p q p x p x base rate p via margin p x classprob function x p x x interchang write dpq dm classifi scorer risk scorer function x r loss function ` r r use ` ` refer ` ` ` condit risk l ` [ ] r r defin l ` v ` v ` v give distribut ` risk scorer defin ld ` [ ` x ] e xy ld ` e [ l ` x x ] set l ` set ` risk scorer xm function class f rx give f set restrict bayesoptim scorer loss ` scorer f minimis ` risk sdf argmin ld ` ` sf set unrestrict bayesoptim scorer sd sdf f rx restrict ` ` ` regret scorer excess risk restrict bayesoptim scorer regretdf ld ` inf l ` ` tf binari classif concern zeroon loss ` v jyv k jv k loss ` classificationcalibrat bayesoptim scorer also optim zeroon loss sd sd convex potenti loss ` v yv r r ` convex nonincreas differenti [ long servedio definit ] convex potenti classificationcalibrat [ bartlett et al theorem ] learn symmetr label nois sln learn problem learn symmetr label nois sln learn follow [ angluin laird kearn blum mitchel natarajan et al ] notion clean distribut would like observ instead observ sampl corrupt distribut sln [ distribut sln margin distribut instanc unchang label independ flip probabl goal learn scorer corrupt sampl ld small quantiti denot corrupt counterpart sln bar e g corrupt margin distribut corrupt classprob function addit clear context occasion refer sln easi check corrupt margin distribut [ natarajan et al lemma ] x x x x slnrobust formalis consid learner ` f loss ` function class f learn search f minimi ` risk inform ` f robust symmetr label nois slnrobust minimis ` f give classifi clean distribut learner would like observ sln [ learner actual observ formalis notion review know slnrobust learner slnrobust learner formal definit fix instanc space x let denot set distribut x give notion clean distribut nsln return set possibl corrupt version learner may observ label flip unknown probabl nsln sln equip defin notion slnrobust definit slnrobust say learner ` f slnrobust df df nsln ld ld ` ` slnrobust requir level label nois observ distribut classif perform wrt learner learner directli observ unfortun wide adopt class learner slnrobust see convex potenti linear function class slnrobust fix x rd consid learner convex potenti ` function class linear scorer flin x hw xi w rd captur e g linear svm logist regress wide studi theori appli practic disappointingli learner slnrobust long servedio [ theorem ] give exampl learn symmetr label nois convex potenti ` corrupt ` risk minimis flin classif perform equival random guess impli ` flin slnrobust per definit proposit long servedio [ theorem ] let x rd pick convex potenti ` ` flin slnrobust fallout learner slnrobust light proposit two way proceed order obtain slnrobust learner either chang class loss ` chang function class f first approach pursu larg bodi work embrac nonconvex loss [ stempfel ralaivola masnadishirazi et al d vishwanathan denchev et al manwani sastri ] loss avoid condit proposit automat impli slnrobust use flin appendix b present evid loss fact slnrobust use flin second approach consid suitabl rich f contain bayesoptim scorer e g employ univers kernel choic one still use convex potenti loss fact owe equat classificationcalibrat loss proposit pick classificationcalibrat ` ` rx slnrobust approach drawback first approach comput penalti requir optimis nonconvex loss second approach statist penalti estim rate rich f requir larg sampl size thu appear slnrobust involv computationalstatist tradeoff howev variant first option pick loss convex convex potenti loss would afford comput statist advantag minimis convex risk linear scorer manwani sastri [ ] demonstr squar loss ` v yv one loss show simpl loss convex slnrobust class convex potenti virtu neg unbound deriv loss first reinterpret robust via noisecorrect procedur even content differ [ ] clean corrupt minimis perform long servedio [ theorem ] impli bad case noisecorrect loss perspect slnrobust reexpress slnrobust reason optim scorer distribut two differ loss help characteris set strongli slnrobust loss reformul slnrobust via noisecorrect loss give [ natarajan et al [ lemma ] show associ loss ` noisecorrect counterpart ` ld ` l ` loss ` defin follow definit noisecorrect loss give loss ` [ noisecorrect loss ` v r ` v ` v ` v sinc ` depend unknown paramet directli usabl design slnrobust learner nonetheless use theoret devic sinc construct f sdf ` sdf sdf mean suffici condit ` f slnrobust sdf ` ` ` ghosh et al [ theorem ] prove suffici condit ` hold name c r v r ` v ` v c interestingli equat necessari strong notion robust explor characteris strong notion slnrobust first step toward strong notion robust rewrit slight abus notat ld ` e xy [ ` x ] e ys r ds [ ` ] l ` r r distribut label score standard slnrobust requir label nois chang ` risk minimis e l ` r l ` r relat hold place strong slnrobust strengthen notion requir label nois affect order pair joint distribut label score cours trivial impli slnrobust definit give distribut r label score let r correspond distribut label flip probabl strong slnrobust make precis follow definit strong slnrobust call loss ` strongli slnrobust everi [ r r l ` r l ` r l ` r l ` r reexpress strong slnrobust use notion order equival loss pair simpli requir two loss order distribut label score ident order equival definit order equival loss pair call pair loss ` ` r r l ` r l ` r l ` r l ` r clearli order equival ` ` impli sdf sdf turn impli slnrobust ` ` thu surpris relat order equival strong slnrobust ` proposit loss ` strongli slnrobust iff everi [ ` ` order equival connect let us exploit classic result decis theori order equival loss affin transform combin definit ` let us conclud suffici condit equat also necessari strong slnrobust ` proposit loss ` strongli slnrobust satisfi equat return origin goal find convex ` slnrobust flin ideal gener function class suggest reason consid loss satisfi equat unfortun evid ` convex nonconst bound zero can not possibl admiss sens show remov bounded restrict allow exist convex admiss loss unhing loss convex strongli slnrobust loss consid follow simpl nonstandard convex loss unh ` unh v v ` v v compar hing loss loss clamp zero e hing thu peculiarli neg unbound issu discuss thu call unhing loss loss number attract properti immedi slnrobust unhing loss strongli slnrobust unh unh sinc ` unh strongli slnrobust thu v ` v proposit impli ` unh ` f slnrobust f follow uniqu properti hard show proposit pick convex loss ` c r ` v ` v c b r ` v v b ` v v scale translat ` unh convex loss strongli slnrobust return case linear scorer impli ` unh flin slnrobust contradict proposit sinc ` unh convex potenti neg unbound intuit properti allow loss offset penalti incur instanc misclassifi high margin award gain instanc correctli classifi high margin unhing loss classif calibr slnrobust insuffici learner use exampl loss uniformli zero strongli slnrobust useless classificationcalibrat fortun unhing loss classificationcalibrat establish technic reason see oper fb [ b b ] x set scorer rang bound b [ proposit fix ` ` unh dm b [ ` dfb x b sign x thu everi b [ restrict bayesoptim scorer fb sign bayesoptim classifi loss limit case f rx optim scorer attain oper extend real r ` unh classificationcalibrat enforc bounded loss classificationcalibr ` unh encourag proposit impli unrestrict bayesrisk thu regret everi nonoptim scorer ident hamper analysi consist orthodox decis theori analog theoret issu aris attempt establish basic theorem unbound loss [ ferguson pg ] sidestep issu restrict attent bound scorer ` unh effect bound proposit affect classificationcalibr loss context linear scorer bounded scorer achiev regularis instead work e flin one instead use flin x hw xi w flin fr r supxx x observ ` unh f slnrobust f ` unh flin slnrobust shall see work flin also let us establish slnrobust hing loss larg unhing loss minimis corrupt distribut consist use bound scorer make possibl establish surrog regret bind unhing loss show classif consist unhing loss minimis corrupt distribut loss consid sriperumbudur et al [ ] reid williamson [ ] context maximum mean discrep see appendix analysi slnrobust knowledg novel proposit fix ` ` unh [ b [ scorer fb dfb regretd regret ` dfb regret ` standard rate converg via generalis bound also trivial deriv see appendix learn unhing loss kernel show optim solut unhing loss employ regularis kern scorer simpl form shed light slnrobust regularis centroid classifi optimi unhing loss consid minimis unhing risk class kern scorer fh x hw x ih w h x h featur map reproduc kernel hilbert space h kernel k equival give distribut want wunh argmin e [ hw x ] hw wih xy wh firstord optim condit impli wunh e [ x ] xy kernel mean map [ smola et al ] thu optim unhing scorer sunh x e [ k x x ] x e [ k x x ] e [ k x x ] xp xq xy equat unhing solut equival near centroid classifi [ man et al pg ] [ tibshirani et al ] [ shawetaylor cristianini section ] equat give simpl way understand slnrobust ` unh fh optim scorer clean corrupt distribut differ scale see appendix e k x x x x e [ k x x ] xy xy interestingli servedio [ theorem ] establish near centroid classifi term averag robust gener class label nois requir assumpt uniform unit sphere result establish sln robust classifi hold without assumpt fact ghosh et al [ theorem ] let one quantifi unhing loss perform gener nois model see appendix discuss practic consider note sever point relat practic usag unhing loss kern scorer first crossvalid requir select sinc chang chang magnitud score sign thu purpos classif one simpli use second easili extend scorer use bia regularis strength b tune b equival comput sunh per equat tune threshold holdout set third h rd small store wunh explicitli use make predict high infinit dimension h either make predict directli via equat use random fourier featur [ rahimi recht ] approxim emb h low dimension rd store wunh usual latter requir translationinvari kernel show assumpt wunh coincid solut two establish method appendix discuss relationship e g maximum mean discrep give train sampl dn use plugin estim appropri equival highli regularis svm convex potenti interest equival unhing solut highli regularis svm note e g hasti et al [ section ] show svm approach nearest centroid classifi cours optim unhing solut proposit pick x h r supxx x h let whing argmin wh e xy [ max hw x ih ] hw wih softmargin svm solut r whing wunh sinc ` unh fh slnrobust follow ` hing v max yv ` hing fh similarli slnrobust provid suffici larg strong ` regularis bound featur map endow hing loss slnrobust proposit generalis show wunh limit solut twice differenti convex potenti show strong ` regularis endow learner slnrobust intuit strong regularis one consid behaviour loss near zero sinc convex potenti behav similarli linear approxim around zero viz unhing loss proposit pick bound featur map x h twice differenti convex potenti [ ] bound let w minimis regularis risk w wunh lim w h wunh h h equival fisher linear discrimin whiten datum binari classif dm fisher linear discrimin fld find weight vector proport minimis squar loss ` sq v yv [ bishop section ] wsq exm [ xxt ] e xy [ x ] wsq chang scale equat fact corrupt margin factor label nois provid altern proof fact ` sq flin slnrobust [ manwani sastri theorem ] clearli unhing loss solut wunh equival fld squar loss solut wsq input datum whiten e e xx xm wellspecifi f e g univers kernel unhing squar loss asymptot recov optim classifi unhing loss requir matrix invers misspecifi f one can not gener argu superior unhing loss squar loss viceversa univers good surrog loss [ reid williamson appendix ] appendix illustr exampl loss may underperform slnrobust unhing loss empir illustr illustr unhing loss slnrobust empir manifest reiter high regularis unhing solut equival svm limit classificationcalibrat loss solut thu aim assert unhing loss good loss rather demonstr slnrobust pure theoret first show unhing risk minimis perform well exampl long servedio [ ] henceforth ls figur show distribut x r margin distribut three instanc determinist posit pick unhing minimis perfectli classifi three point regardless level label nois figur hing minimis perfect nois even small amount nois achiev error rate long servedio [ section ] show ` regularis endow slnrobust squar loss escap result long servedio [ ] sinc monoton decreas unhing hing nois hing nois hing tlogist unhing tabl mean standard deviat error trial ls gray cell denot good perform nois rate figur ls dataset next consid empir risk minimis random train sampl construct train set instanc inject vari level label nois evalu classif perform test set instanc compar hing tlogist [ d vishwanathan ] unhing minimis use linear scorer without bia term regularis strength tabl even label nois unhing classifi abl find perfect solut contrast loss suffer even moder nois rate next report result uci dataset addit tune threshold ensur good train set accuraci tabl summari result sampl four dataset appendix contain result dataset perform metric loss even nois close unhing loss often abl learn classifi discrimin power hing tlogist unhing hing tlogist unhing iri b hous hing tlogist unhing c uspsv hing tlogist unhing splice tabl mean standard deviat error trial uci dataset conclus futur work propos convex classificationcalibrat loss prove robust symmetr label nois slnrobust show uniqu loss satisfi notion strong slnrobust establish optimis near centroid classifi show convex potenti svm also slnrobust highli regularis apolog wild [ ] truth rare pure simpl acknowledg nicta fund australian govern depart commun australian research council ict centr excel program author thank cheng soon ong valuabl comment draft paper refer dana angluin philip laird learn noisi exampl machin learn peter l bartlett michael jordan jon mcauliff convex classif risk bound journal american statist associ christoph bishop pattern recognit machin learn springerverlag new york inc avrim blum tom mitchel combin label unlabel datum cotrain confer comput learn theori colt page vasil denchev nan d hartmut neven v n vishwanathan robust classif adiabat quantum optim intern confer machin learn icml page luc devroy laszlo gyorfi gabor lugosi probabilist theori pattern recognit springer nan d v n vishwanathan tlogist regress advanc neural inform process system nip page curran associ inc thoma ferguson mathemat statist decis theoret approach academ press aritra ghosh naresh manwani p sastri make risk minim toler label nois neurocomput trevor hasti saharon rosset robert tibshirani ji zhu entir regular path support vector machin journal machin learn research decemb issn michael kearn effici noisetoler learn statist queri journal acm novemb philip long rocco servedio random classif nois defeat convex potenti booster machin learn issn christoph man prabhakar raghavan hinrich schutz introduct inform retriev cambridg univers press new york ny usa isbn naresh manwani p sastri nois toler risk minim ieee transact cybernet june ham masnadishirazi vijay mahadevan nuno vasconcelo design robust classifi comput vision ieee confer comput vision pattern recognit cvpr nagarajan natarajan inderjit dhillon pradeep ravikumar ambuj tewari learn noisi label advanc neural inform process system nip page ali rahimi benjamin recht random featur largescal kernel machin advanc neural inform process system nip page mark reid robert c williamson composit binari loss journal machin learn research decemb mark reid robert c williamson inform diverg risk binari experi journal machin learn research mar bernhard scholkopf alexand j smola learn kernel volum mit press rocco servedio pac learn use winnow perceptron perceptronlik algorithm confer comput learn theori colt john shawetaylor nello cristianini kernel method pattern analysi cambridg uni press alex smola arthur gretton le song bernhard scholkopf hilbert space embed distribut algorithm learn theori alt bharath k sriperumbudur kenji fukumizu arthur gretton gert r g lanckriet bernhard scholkopf kernel choic classifi rkh embed probabl distribut advanc neural inform process system nip guillaum stempfel liva ralaivola learn svm sloppili label datum artifici neural network icann volum page springer berlin heidelberg robert tibshirani trevor hasti balasubramanian narasimhan gilbert chu diagnosi multipl cancer type shrunken centroid gene express proceed nation academi scienc oscar wild import earnest
2,6019,Algorithmic Stability and Uniform Generalization,Poster,6019-algorithmic-stability-and-uniform-generalization.pdf,"One of the central questions in statistical learning theory is to determine the conditions under which agents can learn from experience. This includes the necessary and sufficient conditions for generalization from a given finite training set to new observations. In this paper, we prove that algorithmic stability in the inference process is equivalent to uniform generalization across all parametric loss functions. We provide various interpretations of this result.  For instance,  a relationship is proved between stability and data processing, which reveals that algorithmic stability can be improved by post-processing the inferred hypothesis or by augmenting training examples with artificial noise prior to learning. In addition, we establish a relationship between algorithmic stability and the size of the observation space, which provides a formal justification for dimensionality reduction methods. Finally, we connect algorithmic stability to the size of the hypothesis space, which recovers the classical PAC result that the size (complexity) of the hypothesis space should be controlled in order to improve algorithmic stability and improve generalization.","Algorithmic Stability and Uniform Generalization

Ibrahim Alabdulmohsin
King Abdullah University of Science and Technology
Thuwal 23955, Saudi Arabia
ibrahim.alabdulmohsin@kaust.edu.sa

Abstract
One of the central questions in statistical learning theory is to determine the conditions under which agents can learn from experience. This includes the necessary and sufficient conditions for generalization from a given finite training set
to new observations. In this paper, we prove that algorithmic stability in the inference process is equivalent to uniform generalization across all parametric loss
functions. We provide various interpretations of this result. For instance, a relationship is proved between stability and data processing, which reveals that algorithmic stability can be improved by post-processing the inferred hypothesis or by
augmenting training examples with artificial noise prior to learning. In addition,
we establish a relationship between algorithmic stability and the size of the observation space, which provides a formal justification for dimensionality reduction
methods. Finally, we connect algorithmic stability to the size of the hypothesis
space, which recovers the classical PAC result that the size (complexity) of the
hypothesis space should be controlled in order to improve algorithmic stability
and improve generalization.

1

Introduction

One fundamental goal of any learning algorithm is to strike a right balance between underfitting
and overfitting. In mathematical terms, this is often translated into two separate objectives. First,
we would like the learning algorithm to produce a hypothesis that is reasonably consistent with the
empirical evidence (i.e. to have a small empirical risk). Second, we would like to guarantee that the
empirical risk (training error) is a valid estimate of the true unknown risk (test error). The former
condition protects against underfitting while the latter condition protects against overfitting.
The rationale behind these two objectives can be understood if we define the generalization
risk

. 
Rgen by the absolute difference between the empirical and true risks: Rgen = Remp − Rtrue .
Then, it is elementary to observe that the true risk Rtrue is bounded from above by the sum
Remp + Rgen . Hence, by minimizing both the empirical risk (underfitting) and the generalization
risk (overfitting), one obtains an inference procedure whose true risk is minimal.
Minimizing the empirical risk alone can be carried out using the empirical risk minimization (ERM)
procedure [1] or some approximations to it. However, the generalization risk is often impossible to
deal with directly. Instead, it is a common practice to bound it analyticaly so that we can establish
conditions under which it is guaranteed to be small. By establishing conditions for generalization,
one hopes to design better learning algorithms that both perform well empirically and generalize
well to novel observations in the future. A prominent example of such an approach is the Support
Vector Machines (SVM) algorithm for binary classification [2].
However, bounding the generalization risk is quite intricate because it can be approached from
various angles. In fact, several methods have been proposed in the past to prove generalization bounds including uniform convergence, algorithmic stability, Rademacher and Gaussian complexities, generic chaining bounds, the PAC-Bayesian framework, and robustness-based analysis
1

[1, 3, 4, 5, 6, 7, 8, 9]. Concentration of measure inequalities form the building blocks of these rich
theories.
The proliferation of generalization bounds can be understood if we look into the general setting of
learning introduced by Vapnik [1]. In this setting, we have an observation space Z and a hypothesis
m
space H. A learning algorithm, henceforth denoted L : ∪∞
→ H, uses a finite set of
m=1 Z
observations to infer a hypothesis H ∈ H. In the general setting, the inference process end-to-end
is influenced by three key factors: (1) the nature of the observation space Z, (2) the nature of the
hypothesis space H, and (3) the details of the learning algorithm L. By imposing constraints on
any of these three components, one may be able to derive new generalization bounds. For example,
the Vapnik-Chervonenkis (VC) theory derives generalization bounds by assuming constraints on H,
while stability bounds, e.g. [6, 10, 11, 12], are derived by assuming constraints on L.
Given that different generalization bounds can be established by imposing constraints on any of
Z, H, or L, it is intriguing to ask if there exists a single view for generalization that ties all of these
different components together. In this paper, we answer this question in the affirmative by establishing that algorithmic stability alone is equivalent to uniform generalization. Informally speaking, an
inference process is said to generalize uniformly if the generalization risk vanishes uniformly across
all bounded parametric loss functions at the limit of large training sets. A more precise definition
will be presented in the sequel. We will show why constraints that are imposed on either H, Z, or
L to improve uniform generalization can be interpreted as methods of improving the stability of the
learning algorithm L. This is similar in spirit to a result by Kearns and Ron, who showed that having a finite VC dimension in the hypothesis space H implies a certain notion of algorithmic stability
in the inference process [13]. Our statement, however, is more general as it applies to all learning
algorithms that fall under Vapnik’s general setting of learning, well beyond uniform convergence.
The rest of the paper is as follows. First, we review the current literature on algorithmic stability,
generalization, and learnability. Then, we introduce key definitions that will be repeatedly used
throughout the paper. Next, we prove the central theorem, which reveals that algorithmic stability is
equivalent to uniform generalization, and provide various interpretations of this result afterward.

2

Related Work

Perhaps, the two most fundamental concepts in statistical learning theory are those of learnability
and generalization [12, 14]. The two concepts are distinct from each other. As will be discussed
in more details next, whereas learnability is concerned with measuring the excess risk within a
hypothesis space, generalization is concerned with estimating the true risk.
In order to define learnability and generalization, suppose we have an observation space Z, a probability distribution of observations P(z), and a bounded stochastic loss function L(·; H) : Z →
[0, 1], where H ∈ H is an inferred hypothesis. Note that L is implicitly a function of (parameterized by) H as well. We define the true risk of a hypothesis H ∈ H by the risk functional:


Rtrue (H) = EZ∼P(z) L(Z; H)
(1)
Then, a learning algorithm is called consistent if the true risk of its inferred hypothesis H converges
to the optimal true risk within the hypothesis space H at the limit of large training sets m → ∞.
A problem is called learnable if it admits a consistent learning algorithm [14]. It has been known
that learnability for supervised classification and regression problems is equivalent to uniform convergence [3, 14]. However, Shalev-Shwartz et al. recently showed that uniform convergence is not
necessary in Vapnik’s general setting of learning and proposed algorithmic stability as an alternative
key condition for learnability [14].
Unlike learnability, the question of generalization is concerned primarily with how representative
the empirical risk Remp is to the true risk Rtrue . To elaborate, suppose we have a finite training set
Sm = {Zi }i=1,..,m , which comprises of m i.i.d. observations Zi ∼ P(z). We define the empirical
risk of a hypothesis H with respect to Sm by:
1 X
Remp (H; Sm ) =
L(Zi ; H)
(2)
m
Zi ∈Sm

We also let Rtrue (H) be the true risk as defined in Eq. (1). Then, a learning algorithm L is said to
generalize if the empirical risk of its inferred hypothesis converges to its true risk as m → ∞.
2

Similar to learnability, uniform convergence is, by definition, sufficient for generalization [1], but
it is not necessary because the learning algorithm can always restrict its search space to a smaller
subset of H (artificially so to speak). By contrast, it is not known whether algorithmic stability is
necessary for generalization. It has been shown that various notions of algorithmic stability can be
defined that are sufficient for generalization [6, 10, 11, 12, 15, 16]. However, it is not known whether
an appropriate notion of algorithmic stability can be defined that is both necessary and sufficient for
generalization in Vapnik’s general setting of learning. In this paper, we answer this question by
showing that stability in the inference process is not only sufficient for generalization, but it is, in
fact, equivalent to uniform generalization, which is a notion of generalization that is stronger than
the one traditionally considered in the literature.

3

Preliminaries

To simplify the discussion, we will always assume that all sets are countable, including the observation space Z and the hypothesis space H. This is similar to the assumptions used in some previous
works such as [6]. However, the main results, which are presented in Section 4, can be readily
generalized. In addition, we assume that all learning algorithms are invariant to permutations of the
training set. Hence, the order of training examples is irrelevant.
Moreover, if X ∼ P(x) is a random variable
drawn from the alphabet X and f (X) is a function of
P
X, we write EX∼P(x) f (X) to mean x∈X P(x) f (x). Often, we will simply write EX f (X) to
mean EX∼P(x) f (X) if the distribution of X is clear from the context. If X takes its values from
a finite set S uniformly at random, we write X ∼ S to denote this distribution of X. If X is a
boolean random variable, then I{X} = 1 if and only if X is true, otherwise I{X} = 0. In general,
random variables are denoted with capital letters, instances of random variables are denoted with
small letters, and alphabets are denoted with calligraphic typeface. Also, given two probability mass
functions P and Q defined on the same alphabet A, we will write hP,
Qi to denote the overlapping
. P
coefficient, i.e. intersection, between P and Q. That is, hP, Qi = a∈A min{P (a), Q(a)}. Note
that hP, Qi = 1− ||P , Q||T , where ||P , Q||T is the total variation distance. Last, we will write
B(k; φ, n) = nk φk (1 − φ)n−k to denote the binomial distribution.
In this paper, we consider the general setting of learning introduced by Vapnik [1]. To reiterate, we
have an observation space Z and a hypothesis space H. Our learning algorithm L receives a set of
m observations Sm = {Zi }i=1,..,m ∈ Z m generated i.i.d. from a fixed unknown distribution P(z),
m
and picks a hypothesis H ∈ H with probability PL (H = h|Sm ). Formally, L : ∪∞
→ H is a
m=1 Z
stochastic map. In this paper, we allow the hypothesis H to be any summary statistic of the training
set. It can be a measure of central tendency, as in unsupervised learning, or it can be a mapping from
an input space to an output space, as in supervised learning. In fact, we even allow H to be a subset
of the training set itself. In formal terms, L is a stochastic map between the two random variables
H ∈ H and Sm ∈ Z m , where the exact interpretation of those random variables is irrelevant.
In any learning task, we assume a non-negative bounded loss function L(Z; H) : Z → [0, 1] is
used to measure the quality of the inferred hypothesis H ∈ H on the observation Z ∈ Z. Most
importantly, we assume that L(·; H) : Z → [0, 1] is parametric:
Definition 1 (Parametric Loss Functions). A loss function L(·; H) : Z → [0, 1] is called parametric if it is independent of the training set Sm given the inferred hypothesis H. That is, a parametric
loss function satisfies the Markov chain: Sm → H → L(·; H).
For any fixed hypothesis H ∈ H, we define its true risk Rtrue (H) by Eq. (1), and define its
empirical risk on a training set Sm , denoted Remp (H; Sm ), by Eq. (2). We also define the true and
empirical risks of the learning algorithm L by the expected risk of its inferred hypothesis:
R̂true (L) = ESm EH ∼PL (h|Sm ) Rtrue (H)
= ESm EH|Sm Rtrue (H)
(3)
R̂emp (L) = ESm EH ∼PL (h|Sm ) Remp (H; Sm )

= ESm EH|Sm Remp (H; Sm )

(4)

To simplify notation, we will write R̂true and R̂emp instead of R̂true (L) and R̂emp (L). We will
consider the following definition of generalization:
m
Definition 2 (Generalization). A learning algorithm L : ∪∞
→ H with a parametric
m=1 Z
loss function L(·; H) :  Z → [0, 1] generalizes if for any distribution P(z) on Z, we have
limm→∞ |R̂emp − R̂true  = 0, where R̂true and R̂emp are given in Eq. (3) and Eq. (4) respectively.
3

In other words, a learning algorithm L generalizes according to Definition 2 if its empirical performance (training loss) becomes an unbiased estimator to the true risk as m → ∞. Next, we define
uniform generalization:
m
Definition 3 (Uniform Generalization). A learning algorithm L : ∪∞
→ H generalizes
m=1 Z
uniformly if for any  > 0, there exists m0 () > 0 such that for all distributions P(z) on Z, all
parametric loss functions, and all sample sizes m > m0 (), we have |R̂emp (L) − R̂true (L) ≤ .
Uniform generalization is stronger than the original notion of generalization in Definition 2. In
particular, if a learning algorithm generalizes uniformly, then it generalizes according to Definition
2 as well. The converse, however, is not true. Even though uniform generalization appears to be
quite a strong condition, at first sight, a key contribution of this paper is to show that it is not a strong
condition because it is equivalent to a simple condition, namely algorithmic stability.

4

Main Results

Before we prove that algorithmic stability is equivalent to uniform generalization, we introduce a
probabilistic notion of mutual stability between two random variables. In order to abstract away any
labeling information the random variables might possess, e.g. the observation space may or may not
be a metric space, we define stability by the impact of observations on probability distributions:
Definition 4 (Mutual Stability). Let X ∈ X and Y ∈ Y be two random variables. Then, the mutual
stability between X and Y is defined by:
.
S(X; Y ) = hP(X) P(Y ), P(X, Y )i = EX hP(Y ), P(Y |X)i = EY hP(X), P(X|Y )i
If we recall that 0 ≤ hP, Qi ≤ 1 is the overlapping coefficient between the two probability distributions P and Q, we see that S(X; Y ) given by Definition 4 is indeed a probabilistic measure
of mutual stability. It measures how stable the distribution of Y is before and after observing an
instance of X, and vice versa. A small value of S(X; Y ) means that the probability distribution of
X or Y is heavily perturbed by a single observation of the other random variable. Perfect mutual
stability is achieved when the two random variables are independent of each other.
With this probabilistic notion of mutual stability in mind, we define the stability of a learning algorithm L by the mutual stability between its inferred hypothesis and a random training example.
m
→ H be a learning algorithm that receives
Definition 5 (Algorithmic Stability). Let L : ∪∞
m=1 Z
a finite set of training examples Sm = {Zi }i=1,..,m ∈ Z m drawn i.i.d. from a fixed distribution
P(z). Let H ∼ PL (h|Sm ) be the hypothesis inferred by L, and let Ztrn ∼ Sm be a single random training example. We define the stability of L by: S(L) = inf P(z) S(H; Ztrn ), where the
infimum is taken over all possible distributions of observations P(z). A learning algorithm is called
algorithmically stable if limm→∞ S(L) = 1.
Note that the above definition of algorithmic stability is rather weak; it only requires that the contribution of any single training example on the overall inference process to be more and more negligible
as the sample size increases. In addition, it is well-defined even if the learning algorithm is deterministic because the hypothesis H, if it is a deterministic function of an entire training set of m
observations, remains a stochastic function of any individual observation. We illustrate this concept
with the following example:
Example 1. Suppose that observations Zi ∈ {0, 1} are i.i.d. Bernoulli P
trials with P(Zi = 1) = φ,
m
1
and that
the
hypothesis
produced
by
L
is
the
empirical
average
H
=
i=1 Zi . Because P(H =
m


k/m  Ztrn = 1) = B(k − 1; φ, m − 1) and P(H = k/m  Ztrn = 0) = B(k; φ, m − 1), it can be
shown using Stirling’s approximation [17] that the algorithmic stability of this learning algorithm
is asymptotically given by S(L) ∼ 1 − √21π m , which is achieved when φ = 1/2. A more general
statement will be proved later in Section 5.
Next, we show that the notion of algorithmic stability in Definition 5 is equivalent to the notion of
uniform generalization in Definition 3. Before we do that, we first state the following lemma.
Lemma 1 (Data Processing Inequality). Let A, B, and C be three random variables that satisfy the
Markov chain A → B → C. Then: S(A; B) ≤ S(A; C).
4

Proof. The proof consists of two steps 1 . First, we note that because the Markov chain implies that
P(C|B, A) = P(C|B), we have S(A; (B, C)) = S(A; B) by direct substitution into Definition
5. Second, similar to the information-cannot-hurt inequality in information theory [18], it can be
shown that S(A; (B, C)) ≤ S(A; C) for any random variables A, B and C. This is proved using
some algebraic manipulationand
minimum of the sums is always larger than the
	 theP
P the fact
P that
α
,
β
sum of minimums, i.e. min
≥
i i
i i
i min{αi , βi }. Combining both results yields
S(A; B) = S(A; (B, C)) ≤ S(A; C), which is the desired result.
Now, we are ready to state the main result of this paper.
m
Theorem 1. For any learning algorithm L : ∪∞
→ H, algorithmic stability as given in Defm=1 Z
inition
5
is
both
necessary
and
sufficient
for
uniform
generalization
(see Definition 3). In addition,


R̂true − R̂emp  ≤ 1 − S(H; Ztrn ) ≤ 1 − S(L), where Rtrue and Remp are the true and empirical
risks of the learning algorithm defined in Eq. (3) and (4) respectively.
Proof. Here is an outline of the proof. First, because a parametric loss function L(·; H) : Z → [0, 1]
is itself a random variable that satisfies the Markov chain Sm → H → L(·; H), it is not independent
of Ztrn ∼ Sm . Hence, the empirical risk is given by R̂emp = EL(·;H) EZtrn |L(·;H) L(Ztrn ; H). By
contrast, the true risk is given by R̂true = EL(·;H) EZtrn ∼P(z) L(Ztrn ; H). The difference is:


R̂true − R̂emp = EL(·;H) EZtrn L(Ztrn ; H) − EZtrn |L(·;H) L(Ztrn ; H)
To sandwich the right-hand side between an upper and a lower bound, we note that if P1 (z) and
P2 (z) are two distributions
defined on the same alphabet
Z and F (·) : Z → [0, 1] is a bounded loss




function, then EZ∼P1 (z) F (Z) − EZ∼P2 (z) F (Z) ≤ ||P1 (z) , P2 (z)||T , where ||P , Q||T is the
total variation distance. The proof to this result can be immediately deduced by considering the two
regions {z ∈ Z : P1 (z) > P2 (z)} and {z ∈ Z : P1 (z) < P2 (z)} separately. This is, then, used to
deduce the inequalities:


R̂true − R̂emp  ≤ 1 − S(L(·; H); Ztrn ) ≤ 1 − S(H; Ztrn ) ≤ 1 − S(L),
where the second inequality follows by the data processing inequality in Lemma 1, whereas the
last inequality follows by definition of algorithmic stability (see Definition
5). This
 proves that

if L is algorithmically stable, i.e. S(L) → 1 as m → ∞, then R̂true − R̂emp  converges to
zero uniformly across all parametric loss functions. Therefore, algorithmic stability is sufficient for
uniform generalization. The converse is proved by showing that for any
a bounded
 δ > 0, there exists

parametric loss and a distribution Pδ (z) such that 1 − S(L) − δ ≤ R̂true − R̂emp  ≤ 1 − S(L).
Therefore, algorithmic stability is also necessary for uniform generalization.

5

Interpreting Algorithmic Stability and Uniform Generalization

In this section, we provide several interpretations of algorithmic stability and uniform generalization.
In addition, we show how Theorem 1 recovers some classical results in learning theory.
5.1

Algorithmic Stability and Data Processing

The relationship between algorithmic stability and data processing is presented in Lemma 1. Given
the random variables A, B, and C and the Markov chain A → B → C, we always have S(A; B) ≤
S(A; C). This presents us with qualitative insights into the design of machine learning algorithms.
First, suppose we have two different hypotheses H1 and H2 . We will say that H2 contains less
informative than H1 if the Markov chain Sm → H1 → H2 holds. For example, if observations
Zi ∈ {0, 1} are Bernoulli trials, then H1 ∈ R can be the empirical average as given in Example 1
while H2 ∈ {0, 1} can be the label that occurs most often in the training set. Because H2 = I{H1 ≥
m/2}, the hypothesis H2 contains strictly less information about the original training set than H1 .
Formally, we have Sm → H1 → H2 . In this case, H2 enjoys a better uniform generalization bound
than H1 because of data-processing. Intuitively, we know that such a result should hold because H2
is less tied to the original training set than H1 . This brings us to the following remark.
1

Detailed proofs are available in the supplementary file.

5

Remark 1. We can improve the uniform generalization bound (or equivalently algorithmic stability)
of a learning algorithm by post-processing its inferred hypothesis H in a manner that is conditionally independent of the original training set given H.
Example 2. Post-processing hypotheses is a common technique used in machine learning. This
includes sparsifying the coefficient vector w ∈ Rd in linear methods, where wj is set to zero if it has
a small absolute magnitude. It also includes methods that have been proposed to reduce the number
of support vectors in SVM by exploiting linear dependence [19]. By the data processing inequality,
such methods improve algorithmic stability and uniform generalization.
Needless to mention, better generalization does not immediately translate into a smaller true risk.
This is because the empirical risk itself may increase when the inferred hypothesis is post-processed
independently of the original training set.
Second, if the Markov chain A → B → C holds, we also obtain S(A; C) ≥ S(B; C) by applying
the data processing inequality to the reverse Markov chain C → B → A. As a result, we can improve algorithmic stability by contaminating training examples with artificial noise prior to learning.
This is because if Ŝm is a perturbed version of a training set Sm , then Sm → Ŝm → H implies that
S(Ztrn ; H) ≥ S(Ẑtrn ; H), when Ztrn ∼ Sm and Ẑtrn ∼ Ŝm are random training examples drawn
uniformly at random from each training set respectively. This brings us to the following remark:
Remark 2. We can improve the algorithmic stability of a learning algorithm by introducing artificial
noise to training examples, and applying the learning algorithm on the perturbed training set.
Example 3. Corrupting training examples with artificial noise, such as the recent dropout method,
are popular techniques in neural networks to improve generalization [20]. By the data processing
inequality, such methods indeed improve algorithmic stability and uniform generalization.
5.2

Algorithmic Stability and the Size of the Observation Space

Next, we look into how the size of the observation space Z influences algorithmic stability. First,
we start with the following definition:
Definition 6 (Lazy Learning). A learning algorithm L is called lazy if its hypothesis H ∈ H is
mapped one-to-one with the training set Sm , i.e. the mapping H → Sm is injective.
A lazy learner is called lazy if its hypothesis is equivalent to the original training set in its information content. Hence, no learning actually takes place. One example is instance-based learning
when H = Sm . Despite their simple nature, lazy learners are useful in practice. They are useful
theoretical tools as well. In particular, because of the equivalence H ≡ Sm and the data processing
inequality, the algorithmic stability of a lazy learner provides a lower bound to the stability of any
possible learning algorithm. Therefore, we can relate algorithmic stability (uniform generalization)
to the size of the observation space by quantifying the algorithmic stability of lazy learners. Because
the size of Z is usually infinite, however, we introduce the following definition of effective set size.
Definition 7. In a countable space Z endowed with a probability mass function P(z), the effective
p
2
P
.
size of Z w.r.t. P(z) is defined by: Ess [Z; P(z)] = 1 +
P(z) (1 − P(z)) .
z∈Z
At one extreme, if P(z) is uniform over a finite alphabet Z, then Ess [Z; P(z)] = |Z|. At the
other extreme, if P(z) is a Kronecker delta distribution, then Ess [Z; P(z)] = 1. As proved next,
this notion of effective set size determines the rate of convergence of an empirical probability mass
function to its true distribution when the distance is measured in the total variation sense. As a result,
it allows us to relate algorithmic stability to a property of the observation space Z.
Theorem 2. Let Z be a countable space endowed with a probability mass function P(z). Let Sm
be a set of m i.i.d. samples Zi ∼ P(z). Define PSm (z) to be the empirical probability mass function
q induced by drawing samples uniformly at random from Sm . Then: ESm ||P(z), PSm (z)||T =
√
Ess [Z; P(z)]−1
+ o(1/ m), where 1 ≤ Ess [Z; P(z)] ≤ |Z| is the effective size of Z (see Def2πm
∞
m
inition
q 7). In addition, for any learning algorithm L : ∪m=1 Z → H, we have S(H; Ztrn ) ≥
√
P(z)]−1
1 − Ess [Z;
− o(1/ m), where the bound is achieved by lazy learners (see Definition 6)2 .
2πm
2

A special case of Theorem 2 was proved by de Moivre in the 1730s, who showed that the
pempirical mean of
i.i.d. Bernoulli trials with a probability of success φ converges to the true mean at a rate of 2φ(1 − φ)/(πm)

6

 m1 m2
m
Proof. Here is an outline of the proof. First, we know that P(Sm ) = m1 , m
p1 p2 · · · , where
,
...
2

·
1
· is the multinomial coefficient. Using the relation ||P, Q||T = 2 ||P − Q||1 , the multinomial
series, and De Moivre’s formula for the mean deviation of the binomial random variable [22], it can
be shown with some algebraic manipulations that:
1 X
m!
k
ESm ||P(z), PSm (z)||T =
(1 − pk )(1−pk )m p1+mp
k
m
(pk m)! ((1 − pk )m − 1)!
k=1,2,...

Using Stirling’s approximation to the factorial [17], we obtain the simple asymptotic expression:
r
r
X
1
2pk (1 − pk )
Ess [Z; P(z)] − 1
ESm ||P(z), PSm (z)||T ∼
=1−
,
2
πm
2πm
k=1,2,3,...

which is tight due to the tightness of the Stirling approximation. The rest of the theorem follows
from the Markov chain Sm → Sm → H, the data processing inequality, and Definition 6.
Corollary 1. Given the conditions of Theorem 2,q
if Z is in addition finite (i.e. |Z| < ∞), then for
√
any learning algorithm L, we have: S(L) ≥ 1 − |Z|−1
2πm − o(1/ m)
Proof. Because in a finite observation space Z, the maximum effective set size (see Definition 7) is
|Z|, which is attained at the uniform distribution P(z) = 1/|Z|.
Intuitively speaking, Theorem 2 and its corollary state that in order to guarantee good uniform
generalization for all possible learning algorithms, the number of observations must be sufficiently
large to cover the entire effective size of the observation space Z. Needless to mention, this is
difficult to achieve in practice so the algorithmic stability of machine learning algorithms must be
controlled in order to guarantee a good generalization from a few empirical observations. Similarly,
the uniform generalization bound can be improved by reducing the effective size of the observation
space, such as by using dimensionality reduction methods.
5.3

Algorithmic Stability and the Complexity of the Hypothesis Space

Finally, we look into the hypothesis space and how it influences algorithmic stability. First, we look
into the role of the size of the hypothesis space. This is formalized in the following theorem.
m
Theorem 3. Denote by H ∈ H the hypothesis inferred by a learning algorithm L : ∪∞
→
m=1 Z
H. Then, the following bound on algorithmic stability always holds:
r
r
H(H)
log |H|
≥1−
,
S(L) ≥ 1 −
2m
2m
where H is the Shannon entropy measured in nats (i.e. using natural logarithms).
Proof. The proof is information-theoretic. If we let I(X; Y ) be the mutual information between the
r.v.’s X and Y and let Sm = {Z1 , Z2 , . . . , Zm } be a random choice of a training set, we have:
m
hX
i h
i
I(Sm ; H) = H(Sm ) − H(Sm | H) =
H(Zi ) − H(Z1 |H) + H(Z2 |Z1 , H) + · · ·
i=1

Because conditioning reduces entropy, i.e. H(A|B) ≤ H(A) for any r.v.’s A and B, we have:
I(Sm ; H) ≥

m
X

[H(Zi ) − H(Zi | H)] = m [H(Ztrn ) − H(Ztrn | H)]

i=1

Therefore:
I(Ztrn ; H) ≤

I(Sm ; H)
m

(5)

on average. This is believed to be the first appearance of the square-root law in statistical inference in the
literature [21]. Because the effective set size of the Bernoulli distribution, according to Definition 7, is given
by 1 + 4φ(1 − φ), Theorem 2 agrees with, in fact generalizes, de Moivre’s result.

7

Next, we use Pinsker’s
q inequality [18], which states that for any probability distributions P and
D(P || Q)
Q: ||P , Q||T ≤
, where ||P , Q||T is total variation distance and D(P || Q) is
2
the Kullback-Leibler divergence measured in nats (i.e. using natural logarithms). If we recall
that S(Sm ; H) = 1 − ||P(Sm ) P(H) , P(Sm , H)||T while mutual information is I(Sm ; H) =
D(P(Sm , H) || P(Sm ) P(H)), we deduce from Pinsker’s inequality and Eq. (5):
S(Ztrn ; H) = 1 − ||P(Ztrn ) P(H) , P(Ztrn , H)||T
r
r
r
r
I(Ztrn ; H)
I(Sm ; H)
H(H)
log |H|
≥1−
≥1−
≥1−
≥1−
2
2m
2m
2m
In the last line, we used the fact that I(X; Y ) ≤ H(X) for any random variables X and Y .
Theorem 3 re-establishes the classical PAC result on the finite hypothesis space [23]. In terms of
algorithmic stability, a learning algorithm will enjoy a high stability if the size of the hypothesis
space is small. In terms of uniform generalization, it states that the generalizationp
risk of a learning
algorithm
is
bounded
from
above
uniformly
across
all
parametric
loss
functions
by
H(H)/(2m) ≤
p
log |H|/(2m), where H(H) is the Shannon entropy of H.
Next, we relate algorithmic stability to the Vapnik-Chervonenkis (VC) dimension. Despite the fact
that the VC dimension is defined on binary-valued functions whereas algorithmic stability is a functional of probability distributions, there exists a connection between the two concepts. To show this,
we first introduce a notion of an induced concept class that exists for any learning algorithm L:
m
Definition 8. The concept class C induced by a learning algorithm L : ∪∞
→ H is defined
m=1 Z
to be the set of total Boolean functions c(z) = I{P(Ztrn = z | H) ≥ P(Ztrn = z)} for all H ∈ H.
Intuitively, every hypothesis H ∈ H induces a total partition on the observation space Z given by
the Boolean function in Definition 8. That is, H splits Z into two disjoint sets: the set of values in
Z that are, a posteriori, less likely to have been present in the training set than before given that the
inferred hypothesis is H, and the set of all other values. The complexity (richness) of the induced
concept class C is related to algorithmic stability via the VC dimension.
m
Theorem 4. Let L : ∪∞
→ H be a learning algorithm with an induced concept class C. Let
m=1 Z
dV C (C) be the VC dimension of C. Then, the following bound holds if m > dV C (C) + 1:
p
4 + dV C (C) (1 + log(2m))
√
S(L) ≥ 1 −
2m
In particular, L is algorithmically stable if its induced concept class C has a finite VC dimension.
Proof. The
is bounded from below by 1 −
n proof relies on the fact that algorithmic stability S(L)
o


supP(z) ESm suph∈H EZ∼P(z) ch (Z) − EZ∼Sm ch (Z) , where cH (z) = I{P(Ztrn =
z|H) ≥ P(Ztrn ) = z}. The final bound follows by applying uniform convergence results [23].

6

Conclusions

In this paper, we showed that a probabilistic notion of algorithmic stability was equivalent to uniform
generalization. In informal terms, a learning algorithm is called algorithmically stable if the impact
of a single training example on the probability distribution of the final hypothesis always vanishes at
the limit of large training sets. In other words, the inference process never depends heavily on any
single training example. If algorithmic stability holds, then the learning algorithm generalizes well
regardless of the choice of the parametric loss function. We also provided several interpretations of
this result. For instance, the relationship between algorithmic stability and data processing reveals
that algorithmic stability can be improved by either post-processing the inferred hypothesis or by
augmenting training examples with artificial noise prior to learning. In addition, we established a
relationship between algorithmic stability and the effective size of the observation space, which provided a formal justification for dimensionality reduction methods. Finally, we connected algorithmic
stability to the complexity (richness) of the hypothesis space, which re-established the classical PAC
result that the complexity of the hypothesis space should be controlled in order to improve stability,
and, hence, improve generalization.
8

References
[1] V. N. Vapnik, “An overview of statistical learning theory,” Neural Networks, IEEE Transactions
on, vol. 10, September 1999.
[2] C. Cortes and V. Vapnik, “Support-vector networks,” Machine learning, vol. 20, pp. 273–297,
1995.
[3] A. Blumer, A. Ehrenfeucht, D. Haussler, and M. K. Warmuth, “Learnability and the VapnikChervonenkis dimension,” Journal of the ACM (JACM), vol. 36, no. 4, pp. 929–965, 1989.
[4] M. Talagrand, “Majorizing measures: the generic chaining,” The Annals of Probability, vol. 24,
no. 3, pp. 1049–1103, 1996.
[5] D. A. McAllester, “PAC-Bayesian stochastic model selection,” Machine Learning, vol. 51,
pp. 5–21, 2003.
[6] O. Bousquet and A. Elisseeff, “Stability and generalization,” The Journal of Machine Learning
Research (JMLR), vol. 2, pp. 499–526, 2002.
[7] P. L. Bartlett and S. Mendelson, “Rademacher and gaussian complexities: Risk bounds and
structural results,” The Journal of Machine Learning Research (JMLR), vol. 3, pp. 463–482,
2002.
[8] J.-Y. Audibert and O. Bousquet, “Combining PAC-Bayesian and generic chaining bounds,”
The Journal of Machine Learning Research (JMLR), vol. 8, pp. 863–889, 2007.
[9] H. Xu and S. Mannor, “Robustness and generalization,” Machine learning, vol. 86, no. 3,
pp. 391–423, 2012.
[10] A. Elisseeff, M. Pontil, et al., “Leave-one-out error and stability of learning algorithms with
applications,” NATO-ASI series on Learning Theory and Practice Science Series Sub Series
III: Computer and Systems Sciences, 2002.
[11] S. Kutin and P. Niyogi, “Almost-everywhere algorithmic stability and generalization error,” in
Proceedings of the Eighteenth conference on Uncertainty in artificial intelligence (UAI), 2002.
[12] T. Poggio, R. Rifkin, S. Mukherjee, and P. Niyogi, “General conditions for predictivity in
learning theory,” Nature, vol. 428, pp. 419–422, 2004.
[13] M. Kearns and D. Ron, “Algorithmic stability and sanity-check bounds for leave-one-out crossvalidation,” Neural Computation, vol. 11, no. 6, pp. 1427–1453, 1999.
[14] S. Shalev-Shwartz, O. Shamir, N. Srebro, and K. Sridharan, “Learnability, stability and uniform convergence,” The Journal of Machine Learning Research (JMLR), vol. 11, pp. 2635–
2670, 2010.
[15] L. Devroye, L. Györfi, and G. Lugosi, A probabilistic theory of pattern recognition. Springer,
1996.
[16] V. Vapnik and O. Chapelle, “Bounds on error expectation for support vector machines,” Neural
Computation, vol. 12, no. 9, pp. 2013–2036, 2000.
[17] H. Robbins, “A remark on stirling’s formula,” American Mathematical Monthly, pp. 26–29,
1955.
[18] T. M. Cover and J. A. Thomas, Elements of information theory. Wiley & Sons, 1991.
[19] T. Downs, K. E. Gates, and A. Masters, “Exact simplification of support vector solutions,”
JMLR, vol. 2, pp. 293–297, 2002.
[20] S. Wager, S. Wang, and P. S. Liang, “Dropout training as adaptive regularization,” in NIPS,
pp. 351–359, 2013.
[21] S. M. Stigler, The history of statistics: The measurement of uncertainty before 1900. Harvard
University Press, 1986.
[22] P. Diaconis and S. Zabell, “Closed form summation for classical distributions: Variations on a
theme of de moivre,” Statlstlcal Science, vol. 6, no. 3, pp. 284–302, 1991.
[23] S. Shalev-Shwartz and S. Ben-David, Understanding Machine Learning: From Theory to Algorithms. Cambridge University Press, 2014.

9

",one central question statist learn theori determin condit agent learn experi includ necessari suffici condit gener give finit train set new observ paper prove algorithm stabil infer process equival uniform gener across parametr loss function provid variou interpret result instanc relationship prove stabil datum process reveal algorithm stabil improv postprocess infer hypothesi augment train exampl artifici nois prior learn addit establish relationship algorithm stabil size observ space provid formal justif dimension reduct method final connect algorithm stabil size hypothesi space recov classic pac result size complex hypothesi space control order improv algorithm stabil improv gener,algorithm stabil uniform gener ibrahim alabdulmohsin king abdullah univers scienc technolog thuwal saudi arabia ibrahim alabdulmohsinkaust edu sa abstract one central question statist learn theori determin condit agent learn experi includ necessari suffici condit gener give finit train set new observ paper prove algorithm stabil infer process equival uniform gener across parametr loss function provid variou interpret result instanc relationship prove stabil datum process reveal algorithm stabil improv postprocess infer hypothesi augment train exampl artifici nois prior learn addit establish relationship algorithm stabil size observ space provid formal justif dimension reduct method final connect algorithm stabil size hypothesi space recov classic pac result size complex hypothesi space control order improv algorithm stabil improv gener introduct one fundament goal learn algorithm strike right balanc underfitt overfitt mathemat term often translat two separ object first would like learn algorithm produc hypothesi reason consist empir evid e small empir risk second would like guarante empir risk train error valid estim true unknown risk test error former condit protect underfitt latter condit protect overfitt rational behind two object understand defin gener risk rgen absolut differ empir true risk rgen remp rtrue elementari observ true risk rtrue bound sum remp rgen henc minim empir risk underfitt gener risk overfitt one obtain infer procedur whose true risk minim minim empir risk alon carri use empir risk minim erm procedur [ ] approxim howev gener risk often imposs deal directli instead common practic bind analyticali establish condit guarante small establish condit gener one hop design good learn algorithm perform well empir gener well novel observ futur promin exampl approach support vector machin svm algorithm binari classif [ ] howev bound gener risk quit intric approach variou angl fact sever method propos past prove gener bound includ uniform converg algorithm stabil rademach gaussian complex gener chain bound pacbayesian framework robustnessba analysi [ ] concentr measur inequ form build block rich theori prolifer gener bound understand look gener set learn introduc vapnik [ ] set observ space z hypothesi space h learn algorithm henceforth denot l h use finit set z observ infer hypothesi h h gener set infer process endtoend influenc three key factor natur observ space z natur hypothesi space h detail learn algorithm l impos constraint three compon one may abl deriv new gener bound exampl vapnikchervonenki vc theori deriv gener bound assum constraint h stabil bound e g [ ] deriv assum constraint l give differ gener bound establish impos constraint z h l intrigu ask exist singl view gener tie differ compon togeth paper answer question affirm establish algorithm stabil alon equival uniform gener inform speak infer process say gener uniformli gener risk vanish uniformli across bound parametr loss function limit larg train set precis definit present sequel show constraint impos either h z l improv uniform gener interpret method improv stabil learn algorithm l similar spirit result kearn ron show finit vc dimens hypothesi space h impli certain notion algorithm stabil infer process [ ] statement howev gener appli learn algorithm fall vapnik gener set learn well beyond uniform converg rest paper follow first review current literatur algorithm stabil gener learnabl introduc key definit repeatedli use throughout paper next prove central theorem reveal algorithm stabil equival uniform gener provid variou interpret result afterward relat work perhap two fundament concept statist learn theori learnabl gener [ ] two concept distinct discuss detail next wherea learnabl concern measur excess risk within hypothesi space gener concern estim true risk order defin learnabl gener suppos observ space z probabl distribut observ p z bound stochast loss function l h z [ ] h h infer hypothesi note l implicitli function parameteriz h well defin true risk hypothesi h h risk function rtrue h ezp z l z h learn algorithm call consist true risk infer hypothesi h converg optim true risk within hypothesi space h limit larg train set problem call learnabl admit consist learn algorithm [ ] know learnabl supervis classif regress problem equival uniform converg [ ] howev shalevshwartz et al recent show uniform converg necessari vapnik gener set learn propos algorithm stabil altern key condit learnabl [ ] unlik learnabl question gener concern primarili repres empir risk remp true risk rtrue elabor suppos finit train set sm zi compris observ zi p z defin empir risk hypothesi h respect sm x remp h sm l zi h zi sm also let rtrue h true risk defin eq learn algorithm l say gener empir risk infer hypothesi converg true risk similar learnabl uniform converg definit suffici gener [ ] necessari learn algorithm alway restrict search space small subset h artifici speak contrast know whether algorithm stabil necessari gener show variou notion algorithm stabil defin suffici gener [ ] howev know whether appropri notion algorithm stabil defin necessari suffici gener vapnik gener set learn paper answer question show stabil infer process suffici gener fact equival uniform gener notion gener strong one tradit consid literatur preliminari simplifi discuss alway assum set countabl includ observ space z hypothesi space h similar assumpt use previou work [ ] howev main result present section readili gener addit assum learn algorithm invari permut train set henc order train exampl irrelev moreov x p x random variabl draw alphabet x f x function p x write exp x f x mean xx p x f x often simpli write ex f x mean exp x f x distribut x clear context x take valu finit set uniformli random write x denot distribut x x boolean random variabl x x true otherwis x gener random variabl denot capit letter instanc random variabl denot small letter alphabet denot calligraph typefac also give two probabl mass function p q defin alphabet write hp qi denot overlap p coeffici e intersect p q hp qi aa min p q note hp qi p q p q total variat distanc last write b k n nk k nk denot binomi distribut paper consid gener set learn introduc vapnik [ ] reiter observ space z hypothesi space h learn algorithm l receiv set observ sm zi z gener fix unknown distribut p z pick hypothesi h h probabl pl h h sm formal l h z stochast map paper allow hypothesi h summari statist train set measur central tendenc unsupervis learn map input space output space supervis learn fact even allow h subset train set formal term l stochast map two random variabl h h sm z exact interpret random variabl irrelev learn task assum nonneg bound loss function l z h z [ ] use measur qualiti infer hypothesi h h observ z z importantli assum l h z [ ] parametr definit parametr loss function loss function l h z [ ] call parametr independ train set sm give infer hypothesi h parametr loss function satisfi markov chain sm h l h fix hypothesi h h defin true risk rtrue h eq defin empir risk train set sm denot remp h sm eq also defin true empir risk learn algorithm l expect risk infer hypothesi rtrue l esm eh pl h sm rtrue h esm eh sm rtrue h remp l esm eh pl h sm remp h sm esm eh sm remp h sm simplifi notat write rtrue remp instead rtrue l remp l consid follow definit gener definit gener learn algorithm l h parametr z loss function l h z [ ] gener distribut p z z limm remp rtrue rtrue remp give eq eq respect word learn algorithm l generaliz accord definit empir perform train loss becom unbias estim true risk next defin uniform gener definit uniform gener learn algorithm l h generaliz z uniformli exist distribut p z z parametr loss function sampl size remp l rtrue l uniform gener strong origin notion gener definit particular learn algorithm gener uniformli generaliz accord definit well convers howev true even though uniform gener appear quit strong condit first sight key contribut paper show strong condit equival simpl condit name algorithm stabil main result prove algorithm stabil equival uniform gener introduc probabilist notion mutual stabil two random variabl order abstract away label inform random variabl may possess e g observ space may may metric space defin stabil impact observ probabl distribut definit mutual stabil let x x two random variabl mutual stabil x defin x hp x p p x ex hp p x ey hp x p x recal hp qi overlap coeffici two probabl distribut p q see x give definit inde probabilist measur mutual stabil measur stabl distribut observ instanc x vice versa small valu x mean probabl distribut x heavili perturb singl observ random variabl perfect mutual stabil achiev two random variabl independ probabilist notion mutual stabil mind defin stabil learn algorithm l mutual stabil infer hypothesi random train exampl h learn algorithm receiv definit algorithm stabil let l z finit set train exampl sm zi z draw fix distribut p z let h pl h sm hypothesi infer l let ztrn sm singl random train exampl defin stabil l l inf p z h ztrn infimum take possibl distribut observ p z learn algorithm call algorithm stabl limm l note definit algorithm stabil rather weak requir contribut singl train exampl overal infer process neglig sampl size increas addit welldefin even learn algorithm determinist hypothesi h determinist function entir train set observ remain stochast function individu observ illustr concept follow exampl exampl suppos observ zi bernoulli p trial p zi hypothesi produc l empir averag h zi p h km ztrn b k p h km ztrn b k show use stirl approxim [ ] algorithm stabil learn algorithm asymptot give l achiev gener statement prove later section next show notion algorithm stabil definit equival notion uniform gener definit first state follow lemma lemma datum process inequ let b c three random variabl satisfi markov chain b c b c proof proof consist two step first note markov chain impli p c b p c b b c b direct substitut definit second similar informationcannothurt inequ inform theori [ ] show b c c random variabl b c prove use algebra manipulationand minimum sum alway larg & # 9 ; thep p fact p sum minimum e min min combin result yield b b c c desir result readi state main result paper theorem learn algorithm l h algorithm stabil give defm z init necessari suffici uniform gener see definit addit rtrue remp h ztrn l rtrue remp true empir risk learn algorithm defin eq respect proof outlin proof first parametr loss function l h z [ ] random variabl satisfi markov chain sm h l h independ ztrn sm henc empir risk give remp el h eztrn l h l ztrn h contrast true risk give rtrue el h eztrn p z l ztrn h differ rtrue remp el h eztrn l ztrn h eztrn l h l ztrn h sandwich righthand side upper lower bind note p z p z two distribut defin alphabet z f z [ ] bound loss function ezp z f z ezp z f z p z p z p q total variat distanc proof result immedi deduc consid two region z z p z p z z z p z p z separ use deduc inequ rtrue remp l h ztrn h ztrn l second inequ follow datum process inequ lemma wherea last inequ follow definit algorithm stabil see definit prove l algorithm stabl e l rtrue remp converg zero uniformli across parametr loss function therefor algorithm stabil suffici uniform gener convers prove show bound exist parametr loss distribut p z l rtrue remp l therefor algorithm stabil also necessari uniform gener interpret algorithm stabil uniform gener section provid sever interpret algorithm stabil uniform gener addit show theorem recov classic result learn theori algorithm stabil datum process relationship algorithm stabil datum process present lemma give random variabl b c markov chain b c alway b c present us qualit insight design machin learn algorithm first suppos two differ hypothesi h h say h contain less inform h markov chain sm h h hold exampl observ zi bernoulli trial h r empir averag give exampl h label occur often train set h h hypothesi h contain strictli less inform origin train set h formal sm h h case h enjoy good uniform gener bind h dataprocess intuit know result hold h less tie origin train set h bring us follow remark detail proof avail supplementari file remark improv uniform gener bind equival algorithm stabil learn algorithm postprocess infer hypothesi h manner condit independ origin train set give h exampl postprocess hypothesi common techniqu use machin learn includ sparsifi coeffici vector w rd linear method wj set zero small absolut magnitud also includ method propos reduc number support vector svm exploit linear depend [ ] data process inequ method improv algorithm stabil uniform gener needless mention good gener immedi translat small true risk empir risk may increas infer hypothesi postprocess independ origin train set second markov chain b c hold also obtain c b c appli datum process inequ revers markov chain c b result improv algorithm stabil contamin train exampl artifici nois prior learn sm perturb version train set sm sm sm h impli ztrn h ztrn h ztrn sm ztrn sm random train exampl draw uniformli random train set respect bring us follow remark remark improv algorithm stabil learn algorithm introduc artifici nois train exampl appli learn algorithm perturb train set exampl corrupt train exampl artifici nois recent dropout method popular techniqu neural network improv gener [ ] datum process inequ method inde improv algorithm stabil uniform gener algorithm stabil size observ space next look size observ space z influenc algorithm stabil first start follow definit definit lazi learn learn algorithm l call lazi hypothesi h h map onetoon train set sm e map h sm inject lazi learner call lazi hypothesi equival origin train set inform content henc learn actual take place one exampl instanceba learn h sm despit simpl natur lazi learner use practic use theoret tool well particular equival h sm datum process inequ algorithm stabil lazi learner provid low bind stabil possibl learn algorithm therefor relat algorithm stabil uniform gener size observ space quantifi algorithm stabil lazi learner size z usual infinit howev introduc follow definit effect set size definit countabl space z endow probabl mass function p z effect p p size z w r p z defin ess [ z p z ] p z p z zz one extrem p z uniform finit alphabet z ess [ z p z ] z extrem p z kroneck delta distribut ess [ z p z ] prove next notion effect set size determin rate converg empir probabl mass function true distribut distanc measur total variat sens result allow us relat algorithm stabil properti observ space z theorem let z countabl space endow probabl mass function p z let sm set sampl zi p z defin psm z empir probabl mass function q induc draw sampl uniformli random sm esm p z psm z ess [ z p z ] ess [ z p z ] z effect size z see defm init q addit learn algorithm l z h h ztrn p z ] ess [ z bind achiev lazi learner see definit special case theorem prove de moivr show pempir mean bernoulli trial probabl success converg true mean rate proof outlin proof first know p sm p p multinomi coeffici use relat p q p q multinomi seri de moivr formula mean deviat binomi random variabl [ ] show algebra manipul x k esm p z psm z pk pk pmp k pk pk k use stirl approxim factori [ ] obtain simpl asymptot express r r x pk pk ess [ z p z ] esm p z psm z k tight due tight stirl approxim rest theorem follow markov chain sm sm h datum process inequ definit corollari give condit theorem q z addit finit e z learn algorithm l l z proof finit observ space z maximum effect set size see definit z attain uniform distribut p z z intuit speak theorem corollari state order guarante good uniform gener possibl learn algorithm number observ must suffici larg cover entir effect size observ space z needless mention difficult achiev practic algorithm stabil machin learn algorithm must control order guarante good gener empir observ similarli uniform gener bind improv reduc effect size observ space use dimension reduct method algorithm stabil complex hypothesi space final look hypothesi space influenc algorithm stabil first look role size hypothesi space formal follow theorem theorem denot h h hypothesi infer learn algorithm l z h follow bind algorithm stabil alway hold r r h h log h l h shannon entropi measur nat e use natur logarithm proof proof informationtheoret let x mutual inform r v x let sm z z zm random choic train set hx h sm h h sm h sm h h zi h z h h z z h condit reduc entropi e h b h r v b sm h x [ h zi h zi h ] [ h ztrn h ztrn h ] therefor ztrn h sm h averag believ first appear squareroot law statist infer literatur [ ] effect set size bernoulli distribut accord definit give theorem agre fact gener de moivr result next use pinsker q inequ [ ] state probabl distribut p p q q p q p q total variat distanc p q kullbackleibl diverg measur nat e use natur logarithm recal sm h p sm p h p sm h mutual inform sm h p sm h p sm p h deduc pinsker inequ eq ztrn h p ztrn p h p ztrn h r r r r ztrn h sm h h h log h last line use fact x h x random variabl x theorem reestablish classic pac result finit hypothesi space [ ] term algorithm stabil learn algorithm enjoy high stabil size hypothesi space small term uniform gener state generalizationp risk learn algorithm bound uniformli across parametr loss function h h p log h h h shannon entropi h next relat algorithm stabil vapnikchervonenki vc dimens despit fact vc dimens defin binaryvalu function wherea algorithm stabil function probabl distribut exist connect two concept show first introduc notion induc concept class exist learn algorithm l definit concept class c induc learn algorithm l h defin z set total boolean function c z p ztrn z h p ztrn z h h intuit everi hypothesi h h induc total partit observ space z give boolean function definit h split z two disjoint set set valu z posteriori less like present train set give infer hypothesi h set valu complex rich induc concept class c relat algorithm stabil via vc dimens theorem let l h learn algorithm induc concept class c let z dv c c vc dimens c follow bind hold dv c c p dv c c log l particular l algorithm stabl induc concept class c finit vc dimens proof bound n proof reli fact algorithm stabil l supp z esm suphh ezp z ch z ezsm ch z ch z p ztrn z h p ztrn z final bound follow appli uniform converg result [ ] conclus paper show probabilist notion algorithm stabil equival uniform gener inform term learn algorithm call algorithm stabl impact singl train exampl probabl distribut final hypothesi alway vanish limit larg train set word infer process never depend heavili singl train exampl algorithm stabil hold learn algorithm generaliz well regardless choic parametr loss function also provid sever interpret result instanc relationship algorithm stabil datum process reveal algorithm stabil improv either postprocess infer hypothesi augment train exampl artifici nois prior learn addit establish relationship algorithm stabil effect size observ space provid formal justif dimension reduct method final connect algorithm stabil complex rich hypothesi space reestablish classic pac result complex hypothesi space control order improv stabil henc improv gener refer [ ] v n vapnik overview statist learn theori neural network ieee transact vol septemb [ ] c cort v vapnik supportvector network machin learn vol pp [ ] blumer ehrenfeucht haussler k warmuth learnabl vapnikchervonenki dimens journal acm jacm vol pp [ ] talagrand majoriz measur gener chain annal probabl vol pp [ ] mcallest pacbayesian stochast model select machin learn vol pp [ ] bousquet elisseeff stabil gener journal machin learn research jmlr vol pp [ ] p l bartlett mendelson rademach gaussian complex risk bound structur result journal machin learn research jmlr vol pp [ ] j audibert bousquet combin pacbayesian gener chain bound journal machin learn research jmlr vol pp [ ] h xu mannor robust gener machin learn vol pp [ ] elisseeff pontil et al leaveoneout error stabil learn algorithm applic natoasi seri learn theori practic scienc seri sub seri iii comput system scienc [ ] kutin p niyogi almosteverywher algorithm stabil gener error proceed eighteenth confer uncertainti artifici intellig uai [ ] poggio r rifkin mukherje p niyogi gener condit predict learn theori natur vol pp [ ] kearn ron algorithm stabil sanitycheck bound leaveoneout crossvalid neural comput vol pp [ ] shalevshwartz shamir n srebro k sridharan learnabl stabil uniform converg journal machin learn research jmlr vol pp [ ] l devroy l gyorfi g lugosi probabilist theori pattern recognit springer [ ] v vapnik chapel bound error expect support vector machin neural comput vol pp [ ] h robbin remark stirl formula american mathemat monthli pp [ ] cover j thoma element inform theori wiley son [ ] down k e gate master exact simplif support vector solut jmlr vol pp [ ] wager wang p liang dropout train adapt regular nip pp [ ] stigler histori statist measur uncertainti harvard univers press [ ] p diaconi zabel close form summat classic distribut variat theme de moivr statlstlcal scienc vol pp [ ] shalevshwartz bendavid understand machin learn theori algorithm cambridg univers press
3,6035,Adaptive Low-Complexity Sequential Inference for Dirichlet Process Mixture Models,Poster,6035-adaptive-low-complexity-sequential-inference-for-dirichlet-process-mixture-models.pdf,"We develop a sequential low-complexity inference procedure for Dirichlet process mixtures of Gaussians for online clustering and parameter estimation when the number of clusters are unknown a-priori. We present an easily computable, closed form parametric expression for the conditional likelihood, in which hyperparameters are recursively updated as a function of the streaming data assuming conjugate priors. Motivated by large-sample asymptotics, we propose a noveladaptive low-complexity design for the Dirichlet process concentration parameter and show that the number of classes grow at most at a logarithmic rate. We further prove that in the large-sample limit, the conditional likelihood and datapredictive distribution become asymptotically Gaussian. We demonstrate through experiments on synthetic and real data sets that our approach is superior to otheronline state-of-the-art methods.","Adaptive Low-Complexity Sequential Inference for
Dirichlet Process Mixture Models
Theodoros Tsiligkaridis, Keith W. Forsythe
Massachusetts Institute of Technology, Lincoln Laboratory
Lexington, MA 02421 USA
ttsili@ll.mit.edu, forsythe@ll.mit.edu

Abstract
We develop a sequential low-complexity inference procedure for Dirichlet process mixtures of Gaussians for online clustering and parameter estimation when
the number of clusters are unknown a-priori. We present an easily computable,
closed form parametric expression for the conditional likelihood, in which hyperparameters are recursively updated as a function of the streaming data assuming
conjugate priors. Motivated by large-sample asymptotics, we propose a novel
adaptive low-complexity design for the Dirichlet process concentration parameter and show that the number of classes grow at most at a logarithmic rate. We
further prove that in the large-sample limit, the conditional likelihood and data
predictive distribution become asymptotically Gaussian. We demonstrate through
experiments on synthetic and real data sets that our approach is superior to other
online state-of-the-art methods.

1

Introduction

Dirichlet process mixture models (DPMM) have been widely used for clustering data Neal (1992);
Rasmussen (2000). Traditional finite mixture models often suffer from overfitting or underfitting
of data due to possible mismatch between the model complexity and amount of data. Thus, model
selection or model averaging is required to find the correct number of clusters or the model with
the appropriate complexity. This requires significant computation for high-dimensional data sets or
large samples. Bayesian nonparametric modeling are alternative approaches to parametric modeling,
an example being DPMM’s which can automatically infer the number of clusters from the data via
Bayesian inference techniques.
The use of Markov chain Monte Carlo (MCMC) methods for Dirichlet process mixtures has made
inference tractable Neal (2000). However, these methods can exhibit slow convergence and their
convergence can be tough to detect. Alternatives include variational methods Blei & Jordan (2006),
which are deterministic algorithms that convert inference to optimization. These approaches can
take a significant computational effort even for moderate sized data sets. For large-scale data sets
and low-latency applications with streaming data, there is a need for inference algorithms that are
much faster and do not require multiple passes through the data. In this work, we focus on lowcomplexity algorithms that adapt to each sample as they arrive, making them highly scalable. An
online algorithm for learning DPMM’s based on a sequential variational approximation (SVA) was
proposed in Lin (2013), and the authors in Wang & Dunson (2011) recently proposed a sequential
maximum a-posterior (MAP) estimator for the class labels given streaming data. The algorithm is
called sequential updating and greedy search (SUGS) and each iteration is composed of a greedy
selection step and a posterior update step.
The choice of concentration parameter α is critical for DPMM’s as it controls the number of clusters Antoniak (1974). While most fast DPMM algorithms use a fixed α Fearnhead (2004); Daume
1

(2007); Kurihara et al. (2006), imposing a prior distribution on α and sampling from it provides more
flexibility, but this approach still heavily relies on experimentation and prior knowledge. Thus, many
fast inference methods for Dirichlet process mixture models have been proposed that can adapt α
to the data, including the works Escobar & West (1995) where learning of α is incorporated in the
Gibbs sampling analysis, Blei & Jordan (2006) where a Gamma prior is used in a conjugate manner
directly in the variational inference algorithm. Wang & Dunson (2011) also account for model uncertainty on the concentration parameter α in a Bayesian manner directly in the sequential inference
procedure. This approach can be computationally expensive, as discretization of the domain of α is
needed, and its stability highly depends on the initial distribution on α and on the range of values of
α. To the best of our knowledge, we are the first to analytically study the evolution and stability of
the adapted sequence of α’s in the online learning setting.
In this paper, we propose an adaptive non-Bayesian approach for adapting α motivated by largesample asymptotics, and call the resulting algorithm ASUGS (Adaptive SUGS). While the basic
idea behind ASUGS is directly related to the greedy approach of SUGS, the main contribution is
a novel low-complexity stable method for choosing the concentration parameter adaptively as new
data arrive, which greatly improves the clustering performance. We derive an upper bound on the
number of classes, logarithmic in the number of samples, and further prove that the sequence of
concentration parameters that results from this adaptive design is almost bounded. We finally prove,
that the conditional likelihood, which is the primary tool used for Bayesian-based online clustering,
is asymptotically Gaussian in the large-sample limit, implying that the clustering part of ASUGS
asymptotically behaves as a Gaussian classifier. Experiments show that our method outperforms
other state-of-the-art methods for online learning of DPMM’s.
The paper is organized as follows. In Section 2, we review the sequential inference framework for
DPMM’s that we will build upon, introduce notation and propose our adaptive modification. In
Section 3, the probabilistic data model is given and sequential inference steps are shown. Section
4 contains the growth rate analysis of the number of classes and the adaptively-designed concentration parameters, and Section 5 contains the Gaussian large-sample approximation to the conditional
likelihood. Experimental results are shown in Section 6 and we conclude in Section 7.

2

Sequential Inference Framework for DPMM

Here, we review the SUGS framework of Wang & Dunson (2011) for online clustering. Here, the
nonparametric nature of the Dirichlet process manifests itself as modeling mixture models with
countably infinite components. Let the observations be given by yi ∈ Rd , and γi to denote
the class label of the ith observation (a latent variable). We define the available information at
time i as y(i) = {y1 , . . . , yi } and γ (i−1) = {γ1 , . . . , γi−1 }. The online sequential updating and
greedy search (SUGS) algorithm is summarized next for completeness. Set γ1 = 1 and calculate
π(θ1 |y1 , γ1 ). For i ≥ 2,
1. Choose best class label for yi :

γi ∈ arg max1≤h≤ki−1 +1 P (γi = h|y(i) , γ (i−1) ).

2. Update the posterior distribution
f (yi |θγi )π(θγi |y(i−1) , γ (i−1) ).

using

yi , γi :

π(θγi |y(i) , γ (i) )

∝

where θh are the parameters of class h, f (yi |θh ) is the observation density conditioned on class
h and ki−1 is the number of classes created at time i − 1. The algorithm sequentially allocates
observations yi to classes based on maximizing the conditional posterior probability.
To calculate the posterior probability P (γi = h|y(i) , γ (i−1) ), define the variables:
def

def

Li,h (yi ) = P (yi |γi = h, y(i−1) , γ (i−1) ),

πi,h (α) = P (γi = h|α, y(i−1) , γ (i−1) )

From Bayes’ rule, P (γi = h|y(i) , γ (i−1) ) ∝ Li,h (yi )πi,h (α) for h = 1, . . . , ki−1 + 1. Here, α is
considered fixed at this iteration, and is not updated in a fully Bayesian manner.
According to the Dirichlet process prediction, the predictive probability of assigning observation yi
to a class h is:
 mi−1 (h)
, h = 1, . . . , ki−1
πi,h (α) = i−1+α
(1)
α
,
h = ki−1 + 1
i−1+α
2

Algorithm 1 Adaptive Sequential Updating and Greedy Search (ASUGS)
Input: streaming data {yi }∞
i=1 , rate parameter λ > 0.
Set γ1 = 1 and k1 = 1. Calculate π(θ1 |y1 , γ1 ).
for i ≥ 2: do
ki−1
(a) Update concentration parameter: αi−1 = λ+log(i−1)
.
o
n
(i)
L (yi )πi,h (αi−1 )
(b) Choose best label for yi :
γi ∼ {qh } = P 0 i,h
L 0 (yi )π 0 (αi−1 ) .
h

(c) Update posterior distribution:
end for

i,h

i,h

π(θγi |y(i) , γ (i) ) ∝ f (yi |θγi )π(θγi |y(i−1) , γ (i−1) ).

Pi−1
where mi−1 (h) = l=1 I(γl = h) counts the number of observations labeled as class h at time
i − 1, and α > 0 is the concentration parameter.
2.1

Adaptation of Concentration Parameter α

It is well known that the concentration parameter α has a strong influence on the growth of the number of classes Antoniak (1974). Our experiments show that in this sequential framework, the choice
of α is even more critical. Choosing a fixed α as in the online SVA algorithm of Lin (2013) requires
cross-validation, which is computationally prohibitive for large-scale data sets. Furthermore, in the
streaming data setting where no estimate on the data complexity exists, it is impractical to perform
cross-validation. Although the parameter α is handled from a fully Bayesian treatment in Wang &
Dunson (2011), a pre-specified grid of possible values α can take, say {αl }L
l=1 , along with the prior
distribution over them, needs to be chosen in advance. Storage and updating of a matrix of size
(ki−1 + 1) × L and further marginalization is needed to compute P (γi = h|y(i) , γ (i−1) ) at each
iteration i. Thus, we propose an alternative data-driven method for choosing α that works well in
practice, is simple to compute and has theoretical guarantees.
The idea is to start with a prior distribution on α that favors small α and shape it into a posterior
distribution using the data. Define pi (α) = p(α|y(i) , γ (i) ) as the posterior distribution formed at
time i, which will be used in ASUGS at time i + 1. Let p1 (α) ≡ p1 (α|y(1) , γ (1) ) denote the prior
for α, e.g., an exponential distribution p1 (α) = λe−λα . The dependence on y(i) and γ (i) is trivial
only at this first step. Then, by Bayes rule, pi (α) ∝ p(yi , γi |y(i−1) , γ (i−1) , α)p(α|y(i−1) , γ (i−1) ) ∝
pi−1 (α)πi,γi (α) where πi,γi (α) is given in (1). Once this update is made after the selection of γi , the
α to be used in the next selection step is the mean of the distribution pi (α), i.e., αi = E[α|y(i) , γ (i) ].
As will be shown in Section 5, the distribution pi (α) can be approximated by a Gamma distribution
with shape parameter ki and rate parameter λ + log i. Under this approximation, we have αi =
ki
λ+log i , only requiring storage and update of one scalar parameter ki at each iteration i.
The ASUGS algorithm is summarized in Algorithm 1. The selection step may be implemented
(i)
by sampling the probability mass function {qh }. The posterior update step can be efficiently performed by updating the hyperparameters as a function of the streaming data for the case of conjugate
distributions. Section 3 derives these updates for the case of multivariate Gaussian observations and
conjugate priors for the parameters.

3

Sequential Inference under Unknown Mean & Unknown Covariance

We consider the general case of an unknown mean and covariance for each class. The probabilistic
model for the parameters of each class is given as:
yi |µ, T ∼ N (·|µ, T),

µ|T ∼ N (·|µ0 , co T),

T ∼ W(·|δ0 , V0 )

(2)

where N (·|µ, T) denotes the multivariate normal distribution with mean µ and precision matrix
T, and W(·|δ, V) is the Wishart distribution with 2δ degrees of freedom and scale matrix V. The
d
follow a normal-Wishart joint distribution. The model (2) leads
parameters θ = (µ, T) ∈ Rd × S++
to closed-form expressions for Li,h (yi )’s due to conjugacy Tzikas et al. (2008).
To calculate the class posteriors, the conditional likelihoods of yi given assignment to class h and
the previous class assignments need to be calculated first. The conditional likelihood of yi given
3

assignment to class h and the history (y(i−1) , γ (i−1) ) is given by:
Z
Li,h (yi ) = f (yi |θh )π(θh |y(i−1) , γ (i−1) )dθh

(3)

Due to the conjugacy of the distributions, the posterior π(θh |y(i−1) , γ (i−1) ) always has the form:
(i−1)

π(θh |y(i−1) , γ (i−1) ) = N (µh |µh
(i−1)

(i−1)

(i−1)

(i−1)

, ch

(i−1)

Th )W(Th |δh

(i−1)

, Vh

)

(i−1)

where µh
, ch
, δh
, Vh
are hyperparameters that can be recursively computed as new
samples come in. The form of this recursive computation of the hyperparameters is derived in
(i)

Appendix A. For ease of interpretation and numerical stability, we define Σh :=
(i)
(i)
W(·|δh , Vh ).

(i)

(Vh )−1
(i)

2δh

as the

(i)
Σh

inverse of the mean of the Wishart distribution
The matrix
has the natural
interpretation as the covariance matrix of class h at iteration i. Once the γi th component is chosen,
the parameter updates for the γi th class become:
µ(i)
γi =

(i−1)

1

y +
(i−1) i

1 + cγi

cγi
1+

(i−1)
cγi

µγ(i−1)
i

(4)

(i−1)
c(i)
+1
γi = cγi

Σ(i)
γi =

1

(5)

(i−1)
2δγi
Σ(i−1)
(i−1) γi
+ 2δγi

δγ(i)
= δγ(i−1)
+
i
i

1

+

(i−1)

1 + 2δγi

1

(i−1)
cγi
(yi
(i−1)
+ cγi

− µγ(i−1)
)(yi − µ(i−1)
)T
γi
i

1
2

(6)
(7)

(0)

(i)

If the starting matrix Σh is positive definite, then all the matrices {Σh } will remain positive
definite. Let us return to the calculation of the conditional likelihood (3). By iterated integration, it
follows that:
!d/2
(i−1)
(i−1)
(i−1) −1/2
rh
ρd (δh
) det(Σh
)
Li,h (yi ) ∝
(i−1)
δh(i−1) + 21 (8)

(i−1)
2δh
rh
(i−1) T
(i−1) −1
(i−1)
) (Σh
) (yi − µh
)
1 + (i−1) (yi − µh
2δh

def

where ρd (a) =

Γ(a+ 21 )
Γ(a+ 1−d
2 )

(i−1) def

and rh

=

(i−1)

ch

(i−1)

1+ch

. A detailed mathematical derivation of this

conditional likelihood is included in Appendix B. We remark that for the new class h = ki−1 + 1,
Li,ki−1 +1 has the form (8) with the initial choice of hyperparameters r(0) , δ (0) , µ(0) , Σ(0) .

4

Growth Rate Analysis of Number of Classes & Stability

In this section, we derive a model for the posterior distribution pn (α) using large-sample approximations, which will allow us to derive growth rates on the number of classes and the sequence of
concentration parameters, showing that the number of classes grows as E[kn ] = O(log1+ n) for 
arbitarily small under certain mild conditions.
The probability density of the α parameter is updated at the jth step in the following fashion:
 α
innovation class chosen
j+α
,
pj+1 (α) ∝ pj (α) ·
1
otherwise
j+α
where only the α-dependent factors in the update are shown. The α-independent factors are absorbed
by the normalization to a probability density. Choosing the innovation class pushes mass toward
infinity while choosing any other class pushes mass toward zero. Thus there is a possibility that
the innovation probability grows in a undesired manner. We assess the growth of the number of
def
innovations rn = kn − 1 under simple assumptions on some likelihood functions that appear
naturally in the ASUGS algorithm.
Assuming that the initial distribution of α is p1 (α) = λe−λα , the distribution used at step n + 1 is
Qn−1
proportional to αrn j=1 (1 + αj )−1 e−λα . We make use of the limiting relation
4

Theorem 1. The following asymptotic behavior holds: limn→∞

log

Qn−1

α
j=1 (1+ j )
α log n

= 1.

Proof. See Appendix C.
Using Theorem 1, a large-sample model for pn (α) is αrn e−(λ+log n)α , suitably normalized. Recognizing this as the Gamma distribution with shape parameter rn + 1 and rate parameter λ + log n, its
rn +1
mean is given by αn = λ+log
n . We use the mean in this form to choose class membership in Alg. 1.
This asymptotic approximation leads to a very simple scalar update of the concentration parameter;
there is no need for discretization for tracking the evolution of continuous probability distributions
on α. In our experiments, this approximation is very accurate.
Recall that the innovation class is labeled K+ = kn−1 + 1 at the nth step. The modeled updates
randomly select a previous class or innovation (new class) by sampling from the probability distriP
K+
(n)
bution {qk = P (γn = k|y(n) , γ (n−1) )}k=1
. Note that n − 1 = k6=K+ mn (k) , where mn (k)
represents the number of members in class k at time n.
We assume the data follows the Gaussian mixture distribution:
def

pT (y) =

K
X

πh N (y|µh , Σh )

(9)

h=1

where πh are the prior probabilities, and µh , Σh are the parameters of the Gaussian clusters.
Define the mixture-model probability density function, which plays the role of the predictive distribution:
X mn−1 (k)
def
L̃n,K+ (y) =
Ln,k (y),
(10)
n−1
k6=K+

so that the probabilities of choosing a previous class or an innovation (using Equ. (1)) are proporP
mn−1 (k)
αn−1
(n−1)
tional to k6=K+ n−1+α
Ln,k (yn ) = n−1+α
L̃n,K+ (yn ) and n−1+α
Ln,K+ (yn ), respecn−1
n−1
n−1
tively. If τn−1 denotes the innovation probability at step n, then we have
!
(n − 1)L̃n,K+ (yn )
αn−1 Ln,K+ (yn )
= (τn−1 , 1 − τn−1 )
(11)
, ρn−1
ρn−1
n − 1 + αn−1
n − 1 + αn−1
for some positive proportionality factor ρn−1 .
Define the likelihood ratio (LR) at the beginning of stage n as 1 :
def

ln (y) =

Ln,K+ (y)
L̃n,K+ (y)

(12)

Conceptually, the mixture (10) represents a modeled distribution fitting the currently observed data.
If all “modes” of the data have been observed, it is reasonable to expect that L̃n,K+ is a good model
for future observations. The LR ln (yn ) is not large when the future observations are well-modeled
by (10). In fact, we expect L̃n,K+ → pT as n → ∞, as discussed in Section 5.


ln (yn )αn−1
ln (yn )αn−1
Lemma 1. The following bound holds: τn−1 = n−1+l
≤
min
,
1
.
n−1
n (yn )αn−1
Proof. The result follows directly from (11) after a simple calculation.
The innovation random variable rn is described by the random process associated with the probabilities of transition

τn ,
k = rn + 1
P (rn+1 = k|rn ) =
.
(13)
1 − τn , k = rn
1

def

Here, L0 (·) = Ln,K+ (·) is independent of n and only depends on the initial choice of hyperparameters
as discussed in Sec. 3.

5

The expectation of rn is majorized by the expectation of a similar random process, r̄n , based on the
def
transition probability σn = min( rna+1
, 1) instead of τn as Appendix D shows, where the random
n
−1
sequence {an } is given by ln+1 (yn+1 ) n(λ + log n). The latter can be described as a modification
of a Polya urn process with selection probability σn . The asymptotic behavior of rn and related
variables is described in the following theorem.
Theorem 2. Let τn be a sequence of real-valued random variables 0 ≤ τn ≤ 1 satisfying τn ≤ rna+1
n
for n ≥ N , where an = ln+1 (yn+1 )−1 n(λ + log n), and where the nonnegative, integer-valued
random variables rn evolve according to (13). Assume the following for n ≥ N :
1. ln (yn ) ≤ ζ

(a.s.)

2. D(pT k L̃n,K+ ) ≤ δ

(a.s.)

where D(p k q) is the Kullback-Leibler divergence between distributions p(·) and q(·). Then, as
n → ∞,
√
√
rn = OP (log1+ζ δ/2 n),
αn = OP (logζ δ/2 n)
(14)
Proof. See Appendix E.
Theorem 2 bounds the growth rate of the mean of the number of class innovations and the concentration parameter αn in terms of the sample size n and parameter ζ. The bounded LR and bounded
KL divergence conditions of Thm. 2 manifest themselves in the rate exponents of (14). The experiments section shows that both of the conditions of Thm. 2 hold for all iterations n ≥ N for
some N ∈ N. In fact, assuming the correct clustering, the mixture distribution L̃n,kn−1 +1 converges
to the true mixture distribution pT , implying that the number of class innovations grows at most
as O(log1+ n) and the sequence of concentration parameters is O(log n), where  > 0 can be
arbitrarily small.

5

Asymptotic Normality of Conditional Likelihood

In this section, we derive an asymptotic expression for the conditional likelihood (8) in order to gain
insight into the steady-state of the algorithm.
We let πh denote the true prior probability of class h. Using the bounds of the Gamma function
ρd (a)
in Theorem 1.6 from Batir (2008), it follows that lima→∞ e−d/2 (a−1/2)
d/2 = 1. Under normal
convergence conditions of the algorithm (with the pruning and merging steps included), all classes
h = 1, . . . , K will be correctly identified and populated with approximately ni−1 (h) ≈ πh (i − 1)
observations at time i − 1. Thus, the conditional class prior for each class h converges to πh as
i→∞
ni−1 (h)
π√
h
i → ∞, in virtue of (14), πi,h (αi−1 ) = i−1+α
−→ πh . According
=
ζ δ/2
i−1
1+

(i−1)
rh

(i−1)
ch

OP (log

(i−1))

i−1

(i−1)

to (5), we expect
→ 1 as i → ∞ since
∼ πh (i − 1). Also, we expect 2δh
∼
(i−1)
(i−1)
πh (i − 1) as i → ∞ according to (7). Also, from before, ρd (δh
) ∼ e−d/2 (δh
− 1/2)d/2 ∼
(i)
(i)
1 d/2
e−d/2 (πh i−1
. The parameter updates (4)-(7) imply µh → µh and Σh → Σh as i → ∞.
2 − 2)
This follows from the strong law of large numbers, as the updates are recursive implementations
of the sample mean and sample covariance matrix. Thus, the large-sample approximation to the
conditional likelihood becomes:

− i−1
−1
−1
πh
(i−1) T
(i−1) −1
(i−1)
2π
h
(y
−
µ
)
(Σ
)
(y
−
µ
)
lim
1
+
i→∞
i
i
h
h
h
i−1
i→∞
Li,h (yi ) ∝
(i−1) 1/2
limi→∞ det(Σh
)
1

i→∞

∝

T

−1

e− 2 (yi −µh ) Σh (yi −µh )
√
det Σh

(15)

where we used limu→∞ (1+ uc )u = ec . The conditional likelihood (15) corresponds to the multivariate Gaussian distribution with mean µh and covariance matrix Σh . A similar asymptotic normality
6

result was recently obtained in Tsiligkaridis & Forsythe (2015) for Gaussian observations with a von
(n)
(n)
(h)
Mises prior. The asymptotics mn−1
→ πh , µh → µh , Σh → Σh , Ln,h (y) → N (y|µh , Σh )
n−1
as n → ∞ imply that the mixture distribution L̃n,K+ in (10) converges to the true Gaussian mixture
distribution pT of (9). Thus, for any small δ, we expect D(pT k L̃n,K+ ) ≤ δ for all n ≥ N ,
validating the assumption of Theorem 2.

6

Experiments

We apply the ASUGS learning algorithm to a synthetic 16-class example and to a real data set, to
verify the stability and accuracy of our method. The experiments show the value of adaptation of
the Dirichlet concentration parameter for online clustering and parameter estimation.
Since it is possible that multiple clusters are similar and classes might be created due to outliers, or
due to the particular ordering of the streaming data sequence, we add the pruning and merging step
in the ASUGS algorithm as done in Lin (2013). We compare ASUGS and ASUGS-PM with SUGS,
SUGS-PM, SVA and SVA-PM proposed in Lin (2013), since it was shown in Lin (2013) that SVA
and SVA-PM outperform the block-based methods that perform iterative updates over the entire data
set including Collapsed Gibbs Sampling, MCMC with Split-Merge and Truncation-Free Variational
Inference.
6.1

Synthetic Data set

We consider learning the parameters of a 16-class Gaussian mixture each with equal variance of
σ 2 = 0.025. The training set was made up of 500 iid samples, and the test set was made up of
1000 iid samples. The clustering results are shown in Fig. 1(a), showing that the ASUGS-based approaches are more stable than SVA-based algorithms. ASUGS-PM performs best and identifies the
correct number of clusters, and their parameters. Fig. 1(b) shows the data log-likelihood on the test
set (averaged over 100 Monte Carlo trials), the mean and variance of the number of classes at each iteration. The ASUGS-based approaches achieve a higher log-likelihood than SVA-based approaches
asymptotically. Fig. 6.1 provides some numerical verification for the assumptions of Theorem 2.
As expected, the predictive likelihood L̃i,K+ (10) converges to the true mixture distribution pT (9),
and the likelihood ratio li (yi ) is bounded after enough samples are processed.
SVA-PM

0

0

-2

-2

-4
-4

-2

0

2

4

-4
-4

-2

-2

ASUGS

0

2

4

ASUGS-PM

4

4

2

2

0

0

-2

-2

25

Mean Number of Classes

2

Avg. Joint Log-likelihood

4

2

20

-4

15

-6

-8

-10

-2

0

2

4

-4
-4

-2

0

2

4

5
0

0
-4
-4

ASUGS
ASUGS-PM
SUGS
SUGS-PM
SVA
SVA-PM

10

100

200

300

Iteration

400

500

0

100

200

300

Iteration

(a)

400

Variance of Number of Classes

SVA
4

500

5
4
3
2
1
0
0

100

200

300

400

500

Iteration

(b)

Figure 1: (a) Clustering performance of SVA, SVA-PM, ASUGS and ASUGS-PM on synthetic data
set. ASUGS-PM identifies the 16 clusters correctly. (b) Joint log-likelihood on synthetic data, mean
and variance of number of classes as a function of iteration. The likelihood values were evaluated on
a held-out set of 1000 samples. ASUGS-PM achieves the highest log-likelihood and has the lowest
asymptotic variance on the number of classes.

6.2

Real Data Set

We applied the online nonparametric Bayesian methods for clustering image data. We used the
MNIST data set, which consists of 60, 000 training samples, and 10, 000 test samples. Each sample
7

10000

3

9000
2.5

~ i;K+ ! pT k2
kL
2

8000

li (yi )

7000

2

6000
5000

1.5

4000

1

3000
2000

0.5

1000
0

0
100

200

300

400

500

Sample i

L

0

100

200

300

400

500

Sample i

(y )

Figure 2: Likelihood ratio li (yi ) = L̃i,K+ (yi ) (left) and L2 -distance between L̃i,K+ (·) and true
i
i,K+
mixture distribution pT (right) for synthetic example (see 1).
is a 28 × 28 image of a handwritten digit (total of 784 dimensions), and we perform PCA preprocessing to reduce dimensionality to d = 50 dimensions as in Kurihara et al. (2006).
We use only a random 1.667% subset, consisting of 1000 random samples for training. This training
set contains data from all 10 digits with an approximately uniform proportion. Fig. 3 shows the
predictive log-likelihood over the test set, and the mean images for clusters obtained using ASUGSPM and SVA-PM, respectively. We note that ASUGS-PM achieves higher log-likelihood values and
finds all digits correctly using only 23 clusters, while SVA-PM finds some digits using 56 clusters.
0

Predictive Log-Likelihood

-500

ASUGS-PM
SUGS-PM
SVA-PM

-1000
-1500
-2000
-2500
-3000
-3500
-4000
-4500
-5000
0

100

200

300

400

500

600

700

800

900

1000

Iteration

(a)

(b)

(c)

Figure 3: Predictive log-likelihood (a) on test set, mean images for clusters found using ASUGS-PM
(b) and SVA-PM (c) on MNIST data set.

6.3

Discussion

Although both SVA and ASUGS methods have similar computational complexity and use decisions
and information obtained from processing previous samples in order to decide on class innovations, the mechanics of these methods are quite different. ASUGS uses an adaptive α motivated
by asymptotic theory, while SVA uses a fixed α. Furthermore, SVA updates the parameters of all
the components at each iteration (in a weighted fashion) while ASUGS only updates the parameters
of the most-likely cluster, thus minimizing leakage to unrelated components. The λ parameter of
ASUGS does not affect performance as much as the threshold parameter  of SVA does, which often
leads to instability requiring lots of pruning and merging steps and increasing latency. This is critical for large data sets or streaming applications, because cross-validation would be required to set
 appropriately. We observe higher log-likelihoods and better numerical stability for ASUGS-based
methods in comparison to SVA. The mathematical formulation of ASUGS allows for theoretical
guarantees (Theorem 2), and asymptotically normal predictive distribution.

7

Conclusion

We developed a fast online clustering and parameter estimation algorithm for Dirichlet process mixtures of Gaussians, capable of learning in a single data pass. Motivated by large-sample asymptotics,
we proposed a novel low-complexity data-driven adaptive design for the concentration parameter
and showed it leads to logarithmic growth rates on the number of classes. Through experiments on
synthetic and real data sets, we show our method achieves better performance and is as fast as other
state-of-the-art online learning DPMM methods.
8

References
Antoniak, C. E. Mixtures of Dirichlet Processes with Applications to Bayesian Nonparametric
Problems. The Annals of Statistics, 2(6):1152–1174, 1974.
Batir, N. Inequalities for the Gamma Function. Archiv der Mathematik, 91(6):554–563, 2008.
Blei, D. M. and Jordan, M. I. Variational Inference for Dirichlet Process Mixtures. Bayesian Analysis, 1(1):121–144, 2006.
Daume, H. Fast Search for Dirichlet Process Mixture Models. In Conference on Artificial Intelligence and Statistics, 2007.
Escobar, M. D. and West, M. Bayesian Density Estimation and Inference using Mixtures. Journal
of the American Statistical Association, 90(430):577–588, June 1995.
Fearnhead, P. Particle Filters for Mixture Models with an Uknown Number of Components. Statistics and Computing, 14:11–21, 2004.
Kurihara, K., Welling, M., and Vlassis, N. Accelerated Variational Dirichlet Mixture Models. In
Advances in Neural Information Processing Systems (NIPS), 2006.
Lin, Dahua. Online learning of nonparametric mixture models via sequential variational approximation. In Burges, C.J.C., Bottou, L., Welling, M., Ghahramani, Z., and Weinberger, K.Q. (eds.),
Advances in Neural Information Processing Systems 26, pp. 395–403. Curran Associates, Inc.,
2013.
Neal, R. M. Bayesian Mixture Modeling. In Proceedings of the Workshop on Maximum Entropy
and Bayesian Methods of Statistical Analysis, volume 11, pp. 197–211, 1992.
Neal, R. M. Markov chain sampling methods for Dirichlet process mixture models. Journal of
Computational and Graphical Statistics, 9(2):249–265, June 2000.
Rasmussen, C. E. The infinite gaussian mixture model. In Advances in Neural Information Processing Systems 12, pp. 554–560. MIT Press, 2000.
Tsiligkaridis, T. and Forsythe, K. W. A Sequential Bayesian Inference Framework for Blind Frequency Offset Estimation. In Proceedings of IEEE International Workshop on Machine Learning
for Signal Processing, Boston, MA, September 2015.
Tzikas, D. G., Likas, A. C., and Galatsanos, N. P. The Variational Approximation for Bayesian
Inference. IEEE Signal Processing Magazine, pp. 131–146, November 2008.
Wang, L. and Dunson, D. B. Fast Bayesian Inference in Dirichlet Process Mixture Models. Journal
of Computational and Graphical Statistics, 20(1):196–216, 2011.

9

",develop sequenti lowcomplex infer procedur dirichlet process mixtur gaussian onlin cluster paramet estim number cluster unknown apriori present easili comput close form parametr express condit likelihood hyperparamet recurs updat function stream datum assum conjug prior motiv largesampl asymptot propos noveladapt lowcomplex design dirichlet process concentr paramet show number class grow logarithm rate prove largesampl limit condit likelihood datapredict distribut becom asymptot gaussian demonstr experi synthet real datum set approach superior otheronlin stateoftheart method,adapt lowcomplex sequenti infer dirichlet process mixtur model theodoro tsiligkaridi keith w forsyth massachusett institut technolog lincoln laboratori lexington usa ttsilil mit edu forsythel mit edu abstract develop sequenti lowcomplex infer procedur dirichlet process mixtur gaussian onlin cluster paramet estim number cluster unknown apriori present easili comput close form parametr express condit likelihood hyperparamet recurs updat function stream datum assum conjug prior motiv largesampl asymptot propos novel adapt lowcomplex design dirichlet process concentr paramet show number class grow logarithm rate prove largesampl limit condit likelihood datum predict distribut becom asymptot gaussian demonstr experi synthet real datum set approach superior onlin stateoftheart method introduct dirichlet process mixtur model dpmm wide use cluster datum neal rasmussen tradit finit mixtur model often suffer overfitt underfitt datum due possibl mismatch model complex amount datum thu model select model averag requir find correct number cluster model appropri complex requir signific comput highdimension data set larg sampl bayesian nonparametr model altern approach parametr model exampl dpmm automat infer number cluster datum via bayesian infer techniqu use markov chain mont carlo mcmc method dirichlet process mixtur make infer tractabl neal howev method exhibit slow converg converg tough detect altern includ variat method blei jordan determinist algorithm convert infer optim approach take signific comput effort even moder size data set largescal data set lowlat applic stream datum need infer algorithm much faster requir multipl pass datum work focu lowcomplex algorithm adapt sampl arriv make highli scalabl onlin algorithm learn dpmm base sequenti variat approxim sva propos lin author wang dunson recent propos sequenti maximum aposterior map estim class label give stream datum algorithm call sequenti updat greedi search sug iter compos greedi select step posterior updat step choic concentr paramet critic dpmm control number cluster antoniak fast dpmm algorithm use fix fearnhead daum kurihara et al impos prior distribut sampl provid flexibl approach still heavili reli experiment prior knowledg thu mani fast infer method dirichlet process mixtur model propos adapt datum includ work escobar west learn incorpor gibb sampl analysi blei jordan gamma prior use conjug manner directli variat infer algorithm wang dunson also account model uncertainti concentr paramet bayesian manner directli sequenti infer procedur approach comput expens discret domain need stabil highli depend initi distribut rang valu good knowledg first analyt studi evolut stabil adapt sequenc onlin learn set paper propos adapt nonbayesian approach adapt motiv largesampl asymptot call result algorithm asug adapt sug basic idea behind asug directli relat greedi approach sug main contribut novel lowcomplex stabl method choos concentr paramet adapt new datum arriv greatli improv cluster perform deriv upper bind number class logarithm number sampl prove sequenc concentr paramet result adapt design almost bound final prove condit likelihood primari tool use bayesianba onlin cluster asymptot gaussian largesampl limit impli cluster part asug asymptot behav gaussian classifi experi show method outperform stateoftheart method onlin learn dpmm paper organ follow section review sequenti infer framework dpmm build upon introduc notat propos adapt modif section probabilist datum model give sequenti infer step show section contain growth rate analysi number class adaptivelydesign concentr paramet section contain gaussian largesampl approxim condit likelihood experiment result show section conclud section sequenti infer framework dpmm review sug framework wang dunson onlin cluster nonparametr natur dirichlet process manifest model mixtur model countabl infinit compon let observ give yi rd denot class label ith observ latent variabl defin avail inform time yi onlin sequenti updat greedi search sug algorithm summar next complet set calcul choos good class label yi arg maxhki p h updat posterior distribut f yi use yi h paramet class h f yi h observ densiti condit class h ki number class creat time algorithm sequenti alloc observ yi class base maxim condit posterior probabl calcul posterior probabl p h defin variabl def def lih yi p yi h ih p h bay rule p h lih yi ih h ki consid fix iter updat fulli bayesian manner accord dirichlet process predict predict probabl assign observ yi class h mi h h ki ih h ki algorithm adapt sequenti updat greedi search asug input stream datum yi rate paramet set k calcul ki updat concentr paramet log n l yi ih b choos good label yi qh p ih l yi h c updat posterior distribut end ih ih f yi pi mi h l l h count number observ label class h time concentr paramet adapt concentr paramet well know concentr paramet strong influenc growth number class antoniak experi show sequenti framework choic even critic choos fix onlin sva algorithm lin requir crossvalid comput prohibit largescal data set furthermor stream datum set estim datum complex exist impract perform crossvalid although paramet handl fulli bayesian treatment wang dunson prespecifi grid possibl valu take say l l l along prior distribut need choos advanc storag updat matrix size ki l margin need comput p h iter thu propos altern datadriven method choos work well practic simpl comput theoret guarante idea start prior distribut favor small shape posterior distribut use datum defin pi p posterior distribut form time use asug time let p p denot prior e g exponenti distribut p e depend trivial first step bay rule pi p yi p pi ii ii give updat make select use next select step mean distribut pi e e [ ] show section distribut pi approxim gamma distribut shape paramet ki rate paramet log approxim ki log requir storag updat one scalar paramet ki iter asug algorithm summar algorithm select step may implement sampl probabl mass function qh posterior updat step effici perform updat hyperparamet function stream datum case conjug distribut section deriv updat case multivari gaussian observ conjug prior paramet sequenti infer unknown mean unknown covari consid gener case unknown mean covari class probabilist model paramet class give yi n n co w v n denot multivari normal distribut mean precis matrix w v wishart distribut degre freedom scale matrix v follow normalwishart joint distribut model lead paramet rd closedform express lih yi due conjugaci tzika et al calcul class posterior condit likelihood yi give assign class h previou class assign need calcul first condit likelihood yi give assign class h histori give z lih yi f yi h h dh due conjugaci distribut posterior h alway form h n h h ch th w th h vh h ch h vh hyperparamet recurs comput new sampl come form recurs comput hyperparamet deriv appendix eas interpret numer stabil defin h w h vh vh h h invers mean wishart distribut matrix natur interpret covari matrix class h iter th compon choos paramet updat th class becom ci ci ci c ci ci yi ci yi start matrix h posit definit matrix h remain posit definit let us return calcul condit likelihood iter integr follow rh h det h lih yi h h rh h yi h yi h h def def rh ch ch detail mathemat deriv condit likelihood includ appendix b remark new class h ki liki form initi choic hyperparamet r growth rate analysi number class stabil section deriv model posterior distribut pn use largesampl approxim allow us deriv growth rate number class sequenc concentr paramet show number class grow e [ kn ] log n arbitarili small certain mild condit probabl densiti paramet updat jth step follow fashion innov class choos j pj pj otherwis j depend factor updat show independ factor absorb normal probabl densiti choos innov class push mass toward infin choos class push mass toward zero thu possibl innov probabl grow undesir manner assess growth number def innov rn kn simpl assumpt likelihood function appear natur asug algorithm assum initi distribut p e distribut use step n qn proport rn j j e make use limit relat theorem follow asymptot behavior hold limn log qn j j log n proof see appendix c use theorem largesampl model pn rn e log n suitabl normal recogn gamma distribut shape paramet rn rate paramet log n rn mean give n log n use mean form choos class membership alg asymptot approxim lead simpl scalar updat concentr paramet need discret track evolut continu probabl distribut experi approxim accur recal innov class label k kn nth step model updat randomli select previou class innov new class sampl probabl distrip k n bution qk p n k n n k note n kk mn k mn k repres number member class k time n assum data follow gaussian mixtur distribut def pt k x h n h h h h prior probabl h h paramet gaussian cluster defin mixturemodel probabl densiti function play role predict distribut x mn k def lnk lnk n kk probabl choos previou class innov use equ proporp mn k n n tional kk n lnk yn n lnk yn n lnk yn respecn n n tive n denot innov probabl step n n lnk yn n lnk yn n n n n n n n n posit proportion factor n defin likelihood ratio lr begin stage n def ln lnk lnk conceptu mixtur repres model distribut fit current observ datum mode datum observ reason expect lnk good model futur observ lr ln yn larg futur observ wellmodel fact expect lnk pt n discuss section ln yn n ln yn n lemma follow bind hold n nl min n n yn n proof result follow directli simpl calcul innov random variabl rn describ random process associ probabl transit n k rn p rn k rn n k rn def l lnk independ n depend initi choic hyperparamet discuss sec expect rn majoriz expect similar random process rn base def transit probabl n min rna instead n appendix show random n sequenc give ln yn n log n latter describ modif polya urn process select probabl n asymptot behavior rn relat variabl describ follow theorem theorem let n sequenc realvalu random variabl n satisfi n rna n n n ln yn n log n nonneg integervalu random variabl rn evolv accord assum follow n n ln yn pt k lnk p k q kullbackleibl diverg distribut p q n rn op log n n op log n proof see appendix e theorem bound growth rate mean number class innov concentr paramet n term sampl size n paramet bound lr bound kl diverg condit thm manifest rate expon experi section show condit thm hold iter n n n n fact assum correct cluster mixtur distribut lnkn converg true mixtur distribut pt impli number class innov grow log n sequenc concentr paramet log n arbitrarili small asymptot normal condit likelihood section deriv asymptot express condit likelihood order gain insight steadyst algorithm let h denot true prior probabl class h use bound gamma function theorem batir follow lima ed normal converg condit algorithm prune merg step includ class h k correctli identifi popul approxim ni h h observ time thu condit class prior class h converg h ni h h virtu ih h accord rh ch op log expect sinc h also expect h h accord also h ed h ed h paramet updat impli h h h h follow strong law larg number updat recurs implement sampl mean sampl covari matrix thu largesampl approxim condit likelihood becom h h lim h h h lih yi limi det h e yi h h yi h det h use limu uc u ec condit likelihood correspond multivari gaussian distribut mean h covari matrix h similar asymptot normal result recent obtain tsiligkaridi forsyth gaussian observ von n n h mi prior asymptot mn h h h h h lnh n h h n n impli mixtur distribut lnk converg true gaussian mixtur distribut pt thu small expect pt k lnk n n valid assumpt theorem experi appli asug learn algorithm synthet class exampl real datum set verifi stabil accuraci method experi show valu adapt dirichlet concentr paramet onlin cluster paramet estim sinc possibl multipl cluster similar class may creat due outlier due particular order stream datum sequenc add prune merg step asug algorithm do lin compar asug asugspm sug sugspm sva svapm propos lin sinc show lin sva svapm outperform blockba method perform iter updat entir datum set includ collaps gibb sampl mcmc splitmerg truncationfre variat infer synthet datum set consid learn paramet class gaussian mixtur equal varianc train set make iid sampl test set make iid sampl cluster result show fig show asugsba approach stabl svabas algorithm asugspm perform good identifi correct number cluster paramet fig b show datum loglikelihood test set averag mont carlo trial mean varianc number class iter asugsba approach achiev high loglikelihood svaba approach asymptot fig provid numer verif assumpt theorem expect predict likelihood lik converg true mixtur distribut pt likelihood ratio li yi bound enough sampl process svapm asug asugspm mean number class avg joint loglikelihood asug asugspm sug sugspm sva svapm iter iter varianc number class sva iter b figur cluster perform sva svapm asug asugspm synthet datum set asugspm identifi cluster correctli b joint loglikelihood synthet datum mean varianc number class function iter likelihood valu evalu heldout set sampl asugspm achiev high loglikelihood low asymptot varianc number class real datum set appli onlin nonparametr bayesian method cluster imag datum use mnist datum set consist train sampl test sampl sampl ik pt k kl li yi sampl l sampl figur likelihood ratio li yi lik yi leav l distanc lik true ik mixtur distribut pt right synthet exampl see imag handwritten digit total dimens perform pca preprocess reduc dimension dimens kurihara et al use random subset consist random sampl train train set contain datum digit approxim uniform proport fig show predict loglikelihood test set mean imag cluster obtain use asugspm svapm respect note asugspm achiev high loglikelihood valu find digit correctli use cluster svapm find digit use cluster predict loglikelihood asugspm sugspm svapm iter b c figur predict loglikelihood test set mean imag cluster find use asugspm b svapm c mnist datum set discuss although sva asug method similar comput complex use decis inform obtain process previou sampl order decid class innov mechan method quit differ asug use adapt motiv asymptot theori sva use fix furthermor sva updat paramet compon iter weight fashion asug updat paramet mostlik cluster thu minim leakag unrel compon paramet asug affect perform much threshold paramet sva often lead instabl requir lot prune merg step increas latenc critic larg data set stream applic crossvalid would requir set appropri observ high loglikelihood good numer stabil asugsba method comparison sva mathemat formul asug allow theoret guarante theorem asymptot normal predict distribut conclus develop fast onlin cluster paramet estim algorithm dirichlet process mixtur gaussian capabl learn singl datum pass motiv largesampl asymptot propos novel lowcomplex datadriven adapt design concentr paramet show lead logarithm growth rate number class experi synthet real datum set show method achiev good perform fast stateoftheart onlin learn dpmm method refer antoniak c e mixtur dirichlet process applic bayesian nonparametr problem annal statist batir n inequ gamma function archiv der mathematik blei jordan variat infer dirichlet process mixtur bayesian analysi daum h fast search dirichlet process mixtur model confer artifici intellig statist escobar west bayesian densiti estim infer use mixtur journal american statist associ june fearnhead p particl filter mixtur model uknown number compon statist comput kurihara k well vlassi n acceler variat dirichlet mixtur model advanc neural inform process system nip lin dahua onlin learn nonparametr mixtur model via sequenti variat approxim burg c j c bottou l well ghahramani z weinberg k q ed advanc neural inform process system pp curran associ inc neal r bayesian mixtur model proceed workshop maximum entropi bayesian method statist analysi volum pp neal r markov chain sampl method dirichlet process mixtur model journal comput graphic statist june rasmussen c e infinit gaussian mixtur model advanc neural inform process system pp mit press tsiligkaridi forsyth k w sequenti bayesian infer framework blind frequenc offset estim proceed ieee intern workshop machin learn signal process boston septemb tzika g lika c galatsano n p variat approxim bayesian infer ieee signal process magazin pp novemb wang l dunson b fast bayesian infer dirichlet process mixtur model journal comput graphic statist
4,5978,Covariance-Controlled Adaptive Langevin Thermostat for Large-Scale Bayesian Sampling,Poster,5978-covariance-controlled-adaptive-langevin-thermostat-for-large-scale-bayesian-sampling.pdf,"Monte Carlo sampling for Bayesian posterior inference is a common approach used in machine learning. The Markov Chain Monte Carlo procedures that are used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior distribution. An area of current research addresses the computational benefits of stochastic gradient methods in this setting. Existing techniques rely on estimating the variance or covariance of the subsampling error, and typically assume constant variance. In this article, we propose a covariance-controlled adaptive Langevin thermostat that can effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The proposed method achieves a substantial speedup over popular alternative schemes for large-scale machine learning applications.","Covariance-Controlled Adaptive Langevin
Thermostat for Large-Scale Bayesian Sampling

Xiaocheng Shang∗
University of Edinburgh
x.shang@ed.ac.uk

Zhanxing Zhu∗
University of Edinburgh
zhanxing.zhu@ed.ac.uk

Benedict Leimkuhler
University of Edinburgh
b.leimkuhler@ed.ac.uk

Amos J. Storkey
University of Edinburgh
a.storkey@ed.ac.uk

Abstract
Monte Carlo sampling for Bayesian posterior inference is a common approach
used in machine learning. The Markov chain Monte Carlo procedures that are
used are often discrete-time analogues of associated stochastic differential equations (SDEs). These SDEs are guaranteed to leave invariant the required posterior
distribution. An area of current research addresses the computational benefits of
stochastic gradient methods in this setting. Existing techniques rely on estimating
the variance or covariance of the subsampling error, and typically assume constant
variance. In this article, we propose a covariance-controlled adaptive Langevin
thermostat that can effectively dissipate parameter-dependent noise while maintaining a desired target distribution. The proposed method achieves a substantial
speedup over popular alternative schemes for large-scale machine learning applications.

1

Introduction

In machine learning applications, direct sampling with the entire large-scale dataset is computationally infeasible. For instance, standard Markov chain Monte Carlo (MCMC) methods [16], as well
as typical hybrid Monte Carlo (HMC) methods [3, 6, 9], require the calculation of the acceptance
probability and the creation of informed proposals based on the whole dataset.
In order to improve the computational efficiency, a number of stochastic gradient methods [4, 5, 20,
21] have been proposed in the setting of Bayesian sampling based on random (and much smaller)
subsets to approximate the likelihood of the whole dataset, thus substantially reducing the computational cost in practice. Welling and Teh proposed the so-called stochastic gradient Langevin
dynamics (SGLD) [21], combining the ideas of stochastic optimization [18] and traditional Brownian dynamics, with a sequence of stepsizes decreasing to zero. A fixed stepsize is often adopted
in practice which is the choice in this article as in Vollmer et al. [20], where a modified SGLD
(mSGLD) was also introduced that was designed to reduce the sampling bias.
SGLD generates samples from first order Brownian dynamics, and thus, with a fixed timestep, one
can show that it is unable to dissipate excess noise in gradient approximations while maintaining the
desired invariant distribution [4]. A stochastic gradient Hamiltonian Monte Carlo (SGHMC) method
was proposed by Chen et al. [4], which relies on second order Langevin dynamics and incorporates a
parameter-dependent diffusion matrix that is intended to effectively offset the stochastic perturbation
of the gradient. However, it is difficult to accommodate the additional diffusion term in practice.
∗

The first and second authors contributed equally, and the listed author order was decided by lot.

1

Moreover, as pointed out in [5], poor estimation of it may have a significant adverse influence on the
sampling of the target distribution; for example, the effective system temperature may be altered.
The “thermostat” idea, which is widely used in molecular dynamics [7, 13], was recently adopted
in the stochastic gradient Nosé-Hoover thermostat (SGNHT) by Ding et al. [5] in order to adjust
the kinetic energy during simulation in such a way that the canonical ensemble is preserved (i.e. so
that a prescribed constant temperature distribution is maintained). In fact, the SGNHT method is
essentially equivalent to the adaptive Langevin (Ad-Langevin) thermostat proposed earlier by Jones
and Leimkuhler [10] in the molecular dynamics setting (see [15] for discussions).
Despite the substantial interest generated by these methods, the mathematical foundation for
stochastic gradient methods has been incomplete. The underlying dynamics of the SGNHT
method [5] was taken up by Leimkuhler and Shang [15], together with the design of discretization schemes with high effective order of accuracy. SGNHT methods are designed based on the
assumption of constant noise variance. In this article, we propose a covariance-controlled adaptive
Langevin (CCAdL) thermostat, that can handle parameter-dependent noise, improving both robustness and reliability in practice, and which can effectively speed up the convergence to the desired
invariant distribution in large-scale machine learning applications.
The rest of the article is organized as follows. In Section 2, we describe the setting of Bayesian
sampling with noisy gradients and briefly review existing techniques. Section 3 considers the construction of the novel CCAdL method that can effectively dissipate parameter-dependent noise while
maintaining the correct distribution. Various numerical experiments are performed in Section 4 to
verify the usefulness of CCAdL in a wide range of large-scale machine learning applications. Finally, we summarize our findings in Section 5.

2

Bayesian Sampling with Noisy Gradients

In the typical setting of Bayesian sampling [3, 19], one is interested in drawing states from a posterior
distribution defined as
π(θ|X) ∝ π(X|θ)π(θ) ,
(1)
where θ ∈ RNd is the parameter vector of interest, X denotes the entire dataset, and, π(X|θ)
and π(θ) are the likelihood and prior distributions, respectively. We introduce a potential energy
function U (θ) by defining π(θ|X) ∝ exp(−βU (θ)), where β is a positive parameter and can be
interpreted as being proportional to the reciprocal temperature in an associated physical system, i.e.
β −1 = kB T (kB is the Boltzmann constant and T is the temperature). In practice, β is often set to
be unity for notational simplicity. Taking the logarithm of (1) yields
U (θ) = − log π(X|θ)−log π(θ) .
(2)
Assuming the data are independent and identically distributed (i.i.d.), the logarithm of the likelihood
can be calculated as
N
X
log π(X|θ) =
log π(xi |θ) ,
(3)
i=1

where N is the size of the entire dataset.
However, as already mentioned, it is computationally infeasible to deal with the entire large-scale
dataset at each timestep as would typically be required in MCMC and HMC methods. Instead, in
order to improve the efficiency, a random (and much smaller, i.e. n  N ) subset is preferred in
stochastic gradient methods, in which the likelihood of the dataset for given parameters is approximated by
n
NX
log π(X|θ) ≈
log π(xri |θ) ,
(4)
n i=1
where {xri }ni=1 represents a random subset of X. Thus, the “noisy” potential energy can be written
as
n
NX
Ũ (θ) = −
log π(xri |θ)−log π(θ) ,
(5)
n i=1
where the negative gradient of the potential is referred to as the “noisy” force, i.e. F̃(θ) = −∇Ũ (θ).
2

Our goal is to correctly sample the Gibbs distribution ρ(θ) ∝ exp(−βU (θ)) (1). As in [4, 5], the
gradient noise is assumed to be Gaussian with mean zero and unknown variance, in which case one
may rewrite the noisy force as
p
F̃(θ) = −∇U (θ)+ Σ(θ)M1/2 R ,
(6)
where M typically is a diagonal matrix, Σ(θ) represents the covariance
matrix
of
the
noise,
and,
p
R is a vector of i.i.d. standard normal random variables. Note that Σ(θ)M1/2 R here is actually
equivalent to N (0, Σ(θ)M).
In a typical setting 
of numerical integration withassociated stepsize h,one has 
p
√ p
hF̃(θ) = h −∇U (θ)+ Σ(θ)M1/2 R = −h∇U (θ)+ h
hΣ(θ) M1/2 R ,

(7)

2

and therefore, assuming a constant covariance matrix (i.e. Σ = σ I, where I is the identity matrix),
the SGNHT method by Ding et al. [5] has the following underlying dynamics, written as a standard
Itō stochastic differential equation (SDE) system [15]:
dθ = M−1 pdt ,
p
√
(8)
dp = −∇U (θ)dt+σ hM1/2 dW−ξpdt+ 2Aβ −1 M1/2 dWA ,
 T −1

−1
dξ = µ
p M p−Nd kB T dt ,
where, colloquially, dW and dWA represent vectors of independent
Wiener increments; and are
p
often informally denoted by N (0, dtI) [4]. The coefficient 2Aβ −1 M1/2 represents the strength
of artificial noise added into the system to improve ergodicity, and A, which can be termed the “effective friction”, is a positive parameter and proportional to the variance of the noise. The auxiliary
variable ξ ∈ R is governed by a Nosé-Hoover device [8, 17] via a negative feedback mechanism,
i.e. when the instantaneous temperature (average kinetic energy per degree of freedom) calculated
as
kB T = pT M−1 p/Nd
(9)
is below the target temperature, the “dynamical friction” ξ would decrease allowing an increase
of temperature, while ξ would increase when the temperature is above the target. µ is a coupling
parameter which is referred to as the “thermal mass” in the molecular dynamics setting.
Proposition 1 (See Jones and Leimkuhler [10]). The SGNHT method (8) preserves the modified
Gibbs (stationary) distribution:

¯ 2 /2 ,
ρ̃β (θ, p, ξ) = Z −1 exp (−βH(θ, p)) exp −βµ(ξ − ξ)
(10)
where Z is the normalizing constant, H(θ, p) = pT M−1 p/2+U (θ) is the Hamiltonian, and
ξ¯ = A+βhσ 2 /2 .
(11)
Proposition 1 tells us that the SGNHT method can adaptively dissipate excess noise pumped into
the system while maintaining the correct distribution. The variance of the gradient noise, σ 2 , does
not need to be known a priori. As long as σ 2 is constant, the auxiliary variable ξ will be able to
automatically find its mean value ξ¯ on the fly. However, with a parameter-dependent covariance
matrix Σ(θ), the SGNHT method (8) would not produce the required target distribution (10).
Ding et al. [5] claimed that it is reasonable to assume the covariance matrix Σ(θ) is constant when
the size of the dataset, N , is large, in which case the variance of the posterior of θ is small. The
magnitude of the posterior variance does not actually relate to the constancy of the Σ, however,
in general, Σ is not constant. Simply assuming the non-constancy of the Σ can have a significant
impact on the performance of the method (most notably the stability measured by the largest usable
stepsize). Therefore, it is essential to have an approach that can handle parameter-dependent noise.
In the following section, we propose a covariance-controlled thermostat that can effectively dissipate
parameter-dependent noise while maintaining the target stationary distribution.

3

Covariance-Controlled Adaptive Langevin Thermostat

As mentioned in the previous section, the SGNHT method (8) can only dissipate noise with a constant covariance matrix. When the covariance matrix becomes parameter-dependent, in general, a
parameter-dependent covariance matrix does not imply the required “thermal equilibrium”, i.e. the
system cannot be expected to converge to the desired invariant distribution (10), typically resulting
in poor estimation of functions of parameters of interest. In fact, in that case it is not clear whether
or not there exists an invariant distribution at all.
3

In order to construct a stochastic-dynamical system that preserves the canonical distribution, we
suggest adding a suitable damping (viscous) term to effectively dissipate the parameter-dependent
gradient noise. To this end, we propose the following covariance-controlled adaptive Langevin
(CCAdL) thermostat:
dθ = M−1 pdt ,
p
p
dp = −∇U (θ)dt+ hΣ(θ)M1/2 dW−(h/2)βΣ(θ)pdt−ξpdt+ 2Aβ −1 M1/2 dWA , (12)


dξ = µ−1 pT M−1 p−Nd kB T dt .
Proposition 2. The CCAdL thermostat (12) preserves the modified Gibbs (stationary)
distribution:

ρ̂β (θ, p, ξ) = Z −1 exp (−βH(θ, p)) exp −βµ(ξ −A)2 /2 .
(13)
Proof. The Fokker-Planck equation corresponding to (12) is
ρt = L† ρ := −M−1 p·∇θ ρ+∇U (θ)·∇p ρ+(h/2)∇p ·(Σ(θ)M∇p ρ)+(h/2)β∇p ·(Σ(θ)pρ)


+ξ∇p ·(pρ)+Aβ −1 ∇p ·(M∇p ρ)−µ−1 pT M−1 p−Nd kB T ∇ξ ρ .
Just insert ρ̂β (13) into the Fokker-Planck operator L† to see that it vanishes.
The incorporation of the parameter-dependent covariance matrix Σ(θ) in (12) is intended to offset
the covariance matrix coming from the gradient approximation. However, in practice, one does not
know Σ(θ) a priori. Thus instead one must estimate Σ(θ) during the simulation, a task which will
be addressed in Section 3.1. This procedure is related to the method used in the SGHMC method
proposed by Chen et al. [4], which uses dynamics of the following form:
dθ = M−1 pdt ,
p
p
(14)
dp = −∇U (θ)dt+ hΣ(θ)M1/2 dW−Apdt+ 2β −1 (AI−βhΣ(θ)/2)M1/2 dWA .
It can be shown that the SGHMC method preserves the Gibbs canonical distribution:
ρβ (θ, p) = Z −1 exp (−βH(θ, p)) .
(15)
Although both CCAdL (12) and SGHMC (14) preserve their respective invariant distributions, let
us note several advantages of the former over the latter in practice:
(i) CCAdL and SGHMC both require estimation of the covariance matrix Σ(θ) during simulation, which can be costly in high dimension. In numerical experiments, we have found
that simply using the diagonal of the covariance matrix, at significantly reduced computational cost, works quite well in CCAdL. By contrast, it is difficult to find a suitable value
of the parameter A in SGHMC since one has to make sure the matrix AI−βhΣ(θ)/2 is
positive semi-definite. One may attempt to use a large value of the “effective friction” A
and/or a small stepsize h. However, too-large a friction would essentially reduce SGHMC
to SGLD, which is not desirable, as pointed out in [4], while extremely small stepsize
would significantly impact the computational efficiency.
(ii) Estimation of the covariance matrix Σ(θ) unavoidably introduces additional noise in both
CCAdL and SGHMC. Nonetheless, CCAdL can still effectively control the system temperature (i.e. maintaining the correct distribution of the momenta) due to the use of the
stabilizing Nosé-Hoover control, while in SGHMC, poor estimation of the covariance matrix may lead to significant deviations of the system temperature (as well as the distribution
of the momenta), resulting in poor sampling of the parameters of interest.
3.1

Covariance Estimation of Noisy Gradients

Under the assumption that the noise of the stochastic gradient follows a normal distribution, we
apply a similar method to that of [2] to estimate the covariance matrix associated with the noisy
gradient. If we let g(θ; x) = ∇θ log π(x|θ) and assume that the size of subset n is large enough for
the central limit theorem to hold, we have


n
1
1X
g(θ t ; xri ) ∼ N Ex [g(θ t ; x)], It ,
(16)
n i=1
n
where It = Cov[g(θ t ; x)] is the covariance of the gradient at θ t . Given the noisy (stochastic)
Pn
gradient based on the current subset ∇Ũ (θ t ) = − N
i=1 g(θ t ; xri )−∇ log π(θ t ) and the clean
n
4

Algorithm 1 Covariance-Controlled Adaptive Langevin (CCAdL) Thermostat
1:
2:
3:
4:
5:
6:
7:
8:

Input: h, A, {κt }T̂t=1 .
Initialize θ 0 , p0 , I0 , and ξ0 = A.
for t = 1, 2, . . . , T̂ do
θ t = θ t−1 +pt−1 h;
Estimate Ît using Eq. (18);
√
2
pt = pt−1 −∇Ũ (θ t )h− h2 Nn Ît pt−1 h−ξt−1 pt−1 h+ 2AhN (0, I);
ξt = ξt−1 + pTt pt /Nd −1 h;
end for

(full) gradient ∇U (θ t ) = −
and thus

PN

g(θ t ; xi )−∇ log π(θ t ), we have Ex [∇Ũ (θ t )] = Ex [∇U (θ t )],


N2
It ,
(17)
∇Ũ (θ t ) = ∇U (θ t )+N 0,
n
i.e. Σ(θ t ) = N 2 It /n. Assuming θ t does not change dramatically over time, we use the moving
average update to estimate It :
Ît = (1−κt )Ît−1 +κt V(θ t ) ,
(18)
where κt = 1/t and
n
1 X
T
V(θ t ) =
(g(θ t ; xri )−ḡ(θ t )) (g(θ t ; xri )−ḡ(θ t ))
(19)
n−1 i=1
is the empirical covariance of the gradient. ḡ(θ t ) represents the mean gradient of the log likelihood
computed from a subset. As proved in [2], this estimator has a convergence order of O(1/N ).
i=1

As already mentioned, estimating the full covariance matrix is computationally infeasible in high
dimension. However, we have found that employing a diagonal approximation of the covariance
matrix (i.e. estimating the variance only along each dimension of the noisy gradient) works quite
well in practice, as demonstrated in Section 4.
The procedure of the CCAdL method is summarized in Algorithm 1, where we simply used M = I,
β = 1, and µ = Nd in order to be consistent with the original implementation of SGNHT [5].
Note that this is a simple, first order (in terms of the stepsize) algorithm. A recent article [15] has
introduced higher order of accuracy schemes which can improve accuracy, but our interest here is in
the direct comparison of the underlying machinery of SGHMC, SGNHT, and CCAdL, so we avoid
further modifications and enhancements related to timestepping at this stage.
In the following section, we compare the newly established CCAdL method with SGHMC and
SGNHT on various machine learning tasks to demonstrate the benefits of CCAdL in Bayesian sampling with a noisy gradient.

4
4.1

Numerical Experiments
Bayesian Inference for Gaussian Distribution

We first compare the performance of the newly established CCAdL method with SGHMC and
SGNHT for a simple task using synthetic data, i.e. Bayesian inference of both the mean and variance of a one-dimensional normal distribution. We apply the same experimental setting as in [5]. We
generated N = 100 samples from a standard normal distribution N (0, 1). We used the likelihood
function of N (xi |µ, γ −1 ) and assigned a Normal-Gamma distribution as their prior distribution, i.e.
µ, γ ∼ N (µ|0, γ)Gam(γ|1, 1). Then the corresponding posterior distribution is another NormalGamma distribution, i.e. (µ, γ)|X ∼ N (µ|µN , (κN γ)−1 )Gam(γ|αN , βN ), with
N
X
N
(xi − x̄)2
N x̄2
N x̄
,
κN = 1+N ,
αN = 1+ ,
βN = 1+
+
,
µN =
N +1
2
2
2(1+N )
i=1
PN
where x̄ = i=1 xi /N . A random subset of size n = 10 was selected at each timestep to approximate the full gradient, resulting in the
following stochastic gradients:
n
n
γN X
N +1 µ2 N X
∇µ Ũ = (N +1)µγ −
x ri ,
∇γ Ũ = 1−
+ +
(xr −µ)2 .
n i=1
2γ
2 2n i=1 i
5

It can be seen that the variance of the stochastic gradient noise is no longer constant and actually
depends on the size of the subset, n, and the values of µ and γ in each iteration. This directly violates
the constant noise variance assumption of SGNHT [5], while CCAdL adjusts to the varying noise
variance.
The marginal distributions of µ and γ obtained from various methods with different combinations
of h and A were compared and plotted in Figure 1, with Table 1 consisting of the corresponding
root mean square error (RMSE) of the distribution and autocorrelation time from 106 samples. In
most of the cases, both SGNHT and CCAdL easily outperform the SGHMC method possibly due
to the presence of the Nosé-Hoover device, with SGHMC only showing superiority with a small
value of h and a large value of A, neither of which is desirable in practice as discussed in Section 3.
Between SGNHT and the newly proposed CCAdL method, the latter achieves better performance in
each of the cases investigated, highlighting the importance of the covariance control with parameterdependent noise.
3

3

2

2

1

1

1

0
−0.5

0
−0.5

0
−0.5

2

0
µ

0.5

True
SGHMC
SGNHT
CCAdL

3
2
1

1

0
0.5

0
0.5

0
0.5

1
γ

1.5

(a) h = 0.001, A = 1

1
γ

0
µ

1.5

(b) h = 0.001, A = 10

0.5

True
SGHMC
SGNHT
CCAdL

2

1

4

True
SGHMC
SGNHT
CCAdL

3
2
1

3
Density

True
SGHMC
SGNHT
CCAdL

3
Density

0.5

Density

0
µ

True
SGHMC
SGNHT
CCAdL

Density

2

4

True
SGHMC
SGNHT
CCAdL

0
−0.5

0
µ

0.5

True
SGHMC
SGNHT
CCAdL

3
Density

Density

3

4

Density

True
SGHMC
SGNHT
CCAdL

Density

4

2
1

1
γ

1.5

(c) h = 0.01, A = 1

0
0.5

1
γ

1.5

(d) h = 0.01, A = 10

Figure 1: Comparisons of marginal distribution (density) of µ (top row) and γ (bottom row) with various
values of h and A indicated in each column. The peak region is highlighted in the inset.

Table 1: Comparisons of (RMSE, Autocorrelation time) of (µ, γ) of various methods for Bayesian inference
of the mean and variance of a Gaussian distribution.
Methods
h = 0.001, A = 1 h = 0.001, A = 10 h = 0.01, A = 1 h = 0.01, A = 10
SGHMC
(0.0148, 236.12)
(0.0029, 333.04)
(0.0531, 29.78)
(0.0132, 39.33)
SGNHT
(0.0037, 238.32)
(0.0035, 406.71)
(0.0044, 26.71)
(0.0043, 55.00)
CCAdL
(0.0034, 238.06)
(0.0031, 402.45)
(0.0021, 26.71) (0.0035, 54.43)

4.2

Large-scale Bayesian Logistic Regression

We then consider a Bayesian logistic regression model trained on the benchmark MNIST dataset
for binary classification of digits 7 and 9 using 12, 214 training data points, with a test set of size
2037. A 100-dimensional random projection of the original features was used. We used the likeliQN
T
hood function of π {xi , yi }N
i=1 |w ∝
i=1 1/ 1+exp(−yi w xi ) and the prior distribution of
T
π(w) ∝ exp(−w w/2). A subset of size n = 500 was used at each timestep. Since the dimensionality of this problem is not that high, a full covariance estimation was used for CCAdL.
We investigate in Figure 2 (top row) the convergence speed of each method through measuring test
log likelihood using the posterior mean against the number of passes over the entire dataset. CCAdL
displays significant improvements over SGHMC and SGNHT with different values of h and A:
(1) CCAdL converges much faster than the other two, which also indicates its faster mixing speed
and shorter burn-in period; (2) CCAdL shows robustness in different values of the effective friction
A, with SGHMC and SGNHT relying on a relative large value of A (especially for the SGHMC
method), which is intended to dominate the gradient noise.
To compare the sample quality obtained from each method, Figure 2 (bottom row) plots the twodimensional marginal posterior distribution in randomly selected dimensions of 2 and 5 based on
106 samples from each method after the burn-in period (i.e. we start to collect samples when the test
6

log likelihood stabilizes). The true (reference) distribution was obtained by a sufficiently long run of
standard HMC. We implemented 10 runs of standard HMC and found there was no variation between
these runs, which guarantees its qualification as the true (reference) distribution. Again, CCAdL
shows much better performance than SGHMC and SGNHT. Note that the contour of SGHMC does
not even fit in the region of the plot, and in fact it shows significant deviation even in the estimation
of the mean.

−500
SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

−700
−800
0

200
400
Number of Passes

−500
−600
−700
−800

600

0

−3

5
0

−800

300

0

10
5

300

True(HMC)
SGHMC
SGNHT
CCAdL

15
10
5
0

−5
0.03 0.035 0.04 0.045 0.05 0.055
w2

(a) h = 0.2×10−4

100
200
Number of Passes

x 10
True(HMC)
SGHMC
SGNHT
CCAdL

0

−5
0.03 0.035 0.04 0.045 0.05 0.055
w2

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

−700

−3

15

w5

5

w

−600

x 10
True(HMC)
SGHMC
SGNHT
CCAdL

10

100
200
Number of Passes

−500

−3

x 10
15

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

−400

w5

−600

−300

−400

Test Log Likelihood

−300

−400

Test Log Likelihood

Test Log Likelihood

−300

(b) h = 0.5×10−4

−5
0.03 0.035 0.04 0.045 0.05 0.055
w2

(c) h = 1×10−4

Figure 2: Comparisons of Bayesian logistic regression of various methods on the MNIST dataset of digits 7
and 9 with various values of h and A: (top row) test log likelihood using the posterior mean against the number
of passes over the entire dataset; (bottom row) two-dimensional marginal posterior distribution in (randomly
selected) dimensions 2 and 5 with A = 10 fixed, based on 106 samples from each method after the burn-in
period (i.e. we start to collect samples when the test log likelihood stabilizes). Magenta circle is the true
(reference) posterior mean obtained from standard HMC and crosses represent the sample means computed
from various methods. Ellipses represent iso-probability contours covering 95% probability mass. Note that
the contour of SGHMC is well beyond the scale of the plot especially in the large stepsize regime, in which
case we do not include it here.

4.3

Discriminative Restricted Boltzmann Machine (DRBM)

DRBM [11] is a self-contained non-linear classifier, and the gradient of its discriminative objective
can be explicitly computed. Due to the limited space, we refer the readers to [11] for more details.
We trained a DRBM on different large-scale multi-class datasets from the LIBSVM1 dataset collection, including connect-4, letter, and SensIT Vehicle acoustic. The detailed information of these
datasets are presented in Table 2.
We selected the number of hidden units using cross-validation to achieve their best results. Since the
dimension of parameters, Nd , is relatively high, we used only diagonal covariance matrix estimation
for CCAdL to significantly reduce the computational cost, i.e. estimating the variance only along
each dimension. The size of the subset was chosen as 500–1000 to obtain a reasonable variance
estimation. For each dataset, we chose the first 20% of the total number of passes over the entire
dataset as the burn-in period and collected the remaining samples for prediction.
Table 2: Datasets used in DRBM with corresponding parameter configurations.
Datasets
connect-4
letter
acoustic

training/test set
54,046/13,511
10,500/5,000
78,823/19,705

classes
3
26
3

features
126
16
50

hidden units
20
100
20

total number of parameters Nd
2603
4326
1083

The error rates computed by various methods on the test set using the posterior mean against the
number of passes over the entire dataset were plotted in Figure 3. It can be observed that SGHMC
and SGNHT only work well with a large value of the effective friction A, which corresponds to a
strong random walk effect and thus slows down the convergence. On the contrary, CCAdL works
1

http://www.csie.ntu.edu.tw/˜cjlin/libsvmtools/datasets/multiclass.html

7

reliably (much better than the other two) in a wide range of A, and more importantly in the large
stepsize regime, which speeds up the convergence rate in relation to the computational work performed. It can be easily seen that the performance of SGHMC heavily relies on using a small value
of h and a large value of A, which significantly limits its usefulness in practice.

0.29

0.29
0.28

0.27

0.27

50

100
150
Number of Passes

200

Test Error

0.15
0.1

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

100

100
150
Number of Passes

0.3

50

100
150
Number of Passes

(3a) acoustic, h = 0.2×10

200

−3

100
150
Number of Passes

200

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

0.25
0.2
0.15
0.1

200
300
Number of Passes

0.4

400

100

0.3

50

100
150
Number of Passes

(3b) acoustic, h = 0.5×10

200
300
Number of Passes

400

(2c) letter, h = 5×10−3

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

0.35

0.25

50

(1c) connect-4, h = 2×10−3

(2b) letter, h = 2×10−3

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

0.35

0.15

100

Test Error

0.4

0.3
0.29

0.27

200

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

0.2

400

(2a) letter, h = 1×10−3

0.25

50

0.1

200
300
Number of Passes

0.31

0.28

0.25

0.2

SGHMC, A=10
SGHMC, A=50
SGNHT, A=10
SGNHT, A=50
CCAdL, A=10
CCAdL, A=50

0.32

(1b) connect-4, h = 1×10−3

0.25
Test Error

0.3

0.28

(1a) connect-4, h = 0.5×10−3

Test Error

0.31

0.33

Test Error

0.3

SGHMC, A=10
SGHMC, A=50
SGNHT, A=10
SGNHT, A=50
CCAdL, A=10
CCAdL, A=50

0.32

200

−3

0.4

Test Error

Test Error

0.31

0.33

Test Error

SGHMC, A=10
SGHMC, A=50
SGNHT, A=10
SGNHT, A=50
CCAdL, A=10
CCAdL, A=50

0.32

Test Error

0.33

SGHMC, A=1
SGHMC, A=10
SGNHT, A=1
SGNHT, A=10
CCAdL, A=1
CCAdL, A=10

0.35

0.3

0.25

50

100
150
Number of Passes

200

−3

(3c) acoustic, h = 1×10

Figure 3: Comparisons of DRBM on datasets connect-4 (top row), letter (middle row), and acoustic (bottom
row) with various values of h and A indicated: test error rates of various methods using the posterior mean
against the number of passes over the entire dataset.

5

Conclusions and Future Work

In this article, we have proposed a novel CCAdL formulation that can effectively dissipate
parameter-dependent noise while maintaining a desired invariant distribution. CCAdL combines
ideas of SGHMC and SGNHT from the literature, but achieves significant improvements over each
of these methods in practice. The additional error introduced by covariance estimation is expected
to be small in a relative sense, i.e. substantially smaller than the error arising from the noisy gradient. Our findings have been verified in large-scale machine learning applications. In particular, we
have consistently observed that SGHMC relies on a small stepsize h and a large friction A, which
significantly reduces its usefulness in practice as discussed. The techniques presented in this article
could be of use in more general settings of large-scale Bayesian sampling and optimization, which
we leave for future work.
A naive nonsymmetric splitting method has been applied for CCAdL for fair comparison in this
article. However, we point out that optimal design of splitting methods in ergodic SDE systems has
been explored recently in the mathematics community [1, 13, 14]. Moreover, it has been shown
in [15] that a certain type of symmetric splitting method for the Ad-Langevin/SGNHT method with
a clean (full) gradient inherits the superconvergence property (i.e. fourth order convergence to the
invariant distribution for configurational quantities) recently demonstrated in the setting of Langevin
dynamics [12, 14]. We leave further exploration of this direction in the context of noisy gradients
for future work.
8

References
[1] A. Abdulle, G. Vilmart, and K. C. Zygalakis. Long time accuracy of Lie-Trotter splitting
methods for Langevin dynamics. SIAM Journal on Numerical Analysis, 53(1):1–16, 2015.
[2] S. Ahn, A. Korattikara, and M. Welling. Bayesian posterior sampling via stochastic gradient
Fisher scoring. In Proceedings of the 29th International Conference on Machine Learning,
pages 1591–1598, 2012.
[3] S. Brooks, A. Gelman, G. Jones, and X.-L. Meng. Handbook of Markov Chain Monte Carlo.
CRC Press, 2011.
[4] T. Chen, E. B. Fox, and C. Guestrin. Stochastic gradient Hamiltonian Monte Carlo. In Proceedings of the 31st International Conference on Machine Learning, pages 1683–1691, 2014.
[5] N. Ding, Y. Fang, R. Babbush, C. Chen, R. D. Skeel, and H. Neven. Bayesian sampling using
stochastic gradient thermostats. In Advances in Neural Information Processing Systems 27,
pages 3203–3211, 2014.
[6] S. Duane, A. D. Kennedy, B. J. Pendleton, and D. Roweth. Hybrid Monte Carlo. Physics
Letters B, 195(2):216–222, 1987.
[7] D. Frenkel and B. Smit. Understanding Molecular Simulation: From Algorithms to Applications, Second Edition. Academic Press, 2001.
[8] W. G. Hoover. Computational Statistical Mechanics, Studies in Modern Thermodynamics.
Elsevier Science, 1991.
[9] A. M. Horowitz. A generalized guided Monte Carlo algorithm. Physics Letters B, 268(2):247–
252, 1991.
[10] A. Jones and B. Leimkuhler. Adaptive stochastic methods for sampling driven molecular systems. The Journal of Chemical Physics, 135(8):084125, 2011.
[11] H. Larochelle and Y. Bengio. Classification using discriminative restricted Boltzmann machines. In Proceedings of the 25th International Conference on Machine Learning, pages
536–543, 2008.
[12] B. Leimkuhler and C. Matthews. Rational construction of stochastic numerical methods for
molecular sampling. Applied Mathematics Research eXpress, 2013(1):34–56, 2013.
[13] B. Leimkuhler and C. Matthews. Molecular Dynamics: With Deterministic and Stochastic
Numerical Methods. Springer, 2015.
[14] B. Leimkuhler, C. Matthews, and G. Stoltz. The computation of averages from equilibrium and
nonequilibrium Langevin molecular dynamics. IMA Journal of Numerical Analysis, 36(1):13–
79, 2016.
[15] B. Leimkuhler and X. Shang. Adaptive thermostats for noisy gradient systems. SIAM Journal
on Scientific Computing, 2016.
[16] N. Metropolis, A. W. Rosenbluth, M. N. Rosenbluth, A. H. Teller, and E. Teller. Equation of
state calculations by fast computing machines. The Journal of Chemical Physics, 21(6):1087,
1953.
[17] S. Nosé. A unified formulation of the constant temperature molecular dynamics methods. The
Journal of Chemical Physics, 81(1):511, 1984.
[18] H. Robbins and S. Monro. A stochastic approximation method. Annals of Mathematical
Statistics, 22(2):400–407, 1951.
[19] C. Robert and G. Casella. Monte Carlo Statistical Methods, Second Edition. Springer, 2004.
[20] S. J. Vollmer, K. C. Zygalakis, and Y. W. Teh. (Non-) asymptotic properties of stochastic
gradient Langevin dynamics. arXiv preprint arXiv:1501.00438, 2015.
[21] M. Welling and Y. W. Teh. Bayesian learning via stochastic gradient Langevin dynamics. In
Proceedings of the 28th International Conference on Machine Learning, pages 681–688, 2011.

9

",mont carlo sampl bayesian posterior infer common approach use machin learn markov chain mont carlo procedur use often discretetim analogu associ stochast differenti equat sde sde guarante leav invari requir posterior distribut area current research address comput benefit stochast gradient method set exist techniqu reli estim varianc covari subsampl error typic assum constant varianc articl propos covariancecontrol adapt langevin thermostat effect dissip parameterdepend nois maintain desir target distribut propos method achiev substanti speedup popular altern scheme largescal machin learn applic,covariancecontrol adapt langevin thermostat largescal bayesian sampl xiaocheng shang univers edinburgh x shang ac uk zhanx zhu univers edinburgh zhanx zhu ac uk benedict leimkuhl univers edinburgh b leimkuhl ac uk amo j storkey univers edinburgh storkey ac uk abstract mont carlo sampl bayesian posterior infer common approach use machin learn markov chain mont carlo procedur use often discretetim analogu associ stochast differenti equat sde sde guarante leav invari requir posterior distribut area current research address comput benefit stochast gradient method set exist techniqu reli estim varianc covari subsampl error typic assum constant varianc articl propos covariancecontrol adapt langevin thermostat effect dissip parameterdepend nois maintain desir target distribut propos method achiev substanti speedup popular altern scheme largescal machin learn applic introduct machin learn applic direct sampl entir largescal dataset comput infeas instanc standard markov chain mont carlo mcmc method [ ] well typic hybrid mont carlo hmc method [ ] requir calcul accept probabl creation inform propos base whole dataset order improv comput effici number stochast gradient method [ ] propos set bayesian sampl base random much small subset approxim likelihood whole dataset thu substanti reduc comput cost practic well teh propos socal stochast gradient langevin dynam sgld [ ] combin idea stochast optim [ ] tradit brownian dynam sequenc stepsiz decreas zero fix stepsiz often adopt practic choic articl vollmer et al [ ] modifi sgld msgld also introduc design reduc sampl bia sgld gener sampl first order brownian dynam thu fix timestep one show unabl dissip excess nois gradient approxim maintain desir invari distribut [ ] stochast gradient hamiltonian mont carlo sghmc method propos chen et al [ ] reli second order langevin dynam incorpor parameterdepend diffus matrix intend effect offset stochast perturb gradient howev difficult accommod addit diffus term practic first second author contribut equal list author order decid lot moreov point [ ] poor estim may signific advers influenc sampl target distribut exampl effect system temperatur may alter thermostat idea wide use molecular dynam [ ] recent adopt stochast gradient nosehoov thermostat sgnht d et al [ ] order adjust kinet energi simul way canon ensembl preserv e prescrib constant temperatur distribut maintain fact sgnht method essenti equival adapt langevin adlangevin thermostat propos earli jone leimkuhl [ ] molecular dynam set see [ ] discuss despit substanti interest gener method mathemat foundat stochast gradient method incomplet underli dynam sgnht method [ ] take leimkuhl shang [ ] togeth design discret scheme high effect order accuraci sgnht method design base assumpt constant nois varianc articl propos covariancecontrol adapt langevin ccadl thermostat handl parameterdepend nois improv robust reliabl practic effect speed converg desir invari distribut largescal machin learn applic rest articl organ follow section describ set bayesian sampl noisi gradient briefli review exist techniqu section consid construct novel ccadl method effect dissip parameterdepend nois maintain correct distribut variou numer experi perform section verifi use ccadl wide rang largescal machin learn applic final summar find section bayesian sampl noisi gradient typic set bayesian sampl [ ] one interest draw state posterior distribut defin x x rnd paramet vector interest x denot entir dataset x likelihood prior distribut respect introduc potenti energi function u defin x exp u posit paramet interpret proport reciproc temperatur associ physic system e kb kb boltzmann constant temperatur practic often set uniti notat simplic take logarithm yield u log x log assum datum independ ident distribut logarithm likelihood calcul n x log x log xi n size entir dataset howev alreadi mention comput infeas deal entir largescal dataset timestep would typic requir mcmc hmc method instead order improv effici random much small e n n subset prefer stochast gradient method likelihood dataset give paramet approxim n nx log x log xri n xri ni repres random subset x thu noisi potenti energi write n nx u log xri log n neg gradient potenti refer noisi forc e f u goal correctli sampl gibb distribut exp u [ ] gradient nois assum gaussian mean zero unknown varianc case one may rewrit noisi forc p f u r typic diagon matrix repres covari matrix nois p r vector standard normal random variabl note r actual equival n typic set numer integr withassociat stepsiz hone p p hf h u r hu h h r therefor assum constant covari matrix e ident matrix sgnht method d et al [ ] follow underli dynam write standard ito stochast differenti equat sde system [ ] pdt p dp u dt hm dwpdt dwa p pnd kb dt colloqui dw dwa repres vector independ wiener increment p often inform denot n dti [ ] coeffici repres strength artifici nois add system improv ergod term effect friction posit paramet proport varianc nois auxiliari variabl r govern nosehoov devic [ ] via neg feedback mechan e instantan temperatur averag kinet energi per degre freedom calcul kb pt pnd target temperatur dynam friction would decreas allow increas temperatur would increas temperatur target coupl paramet refer thermal mass molecular dynam set proposit see jone leimkuhl [ ] sgnht method preserv modifi gibb stationari distribut p z exp h p exp z normal constant h p pt pu hamiltonian ah proposit tell us sgnht method adapt dissip excess nois pump system maintain correct distribut varianc gradient nois need know priori long constant auxiliari variabl abl automat find mean valu fli howev parameterdepend covari matrix sgnht method would produc requir target distribut ding et al [ ] claim reason assum covari matrix constant size dataset n larg case varianc posterior small magnitud posterior varianc actual relat constanc howev gener constant simpli assum nonconst signific impact perform method notabl stabil measur larg usabl stepsiz therefor essenti approach handl parameterdepend nois follow section propos covariancecontrol thermostat effect dissip parameterdepend nois maintain target stationari distribut covariancecontrol adapt langevin thermostat mention previou section sgnht method dissip nois constant covari matrix covari matrix becom parameterdepend gener parameterdepend covari matrix impli requir thermal equilibrium e system can not expect converg desir invari distribut typic result poor estim function paramet interest fact case clear whether exist invari distribut order construct stochasticdynam system preserv canon distribut suggest add suitabl damp viscou term effect dissip parameterdepend gradient nois end propos follow covariancecontrol adapt langevin ccadl thermostat pdt p p dp u dt h dw h pdtpdt dwa pt pnd kb dt proposit ccadl thermostat preserv modifi gibb stationari distribut p z exp h p exp proof fokkerplanck equat correspond l p u p h p mp h p p p p p mp pt pnd kb insert fokkerplanck oper l see vanish incorpor parameterdepend covari matrix intend offset covari matrix come gradient approxim howev practic one know priori thu instead one must estim simul task address section procedur relat method use sghmc method propos chen et al [ ] use dynam follow form pdt p p dp u dt h dwapdt aih dwa show sghmc method preserv gibb canon distribut p z exp h p although ccadl sghmc preserv respect invari distribut let us note sever advantag former latter practic ccadl sghmc requir estim covari matrix simul costli high dimens numer experi find simpli use diagon covari matrix significantli reduc comput cost work quit well ccadl contrast difficult find suitabl valu paramet sghmc sinc one make sure matrix aih posit semidefinit one may attempt use larg valu effect friction andor small stepsiz h howev toolarg friction would essenti reduc sghmc sgld desir point [ ] extrem small stepsiz would significantli impact comput effici ii estim covari matrix unavoid introduc addit nois ccadl sghmc nonetheless ccadl still effect control system temperatur e maintain correct distribut momenta due use stabil nosehoov control sghmc poor estim covari matrix may lead signific deviat system temperatur well distribut momenta result poor sampl paramet interest covari estim noisi gradient assumpt nois stochast gradient follow normal distribut appli similar method [ ] estim covari matrix associ noisi gradient let g x log x assum size subset n larg enough central limit theorem hold n x g xri n ex [ g x ] n n cov [ g x ] covari gradient give noisi stochast pn gradient base current subset u n g xri log clean n algorithm covariancecontrol adapt langevin ccadl thermostat input h tt initi p pt h estim use eq pt pt u h h nn pt ht pt h ahn ptt pt nd h end full gradient u thu pn g xi log ex [ u ] ex [ u ] n u u n n e n n assum chang dramat time use move averag updat estim v n x v g xri g g xri g n empir covari gradient g repres mean gradient log likelihood comput subset prove [ ] estim converg order n alreadi mention estim full covari matrix comput infeas high dimens howev find employ diagon approxim covari matrix e estim varianc along dimens noisi gradient work quit well practic demonstr section procedur ccadl method summar algorithm simpli use nd order consist origin implement sgnht [ ] note simpl first order term stepsiz algorithm recent articl [ ] introduc high order accuraci scheme improv accuraci interest direct comparison underli machineri sghmc sgnht ccadl avoid modif enhanc relat timestep stage follow section compar newli establish ccadl method sghmc sgnht variou machin learn task demonstr benefit ccadl bayesian sampl noisi gradient numer experi bayesian infer gaussian distribut first compar perform newli establish ccadl method sghmc sgnht simpl task use synthet datum e bayesian infer mean varianc onedimension normal distribut appli experiment set [ ] gener n sampl standard normal distribut n use likelihood function n xi assign normalgamma distribut prior distribut e n gam correspond posterior distribut anoth normalgamma distribut e x n n n gam n n n x n xi x n x n x n n n n n n n pn x xi n random subset size n select timestep approxim full gradient result follow stochast gradient n n n x n n x u n x ri u xr n n see varianc stochast gradient nois longer constant actual depend size subset n valu iter directli violat constant nois varianc assumpt sgnht [ ] ccadl adjust vari nois varianc margin distribut obtain variou method differ combin h compar plot figur tabl consist correspond root mean squar error rmse distribut autocorrel time sampl case sgnht ccadl easili outperform sghmc method possibl due presenc nosehoov devic sghmc show superior small valu h larg valu neither desir practic discuss section sgnht newli propos ccadl method latter achiev good perform case investig highlight import covari control parameterdepend nois true sghmc sgnht ccadl h b h true sghmc sgnht ccadl true sghmc sgnht ccadl densiti true sghmc sgnht ccadl densiti densiti true sghmc sgnht ccadl densiti true sghmc sgnht ccadl true sghmc sgnht ccadl densiti densiti densiti true sghmc sgnht ccadl densiti c h h figur comparison margin distribut densiti top row bottom row variou valu h indic column peak region highlight inset tabl comparison rmse autocorrel time variou method bayesian infer mean varianc gaussian distribut method h h h h sghmc sgnht ccadl largescal bayesian logist regress consid bayesian logist regress model train benchmark mnist dataset binari classif digit use train datum point test set size dimension random project origin featur use use likeliqn hood function xi yi n w exp yi w xi prior distribut w exp w w subset size n use timestep sinc dimension problem high full covari estim use ccadl investig figur top row converg speed method measur test log likelihood use posterior mean number pass entir dataset ccadl display signific improv sghmc sgnht differ valu h ccadl converg much fast two also indic faster mix speed short burnin period ccadl show robust differ valu effect friction sghmc sgnht reli rel larg valu especi sghmc method intend domin gradient nois compar sampl qualiti obtain method figur bottom row plot twodimension margin posterior distribut randomli select dimens base sampl method burnin period e start collect sampl test log likelihood stabil true refer distribut obtain suffici long run standard hmc implement run standard hmc find variat run guarante qualif true refer distribut ccadl show much good perform sghmc sgnht note contour sghmc even fit region plot fact show signific deviat even estim mean sghmc sghmc sgnht sgnht ccadl ccadl number pass true hmc sghmc sgnht ccadl w h number pass x true hmc sghmc sgnht ccadl w sghmc sghmc sgnht sgnht ccadl ccadl w w x true hmc sghmc sgnht ccadl number pass x sghmc sghmc sgnht sgnht ccadl ccadl w test log likelihood test log likelihood test log likelihood b h w c h figur comparison bayesian logist regress variou method mnist dataset digit variou valu h top row test log likelihood use posterior mean number pass entir dataset bottom row twodimension margin posterior distribut randomli select dimens fix base sampl method burnin period e start collect sampl test log likelihood stabil magenta circl true refer posterior mean obtain standard hmc cross repres sampl mean comput variou method ellip repres isoprob contour cover probabl mass note contour sghmc well beyond scale plot especi larg stepsiz regim case includ discrimin restrict boltzmann machin drbm drbm [ ] selfcontain nonlinear classifi gradient discrimin object explicitli comput due limit space refer reader [ ] detail train drbm differ largescal multiclass dataset libsvm dataset collect includ connect letter sensit vehicl acoust detail inform dataset present tabl select number hide unit use crossvalid achiev good result sinc dimens paramet nd rel high use diagon covari matrix estim ccadl significantli reduc comput cost e estim varianc along dimens size subset choos obtain reason varianc estim dataset choos first total number pass entir dataset burnin period collect remain sampl predict tabl dataset use drbm correspond paramet configur dataset connect letter acoust trainingtest set class featur hidden unit total number paramet nd error rate comput variou method test set use posterior mean number pass entir dataset plot figur observ sghmc sgnht work well larg valu effect friction correspond strong random walk effect thu slow converg contrari ccadl work httpwww csie ntu edu tw cjlinlibsvmtoolsdatasetsmulticlass html reliabl much good two wide rang importantli larg stepsiz regim speed converg rate relat comput work perform easili see perform sghmc heavili reli use small valu h larg valu significantli limit use practic number pass test error sghmc sghmc sgnht sgnht ccadl ccadl number pass number pass acoust h number pass sghmc sghmc sgnht sgnht ccadl ccadl number pass number pass b acoust h number pass c letter h sghmc sghmc sgnht sgnht ccadl ccadl c connect h b letter h sghmc sghmc sgnht sgnht ccadl ccadl test error sghmc sghmc sgnht sgnht ccadl ccadl letter h number pass sghmc sghmc sgnht sgnht ccadl ccadl b connect h test error connect h test error test error sghmc sghmc sgnht sgnht ccadl ccadl test error test error test error sghmc sghmc sgnht sgnht ccadl ccadl test error sghmc sghmc sgnht sgnht ccadl ccadl number pass c acoust h figur comparison drbm dataset connect top row letter middl row acoust bottom row variou valu h indic test error rat variou method use posterior mean number pass entir dataset conclus futur work articl propos novel ccadl formul effect dissip parameterdepend nois maintain desir invari distribut ccadl combin idea sghmc sgnht literatur achiev signific improv method practic addit error introduc covari estim expect small rel sens e substanti small error aris noisi gradient find verifi largescal machin learn applic particular consist observ sghmc reli small stepsiz h larg friction significantli reduc use practic discuss techniqu present articl could use gener set largescal bayesian sampl optim leav futur work naiv nonsymmetr split method appli ccadl fair comparison articl howev point optim design split method ergod sde system explor recent mathemat commun [ ] moreov show [ ] certain type symmetr split method adlangevinsgnht method clean full gradient inherit superconverg properti e fourth order converg invari distribut configur quantiti recent demonstr set langevin dynam [ ] leav explor direct context noisi gradient futur work refer [ ] abdul g vilmart k c zygalaki long time accuraci lietrott split method langevin dynam siam journal numer analysi [ ] ahn korattikara well bayesian posterior sampl via stochast gradient fisher score proceed th intern confer machin learn page [ ] brook gelman g jone x l meng handbook markov chain mont carlo crc press [ ] chen e b fox c guestrin stochast gradient hamiltonian mont carlo proceed st intern confer machin learn page [ ] n d fang r babbush c chen r skeel h neven bayesian sampl use stochast gradient thermostat advanc neural inform process system page [ ] duan kennedi b j pendleton roweth hybrid mont carlo physic letter b [ ] frenkel b smit understand molecular simul algorithm applic second edit academ press [ ] w g hoover comput statist mechan studi modern thermodynam elsevi scienc [ ] horowitz gener guid mont carlo algorithm physic letter b [ ] jone b leimkuhl adapt stochast method sampl drive molecular system journal chemic physic [ ] h larochel bengio classif use discrimin restrict boltzmann machin proceed th intern confer machin learn page [ ] b leimkuhl c matthew ration construct stochast numer method molecular sampl appli mathemat research express [ ] b leimkuhl c matthew molecular dynam determinist stochast numer method springer [ ] b leimkuhl c matthew g stoltz comput averag equilibrium nonequilibrium langevin molecular dynam i be go to journal numer analysi [ ] b leimkuhl x shang adapt thermostat noisi gradient system siam journal scientif comput [ ] n metropoli w rosenbluth n rosenbluth h teller e teller equat state calcul fast comput machin journal chemic physic [ ] nose unifi formul constant temperatur molecular dynam method journal chemic physic [ ] h robbin monro stochast approxim method annal mathemat statist [ ] c robert g casella mont carlo statist method second edit springer [ ] j vollmer k c zygalaki w teh non asymptot properti stochast gradient langevin dynam arxiv preprint arxiv [ ] well w teh bayesian learn via stochast gradient langevin dynam proceed th intern confer machin learn page
5,5714,Robust Portfolio Optimization,Poster,5714-robust-portfolio-optimization.pdf,"We propose a robust portfolio optimization approach based on quantile statistics. The proposed method is robust to extreme events in asset returns, and accommodates large portfolios under limited historical data. Specifically, we show that the risk of the estimated portfolio converges to the oracle optimal risk with parametric rate under weakly dependent asset returns. The theory does not rely on higher order moment assumptions, thus allowing for heavy-tailed asset returns. Moreover, the rate of convergence quantifies that the size of the portfolio under management is allowed to scale exponentially with the sample size of the historical data. The empirical effectiveness of the proposed method is demonstrated under both synthetic and real stock data. Our work extends existing ones by achieving robustness in high dimensions, and by allowing serial dependence.","Robust Portfolio Optimization

Fang Han
Department of Biostatistics
Johns Hopkins University
Baltimore, MD 21205
fhan@jhu.edu

Huitong Qiu
Department of Biostatistics
Johns Hopkins University
Baltimore, MD 21205
hqiu7@jhu.edu
Han Liu
Department of Operations Research
and Financial Engineering
Princeton University
Princeton, NJ 08544 hanliu@princeton.edu

Brian Caffo
Department of Biostatistics
Johns Hopkins University
Baltimore, MD 21205
bcaffo@jhsph.edu

Abstract
We propose a robust portfolio optimization approach based on quantile statistics.
The proposed method is robust to extreme events in asset returns, and accommodates large portfolios under limited historical data. Specifically, we show that the
risk of the estimated portfolio converges to the oracle optimal risk with parametric
rate under weakly dependent asset returns. The theory does not rely on higher order moment assumptions, thus allowing for heavy-tailed asset returns. Moreover,
the rate of convergence quantifies that the size of the portfolio under management
is allowed to scale exponentially with the sample size of the historical data. The
empirical effectiveness of the proposed method is demonstrated under both synthetic and real stock data. Our work extends existing ones by achieving robustness
in high dimensions, and by allowing serial dependence.

1

Introduction

Markowitz’s mean-variance analysis sets the basis for modern portfolio optimization theory [1].
However, the mean-variance analysis has been criticized for being sensitive to estimation errors in
the mean and covariance matrix of the asset returns [2, 3]. Compared to the covariance matrix,
the mean of the asset returns is more influential and harder to estimate [4, 5]. Therefore, many
studies focus on the global minimum variance (GMV) formulation, which only involves estimating
the covariance matrix of the asset returns.
Estimating the covariance matrix of asset returns is challenging due to the high dimensionality and
heavy-tailedness of asset return data. Specifically, the number of assets under management is usually
much larger than the sample size of exploitable historical data. On the other hand, extreme events
are typical in financial asset prices, leading to heavy-tailed asset returns.
To overcome the curse of dimensionality, structured covariance matrix estimators are proposed for
asset return data. [6] considered estimators based on factor models with observable factors. [7,
8, 9] studied covariance matrix estimators based on latent factor models. [10, 11, 12] proposed to
shrink the sample covariance matrix towards highly structured covariance matrices, including the
identity matrix, order 1 autoregressive covariance matrices, and one-factor-based covariance matrix
estimators. These estimators are commonly based on the sample covariance matrix. (sub)Gaussian
tail assumptions are required to guarantee consistency.
For heavy-tailed data, robust estimators of covariance matrices are desired. Classic robust covariance
matrix estimators include M -estimators, minimum volume ellipsoid (MVE) and minimum covari1

ance determinant (MCD) estimators, S-estimators, and estimators based on data outlyingness and
depth [13]. These estimators are specifically designed for data with very low dimensions and large
sample sizes. For generalizing the robust estimators to high dimensions, [14] proposed the Orthogonalized Gnanadesikan-Kettenring (OGK) estimator, which extends [15]’s estimator by re-estimating
the eigenvalues; [16, 17] studied shrinkage estimators based on Tyler’s M -estimator. However, although OGK is computationally tractable in high dimensions, consistency is only guaranteed under
fixed dimension. The shrunken Tylor’s M -estimator involves iteratively inverting large matrices.
Moreover, its consistency is only guaranteed when the dimension is in the same order as the sample size. The aforementioned robust estimators are analyzed under independent data points. Their
performance under time series data is questionable.
In this paper, we build on a quantile-based scatter matrix1 estimator, and propose a robust portfolio
optimization approach. Our contributions are in three aspects. First, we show that the proposed
method accommodates high dimensional data by allowing the dimension to scale exponentially
with sample size. Secondly, we verify that consistency of the proposed method is achieved without
any tail conditions, thus allowing for heavy-tailed asset return data. Thirdly, we consider weakly
dependent time series, and demonstrate how the degree of dependence affects the consistency of the
proposed method.

2

Background

In this section, we introduce the notation system, and provide a review on the gross-exposure constrained portfolio optimization that will be exploited in this paper.
2.1

Notation

Let v = (v1 , . . . , vd )T be a d-dimensional real vector, and M = [Mjk ] ∈ Rd1 ×d2 be a d1 × d2
matrix with Mjk as the (j, k) entry. For 0 < q < ∞, we define the `q vector norm of v as
Pd
kvkq := ( j=1 |vj |)1/q and the `∞ vector norm of v as kvk∞ := maxdj=1 |vj |. Let the matrix
qP
2
`max norm of M be kMkmax := maxjk |Mjk |, and the Frobenius norm be kMkF :=
jk Mjk .
d

Let X = (X1 , . . . , Xd )T and Y = (Y1 , . . . , Yd )T be two random vectors. We write X = Y if X
and Y are identically distributed. We use 1, 2, . . . to denote vectors with 1, 2, . . . at every entry.
2.2

Gross-exposure Constrained GMV Formulation

Under the GMV formulation, [18] found that imposing a no-short-sale constraint improves portfolio
efficiency. [19] relaxed the no-short-sale constraint by a gross-exposure constraint, and showed that
portfolio efficiency can be further improved.
Let X ∈ Rd be a random vector of asset returns. A portfolio is characterized by a vector of
investment allocations, w = (w1 , . . . , wd )T , among the d assets. The gross-exposure constrained
GMV portfolio optimization can be formulated as
min wT Σw s.t. 1T w = 1, kwk1 ≤ c.
(2.1)
w

Here Σ is the covariance matrix of X, 1T w = 1 is the budget constraint, and kwk1 ≤ c is the grossexposure constraint. c ≥ 1 is called the gross exposure constant, which controls the percentage
of long and short positions allowed in the portfolio [19]. The optimization problem (2.1) can be
converted into a quadratic programming problem, and solved by standard software [19].

3

Method

In this section, we introduce the quantile-based portfolio optimization approach. Let Z ∈ R be a
random variable with distribution function F , and {zt }Tt=1 be a sequence of observations from Z.
For a constant q ∈ [0, 1], we define the q-quantiles of Z and {zt }Tt=1 to be
Q(Z; q) = Q(F ; q) := inf{z : P(Z ≤ z) ≥ q},
n
o
b t }T ; q) := z (k) where k = min t : t ≥ q .
Q({z
t=1
T

1

A scatter matrix is defined to be any matrix proportional to the covariance matrix by a constant.

2

Here z (1) ≤ . . . ≤ z (T ) are the order statistics of {zt }Tt=1 . We say Q(Z; q) is unique if there
b t }T ; q) is unique if there exists a unique
exists a unique z such that P(Z ≤ z) = q. We say Q({z
t=1
(k)
z ∈ {z1 , . . . , zT } such that z = z . Following the estimator Qn [20], we define the population
and sample quantile-based scales to be
e 1/4) and σ
b
σ Q (Z) := Q(|Z − Z|;
bQ ({zt }Tt=1 ) := Q({|z
(3.1)
s − zt |}1≤s<t≤T ; 1/4).
Q
Q
Here Ze is an independent copy of Z. Based on σ and σ
b , we can further define robust scatter matrices for asset returns. In detail, let X = (X1 , . . . , Xd )T ∈ Rd be a random vector
representing the returns of d assets, and {Xt }Tt=1 be a sequence of observations from X, where
Xt = (Xt1 , . . . , Xtd )T . We define the population and sample quantile-based scatter matrices (QNE)
to be
bQ
bQ
RQ := [RQ
jk ] and R := [Rjk ],
b Q are given by
where the entries of RQ and R
Q
Q
b Q := σ
bQ ({Xtj }Tt=1 )2 ,
Rjj := σ (Xj )2 , R
jj
i
1h Q
2
Q
2
RQ
:=
,
σ
(X
+
X
)
−
σ
(X
−
X
)
j
k
j
k
jk
4
h
i
Q
T
2
Q
T
2
b Q := 1 σ
R
b
({X
+
X
}
)
−
σ
({X
−
X
}
)
.
tj
tk
tj
tk
t=1
t=1
jk
4
b Q is
Since σ
bQ can be computed using O(T log T ) time [20], the computational complexity of R
2
Q
b
O(d T log T ). Since T  d in practice, R can be computed almost as efficiently as the sample
covariance matrix, which has O(d2 T ) complexity.
Let w = (w1 , . . . , wd )T be the vector of investment allocations among the d assets. For a matrix
M, we define a risk function R : Rd × Rd×d → R by
R(w; M) := wT Mw.
When X has covariance matrix Σ, R(w; Σ) = Var(wT X) is the variance of the portfolio return,
wT X, and is employed as the objected function in the GMV formulation. However, estimating Σ
is difficult due to the heavy tails of asset returns. In this paper, we adopt R(w; RQ ) as a robust
alternative to the moment-based risk metric, R(w; Σ), and consider the following oracle portfolio
optimization problem:
wopt = argmin R(w; RQ ) s.t. 1T w = 1, kwk1 ≤ c.
(3.2)
w

Here kwk1 ≤ c is the gross-exposure constraint introduced in Section 2.2. In practice, RQ is
b Q onto the cone
unknown and has to be estimated. For convexity of the risk function, we project R
of positive definite matrices:


 Q
b − R
e Q = argminR 
R
R
max
(3.3)
s.t. R ∈ Sλ := {M ∈ Rd×d : MT = M, λmin Id  M  λmax Id }.
e Q . The optimization
Here λmin and λmax set the lower and upper bounds for the eigenvalues of R
problem (3.3) can be solved by a projection and contraction algorithm [21]. We summarize the
e Q , we formulate the empirical robust portfolio
algorithm in the supplementary material. Using R
optimization by
e Q ) s.t. 1T w = 1, kwk1 ≤ c.
e opt = argmin R(w; R
w
(3.4)
w

Remark 3.1. The robust portfolio optimization approach involves three parameters: λmin , λmax ,
and c. Empirically, setting λmin = 0.005 and λmax = ∞ proves to work well. c is typically provided
by investors for controlling the percentages of short positions. When a data-driven choice is desired,
we refer to [19] for a cross-validation-based approach.
Remark 3.2. The rationale behind the positive definite projection (3.3) lies in two aspects. First, in
order that the portfolio optimization is convex and well conditioned, a positive definite matrix with
lower bounded eigenvalues is needed. This is guaranteed by setting λmin > 0. Secondly, the projection (3.3) is more robust compared to the OGK estimate [14]. OGK induces positive definiteness
by re-estimating the eigenvalues using the variances of the principal components. Robustness is lost
when the data, possibly containing outliers, are projected onto the principal directions for estimating
the principal components.
3

Remark 3.3. We adopt the 1/4 quantile in the definitions of σ Q and σ
bQ to achieve 50% breakdown
point. However, we note that our methodology and theory carries through if 1/4 is replaced by any
absolute constant q ∈ (0, 1).

4

Theoretical Properties

In this section, we provide theoretical analysis of the proposed portfolio optimization approach. For
b opt , based on an estimate, R, of RQ , the next lemma shows that the error
an optimized portfolio, w
opt
b ; RQ ) and R(wopt ; RQ ) is essentially related to the estimation error in R.
between the risks R(w
opt
b
Lemma 4.1. Let w
be the solution to
min R(w; R) s.t. 1T w = 1, kwk1 ≤ c
(4.1)
w

for an arbitrary matrix R. Then, we have
b opt ; RQ ) − R(wopt ; RQ )| ≤ 2c2 kR − RQ kmax ,
|R(w
opt
where w
is the solution to the oracle portfolio optimization problem (3.2), and c is the grossexposure constant.
e opt ; RQ ), which relates to the rate of convergence
Next, we derive the rate of convergence for R(w
Q
Q
e − R kmax . To this end, we first introduce a dependence condition on the asset return series.
in kR
0
:= σ(Xt : t ≤ 0) and
Definition 4.2. Let {Xt }t∈Z be a stationary process. Denote by F−∞
Fn∞ := σ(Xt : t ≥ n) the σ-fileds generated by {Xt }t≤0 and {Xt }t≥n , respectively. The φ-mixing
coefficient is defined by
φ(n) :=
sup
|P(A | B) − P(A)|.
0
∞ ,P(B)>0
B∈F−∞
,A∈Fn

The process {Xt }t∈Z is φ-mixing if and only if limn→∞ φ(n) = 0.
Condition 1. {Xt ∈ Rd }t∈Z is a stationary process such that for any j 6= k ∈ {1, . . . , d},
{Xtj }t∈Z , {Xtj + Xtk }t∈Z , and {Xtj − Xtk }t∈Z are φ-mixing processes satisfying φ(n) ≤ 1/n1+
for any n > 0 and some constant  > 0.
The parameter  determines the rate of decay in φ(n), and characterizes the degree of dependence
in {Xt }t∈Z . Next, we introduce an identifiability condition on the distribution function of the asset
returns.
f = (X
e1 , . . . , X
ed )T be an independent copy of X1 . For any j 6= k ∈ {1, . . . , d},
Condition 2. Let X
ej |, |X1j + X1k − X
ej − X
ek |, and
let F1;j , F2;j,k , and F3;j,k be the distribution functions of |X1j − X
e
e
|X1j − X1k − Xj + Xk |. We assume there exist constants κ > 0 and η > 0 such that
d
inf
F (y) ≥ η
|y−Q(F ;1/4)|≤κ dy
for any F ∈ {F1;j , F2;j,k , F3;j,k : j 6= k = 1, . . . , d}.
Condition 2 guarantees the identifiability of the 1/4 quantiles, and is standard in the literature on
quantile statistics [22, 23]. Based on Conditions 1 and 2, we can present the rates of convergence
b Q and R
e Q.
for R
Theorem 4.3. Let {Xt }t∈Z be an absolutely continuous stationary process satisfying Conditions
1 and 2. Suppose log d/T → 0 as T → ∞. Then, for any α ∈ (0, 1) and T large enough, with
probability no smaller than 1 − 8α2 , we have
b Q − RQ kmax ≤ rT .
kR
(4.2)
Here the rate of convergence rT is defined by
r
n 2 h 4(1 + 2C )(log d − log α) 4C i2


rT = max 2
+
,
η
T
T
r
Q h
4(1 + 2C )(log d − log α) 4C io
4σmax
+
,
(4.3)
η
T
T
Q
Q
Q
Q
where
P∞ σmax1+:= max{σ (Xj ),Qσ (Xj + Xk ), σ (Xj − Xk ) : j 6= k ∈ {1, . . . , d}} and C :=
. Moreover, if R ∈ Sλ for Sλ defined in (3.3), we further have
k=1 1/k
e Q − RQ kmax ≤ 2rT .
kR
(4.4)
4

The implications of Theorem 4.3 are as follows.
Q
1. When the
p parameters η, , and σmax do not scale with T , the rate of convergence reduces
to OP ( log d/T ). Thus, the number of assets under management is allowed to scale
exponentially with sample size T . Compared to similar rates of convergence obtained
for sample-covariance-based estimators [24, 25, 9], we do not require any moment or tail
conditions, thus accommodating heavy-tailed asset return data.
2. The effect of serial dependence P
on the rate of convergence is characterized by C . Specif∞
ically, as  approaches 0, C = k=1 1/k 1+ increases towards infinity, inflating rT .  is
allowed to scale with T such that C = o(T / log d).
3. The rate of convergence rT is inversely related to the lower bound, η, on the marginal
density functions around the 1/4 quantiles. This is because when η is small, the distribution functions are flat around the 1/4 quantiles, making the population quantiles harder to
estimate.

e opt ; RQ ).
Combining Lemma 4.1 and Theorem 4.3, we obtain the rate of convergence for R(w
Theorem 4.4. Let {Xt }t∈Z be an absolutely continuous stationary process satisfying Conditions 1
and 2. Suppose that log d/T → 0 as T → ∞ and RQ ∈ Sλ . Then, for any α ∈ (0, 1) and T large
enough, we have
e opt ; RQ ) − R(wopt ; RQ )| ≤ 2c2 rT ,
|R(w
(4.5)
where rT is defined in (4.3) and c is the gross-exposure constant.
Theorem 4.4 shows that the risk of the estimated portfolio converges to the oracle optimal risk with
parametric rate rT . The number of assets, d, is allowed to scale exponentially with sample size T .
Moreover, the rate of convergence does not rely on any tail conditions on the distribution of the asset
returns.
For the rest of this section, we build the connection between the proposed robust portfolio optimization and its moment-based counterpart. Specifically, we show that they are consistent under the
elliptical model.
Definition 4.5. [26] A random vector X ∈ Rd follows an elliptical distribution with location µ ∈
Rd and scatter S ∈ Rd×d if and only if there exist a nonnegative random variable ξ ∈ R, a matrix
A ∈ Rd×r with rank(A) = r, a random vector U ∈ Rr independent from ξ and uniformly
distributed on the r-dimensional sphere, Sr−1 , such that
d

X = µ + ξAU .
T
Here S = AA has rank r. We denote X ∼ ECd (µ, S, ξ). ξ is called the generating variate.
Commonly used elliptical distributions include Gaussian distribution and t-distribution. Elliptical
distributions have been widely used for modeling financial return data, since they naturally capture
many stylized properties including heavy tails and tail dependence [27, 28, 29, 30, 31, 32]. The next
theorem relates RQ and R(w; RQ ) to their moment-based counterparts, Σ and R(w; Σ), under the
elliptical model.
Theorem 4.6. Let X = (X1 , . . . , Xd )T ∼ ECd (µ, S, ξ) be an absolutely continuous elliptical
f = (X
e1 , . . . , X
ed )T be an independent copy of X. Then, we have
random vector and X
RQ = mQ S
(4.6)
Q
for some constant m only depending on the distribution of X. Moreover, if 0 < Eξ 2 < ∞, we
have
RQ = cQ Σ and R(w; RQ ) = cQ R(w; Σ),
(4.7)
Q
where Σ = Cov(X) is the covariance matrix of X, and c is a constant given by
n (X + X − X
n (X − X
ej )2 1 o
ej − X
ek )2 1 o
j
j
k
cQ =Q
;
=Q
;
Var(Xj ) 4
Var(Xj + Xk )
4
n (X − X − X
o
2
ej + X
ek ) 1
j
k
=Q
;
.
(4.8)
Var(Xj − Xk )
4
Here the last two inequalities hold when Var(Xj + Xk ) > 0 and Var(Xj − Xk ) > 0.
5

By Theorem 4.6, under the elliptical model, minimizing the robust risk metric, R(w; RQ ), is equivalent with minimizing the standard moment-based risk metric, R(w; Σ). Thus, the robust portfolio
optimization (3.2) is equivalent to its moment-based counterpart (2.1) in the population level. Plugging (4.7) into (4.5) leads to the following theorem.
Theorem 4.7. Let {Xt }t∈Z be an absolutely continuous stationary process satisfying Conditions 1
and 2. Suppose that X1 ∼ ECd (µ, S, ξ) follows an elliptical distribution with covariance matrix
Σ, and log d/T → 0 as T → ∞. Then, we have
2c2
e opt ; Σ) − R(wopt ; Σ)| ≤ Q rT ,
|R(w
c
where c is the gross-exposure constant, cQ is defined in (4.8), and rT is defined in (4.3).
e opt , obtained from the robust portfolio
Thus, under the elliptical model, the optimal portfolio, w
optimization also leads to parametric rate of convergence for the standard moment-based risk.

5

Experiments

In this section, we investigate the empirical performance of the proposed portfolio optimization
approach. In Section 5.1, we demonstrate the robustness of the proposed approach using synthetic
heavy-tailed data. In Section 5.2, we simulate portfolio management using the Standard & Poor’s
500 (S&P 500) stock index data.
The proposed portfolio optimization approach (QNE) is compared with three competitors. These
competitors are constructed by replacing the covariance matrix Σ in (2.1) by commonly used covariance/scatter matrix estimators:
1. OGK: The orthogonalized Gnanadesikan-Kettenring estimator constructs a pilot scatter
matrix estimate using a robust τ -estimator of scale, then re-estimates the eigenvalues using
the variances of the principal components [14].
2. Factor: The principal factor estimator iteratively solves for the specific variances and the
factor loadings [33].
3. Shrink: The shrinkage estimator shrinkages the sample covariance matrix towards a onefactor covariance estimator[10].
5.1

Synthetic Data

Following [19], we construct the covariance matrix of the asset returns using a three-factor model:
Xj = bj1 f1 + bj2 f2 + bj3 f3 + εj , j = 1, . . . , d,
(5.1)
where Xj is the return of the j-th stock, bjk is the loadings of the j-th stock on factor fk , and εj is
the idiosyncratic noise independent of the three factors. Under this model, the covariance matrix of
the stock returns is given by
Σ = BΣf BT + diag(σ12 , . . . , σd2 ),
(5.2)
where B = [bjk ] is a d × 3 matrix consisting of the factor loadings, Σf is the covariance matrix
of the three factors, and σj2 is the variance of the noise εi . We adopt the covariance in (5.2) in our
simulations. Following [19], we generate the factor loadings B from a trivariate normal distribution,
Nd (µb , Σb ), where the mean, µb , and covariance, Σb , are specified in Table 1. After the factor
loadings are generated, they are fixed as parameters throughout the simulations. The covariance
matrix, Σf , of the three factors is also given in Table 1. The standard deviations, σ1 , . . . , σd , of the
idiosyncratic noises are generated independently from a truncated gamma distribution with shape
3.3586 and scale 0.1876, restricting the support to [0.195, ∞). Again these standard deviations are
fixed as parameters once they are generated. According to [19], these parameters are obtained by
fitting the three-factor model, (5.1), using three-year daily return data of 30 Industry Portfolios from
May 1, 2002 to Aug. 29, 2005. The covariance matrix, Σ, is fixed throughout the simulations. Since
we are only interested in risk optimization, we set the mean of the asset returns to be µ = 0. The
dimension of the stocks under consideration is fixed at d = 100.
Given the covariance matrix Σ, we generate the asset return data from the following three distributions.
D1 : multivariate Gaussian distribution, Nd (0, Σ);
6

Table 1: Parameters for generating the covariance matrix in Equation (5.2).
Parameters for factor loadings

1.8

2.0

risk

0.4
1.0

gross−exposure constant (c)

1.2

1.0

1.8

2.0

1.0

Factor
Shrink

1.0

1.2

1.4

1.6

1.8

gross−exposure constant (c)

Gaussian

2.0

1.6

1.8

2.0

QNE
OGK

Factor
Shrink

0.2
0.0

0.2

0.4

0.6

matching rate

0.8

QNE
OGK

1.4

elliptical log-normal

0.0

0.0

0.2

0.4

0.6

matching rate

0.8

Factor
Shrink

1.2

gross−exposure constant (c)

0.8

1.0

1.6

multivariate t

Gaussian
QNE
OGK

1.4

gross−exposure constant (c)

1.0

1.6

Factor
Shrink

0.6

1.4

Oracle
QNE
OGK

0.4

1.2

-0.2042
-0.0023
0.1930

0.2

0.4

risk

Factor
Shrink

0.2

0.2
1.0

-0.035
0.3156
-0.0023

0.8

Oracle
QNE
OGK

1.2507
-0.0350
-0.2042
1.0

1.0

0.01018
-0.00697
0.08686

0.8

Factor
Shrink

0.6

0.8

Oracle
QNE
OGK

0.02387
0.05395
-0.00697

0.4

risk

0.02915
0.02387
0.01018

Σf

0.6

1.0

0.7828
0.5180
0.4100

matching rate

Parameters for factor returns

Σb

0.6

µb

1.0

1.2

1.4

1.6

1.8

gross−exposure constant (c)

multivariate t

2.0

1.0

1.2

1.4

1.6

1.8

2.0

gross−exposure constant (c)

elliptical log-normal

Figure 1: Portfolio risks, selected number of stocks, and matching rates to the oracle optimal portfolios.
D2 : multivariate t distribution with degree of freedom 3 and covariance matrix Σ;
D2 : elliptical distribution with log-normal generating variate, log N (0, 2), and covariance matrix Σ.
Under each distribution, we generate asset return series of half a year (T = 126). We estimate
the covariance/scatter matrices using QNE and the three competitors, and plug them into (2.1) to
optimize the portfolio allocations. We also solve (2.1) with the true covariance matrix, Σ, to obtain
the oracle optimal portfolios as benchmarks. We range the gross-exposure constraint, c, from 1 to 2.
The results are based on 1,000 simulations.
b Σ) and the matching rates between the optimized portfolios
Figure 1 shows the portfolio risks R(w;
and the oracle optimal portfolios2 . Here the matching rate is defined as follows. For two portfolios
P1 and P2 , let S1 and S2 be the corresponding sets of selected assets, i.e., the assets for which
the T
weights, wS
i , are non-zero. The matching rate between P1 and P2 is defined as r(P1 , P2 ) =
|S1 S2 |/|S1 S2 |, where |S| denotes the cardinality of set S.
We note two observations from Figure 1. (i) The four estimators leads to comparable portfolio
risks under the Gaussian model D1 . However, under heavy-tailed distributions D2 and D3 , QNE
achieves lower portfolio risk. (ii) The matching rates of QNE are stable across the three models,
and are higher than the competing methods under heavy-tailed distributions D2 and D3 . Thus, we
conclude that QNE is robust to heavy tails in both risk minimization and asset selection.
5.2

Real Data

In this section, we simulate portfolio management using the S&P 500 stocks. We collect 1,258
adjusted daily closing prices3 for 435 stocks that stayed in the S&P 500 index from January 1, 2003
2

Due to the `1 regularization in the gross-exposure constraint, the solution is generally sparse.
The adjusted closing prices accounts for all corporate actions including stock splits, dividends, and rights
offerings.
3

7

Table 2: Annualized Sharpe ratios, returns, and risks under 4 competing approaches, using S&P 500
index data.

Sharpe ratio

c=1.0
c=1.2
c=1.4
c=1.6
c=1.8
c=2.0

QNE
2.04
1.89
1.61
1.56
1.55
1.53

OGK
1.64
1.39
1.24
1.31
1.48
1.51

Factor
1.29
1.22
1.34
1.38
1.41
1.43

Shrink
0.92
0.74
0.72
0.75
0.78
0.83

return (in %)

c=1.0
c=1.2
c=1.4
c=1.6
c=1.8
c=2.0

20.46
18.41
15.58
15.02
14.77
14.51

16.59
13.15
11.30
11.48
12.39
12.27

13.18
10.79
10.88
10.68
10.57
10.60

9.84
7.20
6.55
6.49
6.58
6.76

risk (in %)

c=1.0
c=1.2
c=1.4
c=1.6
c=1.8
c=2.0

10.02
9.74
9.70
9.63
9.54
9.48

10.09
9.46
9.10
8.75
8.39
8.13

10.19
8.83
8.12
7.71
7.51
7.43

10.70
9.76
9.14
8.68
8.38
8.18

to December 31, 2007. Using the closing prices, we obtain 1,257 daily returns as the daily growth
rates of the prices.
We manage a portfolio consisting of the 435 stocks from January 1, 2003 to December 31, 20074 .
On days i = 42, 43, . . . , 1, 256, we optimize the portfolio allocations using the past 2 months stock
return data (42 sample points). We hold the portfolio for one day, and evaluate the portfolio return
on day i + 1. In this way, we obtain 1,215 portfolio returns. We repeat the process for each of the
four methods under comparison, and range the gross-exposure constant c from 1 to 25 .
Since the true covariance matrix of the stock returns is unknown, we adopt the Sharpe ratio for
evaluating the performances of the portfolios. Table 2 summarizes the annualized Sharpe ratios,
mean returns, and empirical risks (i.e., standard deviations of the portfolio returns). We observe that
QNE achieves the largest Sharpe ratios under all values of the gross-exposure constant, indicating
the lowest risks under the same returns (or equivalently, the highest returns under the same risk).

6

Discussion

In this paper, we propose a robust portfolio optimization framework, building on a quantile-based
scatter matrix. We obtain non-asymptotic rates of convergence for the scatter matrix estimators and
the risk of the estimated portfolio. The relations of the proposed framework with its moment-based
counterpart are well understood.
The main contribution of the robust portfolio optimization approach lies in its robustness to heavy
tails in high dimensions. Heavy tails present unique challenges in high dimensions compared to
low dimensions.
For example, asymptotic theory of M -estimators guarantees consistency in the rate
p
OP ( d/n) even for non-Gaussian data [34, 35]. If d  n, statistical error diminishes rapidly with
increasing n. However, when d  n, statistical error may scale rapidly with dimension. Thus,
stringent tail conditions, such as subGaussian conditions, are required to guarantee consistency for
moment-based estimators in high dimensions [36]. In this paper, based on quantile statistics, we
achieve consistency for portfolio risk without assuming any tail conditions, while allowing d to
scale nearly exponentially with n.
Another contribution of his work lies in the theoretical analysis of how serial dependence may affect
consistency of the estimation. We measure the degree of serial dependence using the φ-mixing
coefficient, φ(n). We show that the effect of the serial dependence
P∞on the rate of convergence is
summarized by the parameter C , which characterizes the size of n=1 φ(n).
4

We drop the data after 2007 to avoid the financial crisis, when the stock prices are likely to violate the
stationary assumption.
5
c = 2 imposes a 50% upper bound on the percentage of short positions. In practice, the percentage of
short positions is usually strictly controlled to be much lower.

8

References
[1] Harry Markowitz. Portfolio selection. The Journal of Finance, 7(1):77–91, 1952.
[2] Michael J Best and Robert R Grauer. On the sensitivity of mean-variance-efficient portfolios to changes
in asset means: some analytical and computational results. Review of Financial Studies, 4(2):315–342,
1991.
[3] Vijay Kumar Chopra and William T Ziemba. The effect of errors in means, variances, and covariances on
optimal portfolio choice. The Journal of Portfolio Management, 19(2):6–11, 1993.
[4] Robert C Merton. On estimating the expected return on the market: An exploratory investigation. Journal
of Financial Economics, 8(4):323–361, 1980.
[5] Jarl G Kallberg and William T Ziemba. Mis-specifications in portfolio selection problems. In Risk and
Capital, pages 74–87. Springer, 1984.
[6] Jianqing Fan, Yingying Fan, and Jinchi Lv. High dimensional covariance matrix estimation using a factor
model. Journal of Econometrics, 147(1):186–197, 2008.
[7] James H Stock and Mark W Watson. Forecasting using principal components from a large number of
predictors. Journal of the American Statistical Association, 97(460):1167–1179, 2002.
[8] Jushan Bai, Kunpeng Li, et al. Statistical analysis of factor models of high dimension. The Annals of
Statistics, 40(1):436–465, 2012.
[9] Jianqing Fan, Yuan Liao, and Martina Mincheva. Large covariance estimation by thresholding principal
orthogonal complements. Journal of the Royal Statistical Society: Series B (Statistical Methodology),
75(4):603–680, 2013.
[10] Olivier Ledoit and Michael Wolf. Improved estimation of the covariance matrix of stock returns with an
application to portfolio selection. Journal of Empirical Finance, 10(5):603–621, 2003.
[11] Olivier Ledoit and Michael Wolf. A well-conditioned estimator for large-dimensional covariance matrices. Journal of Multivariate Analysis, 88(2):365–411, 2004.
[12] Olivier Ledoit and Michael Wolf. Honey, I shrunk the sample covariance matrix. The Journal of Portfolio
Management, 30(4):110–119, 2004.
[13] Peter J Huber. Robust Statistics. Wiley, 1981.
[14] Ricardo A Maronna and Ruben H Zamar. Robust estimates of location and dispersion for highdimensional datasets. Technometrics, 44(4):307–317, 2002.
[15] Ramanathan Gnanadesikan and John R Kettenring. Robust estimates, residuals, and outlier detection with
multiresponse data. Biometrics, 28(1):81–124, 1972.
[16] Yilun Chen, Ami Wiesel, and Alfred O Hero. Robust shrinkage estimation of high-dimensional covariance
matrices. IEEE Transactions on Signal Processing, 59(9):4097–4107, 2011.
[17] Romain Couillet and Matthew R McKay. Large dimensional analysis and optimization of robust shrinkage
covariance matrix estimators. Journal of Multivariate Analysis, 131:99–120, 2014.
[18] Ravi Jagannathan and T Ma. Risk reduction in large portfolios: Why imposing the wrong constraints
helps. The Journal of Finance, 58(4):1651–1683, 2003.
[19] Jianqing Fan, Jingjin Zhang, and Ke Yu. Vast portfolio selection with gross-exposure constraints. Journal
of the American Statistical Association, 107(498):592–606, 2012.
[20] Peter J Rousseeuw and Christophe Croux. Alternatives to the median absolute deviation. Journal of the
American Statistical Association, 88(424):1273–1283, 1993.
[21] M. H. Xu and H. Shao. Solving the matrix nearness problem in the maximum norm by applying a
projection and contraction method. Advances in Operations Research, 2012:1–15, 2012.
[22] Alexandre Belloni and Victor Chernozhukov. `1 -penalized quantile regression in high-dimensional sparse
models. The Annals of Statistics, 39(1):82–130, 2011.
[23] Lan Wang, Yichao Wu, and Runze Li. Quantile regression for analyzing heterogeneity in ultra-high
dimension. Journal of the American Statistical Association, 107(497):214–222, 2012.
[24] Peter J Bickel and Elizaveta Levina. Covariance regularization by thresholding. The Annals of Statistics,
36(6):2577–2604, 2008.
[25] T Tony Cai, Cun-Hui Zhang, and Harrison H Zhou. Optimal rates of convergence for covariance matrix
estimation. The Annals of Statistics, 38(4):2118–2144, 2010.
[26] Kai-Tai Fang, Samuel Kotz, and Kai Wang Ng. Symmetric Multivariate and Related Distributions. Chapman and Hall, 1990.
[27] Harry Joe. Multivariate Models and Dependence Concepts. Chapman and Hall, 1997.
[28] Rafael Schmidt. Tail dependence for elliptically contoured distributions. Mathematical Methods of Operations Research, 55(2):301–327, 2002.
[29] Svetlozar Todorov Rachev. Handbook of Heavy Tailed Distributions in Finance. Elsevier, 2003.
[30] Svetlozar T Rachev, Christian Menn, and Frank J Fabozzi. Fat-tailed and Skewed Asset Return Distributions: Implications for Risk Management, Portfolio Selection, and Option Pricing. Wiley, 2005.
[31] Kevin Dowd. Measuring Market Risk. Wiley, 2007.
[32] Torben Gustav Andersen. Handbook of Financial Time Series. Springer, 2009.
[33] Jushan Bai and Shuzhong Shi. Estimating high dimensional covariance matrices and its applications.
Annals of Economics and Finance, 12(2):199–215, 2011.
[34] Sara Van De Geer and SA Van De Geer. Empirical Processes in M -estimation. Cambridge University
Press, Cambridge, 2000.
[35] Alastair R Hall. Generalized Method of Moments. Oxford University Press, Oxford, 2005.
[36] Peter Bühlmann and Sara Van De Geer. Statistics for High-dimensional Data: Methods, Theory and
Applications. Springer, 2011.

9

",propos robust portfolio optim approach base quantil statist propos method robust extrem event asset return accommod larg portfolio limit histor datum specif show risk estim portfolio converg oracl optim risk parametr rate weakli depend asset return theori reli high order moment assumpt thu allow heavytail asset return moreov rate converg quantifi size portfolio manag allow scale exponenti sampl size histor datum empir effect propos method demonstr synthet real stock data work extend exist one achiev robust high dimens allow serial depend,robust portfolio optim fang han depart biostatist john hopkin univers baltimor md fhanjhu edu huitong qiu depart biostatist john hopkin univers baltimor md hqiujhu edu han liu depart oper research financi engin princeton univers princeton nj hanliuprinceton edu brian caffo depart biostatist john hopkin univers baltimor md bcaffojhsph edu abstract propos robust portfolio optim approach base quantil statist propos method robust extrem event asset return accommod larg portfolio limit histor datum specif show risk estim portfolio converg oracl optim risk parametr rate weakli depend asset return theori reli high order moment assumpt thu allow heavytail asset return moreov rate converg quantifi size portfolio manag allow scale exponenti sampl size histor datum empir effect propos method demonstr synthet real stock data work extend exist one achiev robust high dimens allow serial depend introduct markowitz meanvari analysi set basi modern portfolio optim theori [ ] howev meanvari analysi critic sensit estim error mean covari matrix asset return [ ] compar covari matrix mean asset return influenti hard estim [ ] therefor mani studi focu global minimum varianc gmv formul involv estim covari matrix asset return estim covari matrix asset return challeng due high dimension heavytailed asset return datum specif number asset manag usual much larg sampl size exploit histor data hand extrem event typic financi asset price lead heavytail asset return overcom curs dimension structur covari matrix estim propos asset return datum [ ] consid estim base factor model observ factor [ ] studi covari matrix estim base latent factor model [ ] propos shrink sampl covari matrix toward highli structur covari matrix includ ident matrix order autoregress covari matrix onefactorba covari matrix estim estim commonli base sampl covari matrix sub gaussian tail assumpt requir guarante consist heavytail datum robust estim covari matrix desir classic robust covari matrix estim includ estim minimum volum ellipsoid mve minimum covari anc determin mcd estim sestim estim base datum outlying depth [ ] estim specif design datum low dimens larg sampl size gener robust estim high dimens [ ] propos orthogon gnanadesikankettenr ogk estim extend [ ] estim reestim eigenvalu [ ] studi shrinkag estim base tyler estim howev although ogk comput tractabl high dimens consist guarante fix dimens shrunken tylor estim involv iter invert larg matrix moreov consist guarante dimens order sampl size aforement robust estim analyz independ datum point perform time seri datum question paper build quantileba scatter matrix estim propos robust portfolio optim approach contribut three aspect first show propos method accommod high dimension datum allow dimens scale exponenti sampl size secondli verifi consist propos method achiev without tail condit thu allow heavytail asset return datum thirdli consid weakli depend time seri demonstr degre depend affect consist propos method background section introduc notat system provid review grossexposur constrain portfolio optim exploit paper notat let v v vd ddimension real vector [ mjk ] rd matrix mjk j k entri q defin ` q vector norm v pd kvkq j vj q ` vector norm v kvk maxdj vj let matrix qp ` max norm kmkmax maxjk mjk frobeniu norm kmkf jk mjk let x x xd yd two random vector write x x ident distribut use denot vector everi entri grossexposur constrain gmv formul gmv formul [ ] find impos noshortsal constraint improv portfolio effici [ ] relax noshortsal constraint grossexposur constraint show portfolio effici improv let x rd random vector asset return portfolio character vector invest alloc w w wd among asset grossexposur constrain gmv portfolio optim formul min wt w w kwk c w covari matrix x w budget constraint kwk c grossexposur constraint c call gross exposur constant control percentag long short posit allow portfolio [ ] optim problem convert quadrat program problem solv standard softwar [ ] method section introduc quantilebas portfolio optim approach let z r random variabl distribut function f zt tt sequenc observ z constant q [ ] defin qquantil z zt tt q z q q f q inf z p z z q n b q z k k min q q z scatter matrix defin matrix proport covari matrix constant z z order statist zt tt say q z q uniqu b q uniqu exist uniqu exist uniqu z p z z q say q z k z z zt z z follow estim qn [ ] defin popul sampl quantileba scale e b q z q z z bq zt tt q z zt stt q q ze independ copi z base b defin robust scatter matrix asset return detail let x x xd rd random vector repres return asset xt tt sequenc observ x xt xt xtd defin popul sampl quantileba scatter matrix qne bq bq rq [ rq jk ] r [ rjk ] b q give entri rq r q q b q bq xtj tt rjj xj r jj h q q rq x x x x j k j k jk h q q b q r b x x x x tj tk tj tk jk b q sinc bq comput use log time [ ] comput complex r q b log sinc practic r comput almost effici sampl covari matrix complex let w w wd vector invest alloc among asset matrix defin risk function r rd rdd r r w wt mw x covari matrix r w var wt x varianc portfolio return wt x employ object function gmv formul howev estim difficult due heavi tail asset return paper adopt r w rq robust altern momentba risk metric r w consid follow oracl portfolio optim problem wopt argmin r w rq w kwk c w kwk c grossexposur constraint introduc section practic rq b q onto cone unknown estim convex risk function project r posit definit matrix q b r e q argminr r r max r rdd mt min i would max i would e q optim min max set low upper bound eigenvalu r problem solv project contract algorithm [ ] summar e q formul empir robust portfolio algorithm supplementari materi use r optim e q w kwk c e opt argmin r w r w w remark robust portfolio optim approach involv three paramet min max c empir set min max prove work well c typic provid investor control percentag short posit datadriven choic desir refer [ ] crossvalidationba approach remark rational behind posit definit project lie two aspect first order portfolio optim convex well condit posit definit matrix low bound eigenvalu need guarante set min secondli project robust compar ogk estim [ ] ogk induc posit definit reestim eigenvalu use varianc princip compon robust lose datum possibl contain outlier project onto princip direct estim princip compon remark adopt quantil definit q bq achiev breakdown point howev note methodolog theori carri replac absolut constant q theoret properti section provid theoret analysi propos portfolio optim approach b opt base estim r rq next lemma show error optim portfolio w opt b rq r wopt rq essenti relat estim error r risk r w opt b lemma let w solut min r w r w kwk c w arbitrari matrix r b opt rq r wopt rq c kr rq kmax r w opt w solut oracl portfolio optim problem c grossexposur constant e opt rq relat rate converg next deriv rate converg r w q q e r kmax end first introduc depend condit asset return seri kr xt definit let xt tz stationari process denot f fn xt n file gener xt xt tn respect mix coeffici defin n sup p b p p b bf afn process xt tz mix limn n condit xt rd tz stationari process j k xtj tz xtj xtk tz xtj xtk tz mix process satisfi n n n constant paramet determin rate decay n character degre depend xt tz next introduc identifi condit distribut function asset return f x e x ed independ copi x j k condit let x ej xj xk x ej x ek let fj fjk fjk distribut function xj x e e xj xk xj xk assum exist constant inf f yq f dy f fj fjk fjk j k condit guarante identifi quantil standard literatur quantil statist [ ] base condit present rate converg b q r e q r theorem let xt tz absolut continu stationari process satisfi condit suppos log dt larg enough probabl small b q rq kmax rt kr rate converg rt defin r n h c log log c rt max r q h c log log c io max q q q q p max max xj q xj xk xj xk j k c moreov r defin k k e q rq kmax rt kr implic theorem follow q p paramet max scale rate converg reduc op log dt thu number asset manag allow scale exponenti sampl size compar similar rate converg obtain samplecovarianceba estim [ ] requir moment tail condit thu accommod heavytail asset return datum effect serial depend p rate converg character c specif ical approach c k k increas toward infin inflat rt allow scale c log rate converg rt invers relat lower bind margin densiti function around quantil small distribut function flat around quantil make popul quantil harder estim e opt rq combin lemma theorem obtain rate converg r w theorem let xt tz absolut continu stationari process satisfi condit suppos log dt rq larg enough e opt rq r wopt rq c rt r w rt defin c grossexposur constant theorem show risk estim portfolio converg oracl optim risk parametr rate rt number asset allow scale exponenti sampl size moreov rate converg reli tail condit distribut asset return rest section build connect propos robust portfolio optim momentba counterpart specif show consist ellipt model definit [ ] random vector x rd follow ellipt distribut locat rd scatter rdd exist nonneg random variabl r matrix rdr rank r random vector u rr independ uniformli distribut rdimension sphere sr x au aa rank r denot x ecd call gener variat commonli use ellipt distribut includ gaussian distribut tdistribut ellipt distribut wide use model financi return datum sinc natur captur mani styliz properti includ heavi tail tail depend [ ] next theorem relat rq r w rq momentba counterpart r w ellipt model theorem let x x xd ecd absolut continu ellipt f x e x ed independ copi x random vector x rq mq q constant depend distribut x moreov e rq cq r w rq cq r w q cov x covari matrix x c constant give n x x x n x x ej ej x ek j j k cq q q var xj var xj xk n x x x ej x ek j k q var xj xk last two inequ hold var xj xk var xj xk theorem ellipt model minim robust risk metric r w rq equival minim standard momentba risk metric r w thu robust portfolio optim equival momentba counterpart popul level plug lead follow theorem theorem let xt tz absolut continu stationari process satisfi condit suppos x ecd follow ellipt distribut covari matrix log dt c e opt r wopt q rt r w c c grossexposur constant cq defin rt defin e opt obtain robust portfolio thu ellipt model optim portfolio w optim also lead parametr rate converg standard momentba risk experi section investig empir perform propos portfolio optim approach section demonstr robust propos approach use synthet heavytail data section simul portfolio manag use standard poor sp stock index datum propos portfolio optim approach qne compar three competitor competitor construct replac covari matrix commonli use covariancescatt matrix estim ogk orthogonaliz gnanadesikankettenr estim construct pilot scatter matrix estim use robust estim scale reestimat eigenvalu use varianc princip compon [ ] factor princip factor estim iter solv specif varianc factor load [ ] shrink shrinkag estim shrinkag sampl covari matrix toward onefactor covari estim [ ] synthet datum follow [ ] construct covari matrix asset return use threefactor model xj bj f bj f bj f j j xj return jth stock bjk load jth stock factor fk j idiosyncrat nois independ three factor model covari matrix stock return give bf bt diag b [ bjk ] matrix consist factor load f covari matrix three factor j varianc nois adopt covari simul follow [ ] gener factor load b trivari normal distribut nd b b mean b covari b specifi tabl factor load gener fix paramet throughout simul covari matrix f three factor also give tabl standard deviat idiosyncrat nois gener independ truncat gamma distribut shape scale restrict support [ standard deviat fix paramet gener accord [ ] paramet obtain fit threefactor model use threeyear daili return datum industri portfolio may aug covari matrix fix throughout simul sinc interest risk optim set mean asset return dimens stock consider fix give covari matrix gener asset return datum follow three distribut multivari gaussian distribut nd tabl paramet gener covari matrix equat paramet factor load risk grossexposur constant c factor shrink grossexposur constant c gaussian qne ogk factor shrink match rate qne ogk ellipt lognorm match rate factor shrink grossexposur constant c multivari gaussian qne ogk grossexposur constant c factor shrink oracl qne ogk risk factor shrink oracl qne ogk factor shrink oracl qne ogk risk f match rate paramet factor return b b grossexposur constant c multivari grossexposur constant c ellipt lognorm figur portfolio risk select number stock match rate oracl optim portfolio multivari distribut degre freedom covari matrix ellipt distribut lognorm gener variat log n covari matrix distribut gener asset return seri half year estim covariancescatt matrix use qne three competitor plug optim portfolio alloc also solv true covari matrix obtain oracl optim portfolio benchmark rang grossexposur constraint c result base simul b match rate optim portfolio figur show portfolio risk r w oracl optim portfolio match rate defin follow two portfolio p p let correspond set select asset e asset weight ws nonzero match rate p p defin r p p denot cardin set note two observ figur four estim lead compar portfolio risk gaussian model howev heavytail distribut qne achiev low portfolio risk ii match rate qne stabl across three model high compet method heavytail distribut thu conclud qne robust heavi tail risk minim asset select real datum section simul portfolio manag use sp stock collect adjust daili close price stock stay sp index januari due ` regular grossexposur constraint solut gener spars adjust close price account corpor action includ stock split dividend right offer tabl annualiz sharp ratio return risk compet approach use sp index datum sharp ratio c c c c c c qne ogk factor shrink return c c c c c c risk c c c c c c decemb use close price obtain daili return daili growth rate price manag portfolio consist stock januari decemb day optim portfolio alloc use past month stock return datum sampl point hold portfolio one day evalu portfolio return day way obtain portfolio return repeat process four method comparison rang grossexposur constant c sinc true covari matrix stock return unknown adopt sharp ratio evalu perform portfolio tabl summariz annualiz sharp ratio mean return empir risk e standard deviat portfolio return observ qne achiev larg sharp ratio valu grossexposur constant indic low risk return equival high return risk discuss paper propos robust portfolio optim framework build quantileba scatter matrix obtain nonasymptot rate converg scatter matrix estim risk estim portfolio relat propos framework momentba counterpart well understand main contribut robust portfolio optim approach lie robust heavi tail high dimens heavi tail present uniqu challeng high dimens compar low dimens exampl asymptot theori estim guarante consist rate p op dn even nongaussian datum [ ] n statist error diminish rapidli increas n howev n statist error may scale rapidli dimens thu stringent tail condit subgaussian condit requir guarante consist momentba estim high dimens [ ] paper base quantil statist achiev consist portfolio risk without assum tail condit allow scale nearli exponenti n anoth contribut work lie theoret analysi serial depend may affect consist estim measur degre serial depend use mix coeffici n show effect serial depend pon rate converg summar paramet c character size n n drop data avoid financi crisi stock price like violat stationari assumpt c impos upper bind percentag short posit practic percentag short posit usual strictli control much low refer [ ] harri markowitz portfolio select journal financ [ ] michael j good robert r grauer sensit meanvarianceeffici portfolio chang asset mean analyt comput result review financi studi [ ] vijay kumar chopra william ziemba effect error mean varianc covari optim portfolio choic journal portfolio manag [ ] robert c merton estim expect return market exploratori investig journal financi econom [ ] jarl g kallberg william ziemba misspecif portfolio select problem risk capit page springer [ ] jianq fan yingi fan jinchi lv high dimension covari matrix estim use factor model journal econometr [ ] jame h stock mark w watson forecast use princip compon larg number predictor journal american statist associ [ ] jushan bai kunpeng li et al statist analysi factor model high dimens annal statist [ ] jianq fan yuan liao martina mincheva larg covari estim threshold princip orthogon complement journal royal statist societi seri b statist methodolog [ ] olivi ledoit michael wolf improv estim covari matrix stock return applic portfolio select journal empir financ [ ] olivi ledoit michael wolf wellcondit estim largedimension covari matrix journal multivari analysi [ ] olivi ledoit michael wolf honey shrunk sampl covari matrix journal portfolio manag [ ] peter j huber robust statist wiley [ ] ricardo maronna ruben h zamar robust estim locat dispers highdimension dataset technometr [ ] ramanathan gnanadesikan john r kettenr robust estim residu outlier detect multirespons data biometr [ ] yilun chen ami wiesel alfr hero robust shrinkag estim highdimension covari matric ieee transact signal process [ ] romain couillet matthew r mckay larg dimension analysi optim robust shrinkag covari matrix estim journal multivari analysi [ ] ravi jagannathan risk reduct larg portfolio impos wrong constraint help journal financ [ ] jianq fan jingjin zhang ke yu vast portfolio select grossexposur constraint journal american statist associ [ ] peter j rousseeuw christoph croux altern median absolut deviat journal american statist associ [ ] h xu h shao solv matrix near problem maximum norm appli project contract method advanc oper research [ ] alexandr belloni victor chernozhukov ` penal quantil regress highdimension spars model annal statist [ ] lan wang yichao wu runz li quantil regress analyz heterogen ultrahigh dimens journal american statist associ [ ] peter j bickel elizaveta levina covari regular threshold annal statist [ ] toni cai cunhui zhang harrison h zhou optim rate converg covari matrix estim annal statist [ ] kaitai fang samuel kotz kai wang ng symmetr multivari relat distribut chapman hall [ ] harri joe multivari model depend concept chapman hall [ ] rafael schmidt tail depend ellipt contour distribut mathemat method oper research [ ] svetlozar todorov rachev handbook heavi tail distribut financ elsevi [ ] svetlozar rachev christian menn frank j fabozzi fattail skew asset return distribut implic risk manag portfolio select option price wiley [ ] kevin dowd measur market risk wiley [ ] torben gustav andersen handbook financi time seri springer [ ] jushan bai shuzhong shi estim high dimension covari matrix applic annal econom financ [ ] sara van de geer sa van de geer empir process estim cambridg univers press cambridg [ ] alastair r hall gener method moment oxford univers press oxford [ ] peter buhlmann sara van de geer statist highdimension datum method theori applic springer
6,5937,Logarithmic Time Online Multiclass prediction,Spotlight,5937-logarithmic-time-online-multiclass-prediction.pdf,"We study the problem of multiclass classification with an extremely large number of classes (k), with the goal of obtaining train and test time complexity logarithmic in the number of classes. We develop top-down tree construction approaches for constructing logarithmic depth trees. On the theoretical front, we formulate a new objective function, which is optimized at each node of the tree and creates dynamic partitions of the data which are both pure (in terms of class labels) and balanced. We demonstrate that under favorable conditions, we can construct logarithmic depth trees that have leaves with low label entropy. However, the objective function at the nodes is challenging to optimize computationally. We address the empirical problem with a new online decision tree construction procedure. Experiments demonstrate that this online algorithm quickly achieves improvement in test error compared to more common logarithmic training time approaches, which makes it a plausible method in computationally constrained large-k applications.","Logarithmic Time Online Multiclass prediction
Anna Choromanska
Courant Institute of Mathematical Sciences
New York, NY, USA
achoroma@cims.nyu.edu

John Langford
Microsoft Research
New York, NY, USA
jcl@microsoft.com

Abstract
We study the problem of multiclass classification with an extremely large number
of classes (k), with the goal of obtaining train and test time complexity logarithmic in the number of classes. We develop top-down tree construction approaches
for constructing logarithmic depth trees. On the theoretical front, we formulate a
new objective function, which is optimized at each node of the tree and creates
dynamic partitions of the data which are both pure (in terms of class labels) and
balanced. We demonstrate that under favorable conditions, we can construct logarithmic depth trees that have leaves with low label entropy. However, the objective
function at the nodes is challenging to optimize computationally. We address the
empirical problem with a new online decision tree construction procedure. Experiments demonstrate that this online algorithm quickly achieves improvement in
test error compared to more common logarithmic training time approaches, which
makes it a plausible method in computationally constrained large-k applications.

1

Introduction

The central problem of this paper is computational complexity in a setting where the number of
classes k for multiclass prediction is very large. Such problems occur in natural language (Which
translation is best?), search (What result is best?), and detection (Who is that?) tasks. Almost all
machine learning algorithms (with the exception of decision trees) have running times for multiclass
classification which are O(k) with a canonical example being one-against-all classifiers [1].
In this setting, the most efficient possible accurate approach is given by information theory [2].
In essence, any multiclass classification algorithm must uniquely specify the bits of all labels that
it predicts correctly on. Consequently, Kraft’s inequality ([2] equation 5.6) implies that the expected computational complexity of predicting correctly is ⌦(H(Y )) per example where H(Y ) is
the Shannon entropy of the label. For the worst case distribution on k classes, this implies ⌦(log(k))
computation is required.

Hence, our goal is achieving O(log(k)) computational time per example1 for both training and
testing, while effectively using online learning algorithms to minimize passes over the data.
The goal of logarithmic (in k) complexity naturally motivates approaches that construct a logarithmic depth hierarchy over the labels, with one label per leaf. While this hierarchy is sometimes
available through prior knowledge, in many scenarios it needs to be learned as well. This naturally
leads to a partition problem which arises at each node in the hierarchy. The partition problem is
finding a classifier: c : X ! { 1, 1} which divides examples into two subsets with a purer set of
labels than the original set. Definitions of purity vary, but canonical examples are the number of
labels remaining in each subset, or softer notions such as the average Shannon entropy of the class
labels. Despite resulting in a classifier, this problem is fundamentally different from standard binary
classification. To see this, note that replacing c(x) with c(x) is very bad for binary classification,
but has no impact on the quality of a partition2 . The partition problem is fundamentally non-convex
1
2

Throughout the paper by logarithmic time we mean logarithmic time per example.
The problem bears parallels to clustering in this regard.

1

for symmetric classes since the average c(x) 2 c(x) of c(x) and c(x) is a poor partition (the always-0
function places all points on the same side).
The choice of partition matters in problem dependent ways. For example, consider examples on a
line with label i at position i and threshold classifiers. In this case, trying to partition class labels
{1, 3} from class label 2 results in poor performance.

accuracy

The partition problem is typically solved for decision tree learning via an enumerate-and-test approach amongst a small set of possible classifiers (see e.g. [3]). In the multiclass setting, it is
desirable to achieve substantial error reduction for each node in the tree which motivates using a richer set of classifiers in the nodes to minimize the number of nodes, and thereby decrease the computational complexity. The main theoretical contribution of this work is to establish a boosting algorithm for learning trees with O(k) nodes and O(log k) depth, thereby addressing the goal of logarithmic time train and test complexity. Our main theoretical result,
presented in Section 2.3, generalizes a binary boosting-by-decision-tree theorem [4] to multiclass boosting. As in all boosting results, performance is critically dependent on the quality
of the weak learner, supporting intuition that we need sufficiently rich partitioners at nodes.
The approach uses a new objective for decision tree learning, which we optimize at each
node of the tree. The objective and its theoretical properties are presented in Section 2.
A complete system with multiple partitions
LOMtree vs one−against−all
could be constructed top down (as the boost1
OAA
ing theorem) or bottom up (as Filter tree [5]).
LOMtree
A bottom up partition process appears impossi0.8
ble with representational constraints as shown
in Section 6 in the Supplementary material so
we focus on top-down tree creation.
0.6
Whenever there are representational constraints
on partitions (such as linear classifiers), finding a strong partition function requires an efficient search over this set of classifiers. Ef0.2
ficient searches over large function classes are
routinely performed via gradient descent tech0
niques for supervised learning, so they seem
26
105
1000
21841 105033
number of classes
like a natural candidate. In existing literature,
Figure 1: A comparison of One-Against- examples for doing this exist when the problem
All (OAA) and the Logarithmic Online Multi- is indeed binary, or when there is a prespeciclass Tree (LOMtree) with One-Against-All con- fied hierarchy over the labels and we just need
strained to use the same training time as the to find partitioners aligned with that hierarchy.
LOMtree by dataset truncation and LOMtree con- Neither of these cases applies—we have multistrained to use the same representation complex- ple labels and want to dynamically create the
ity as One-Against-All. As the number of class choice of partition, rather than assuming that
labels grows, the problem becomes harder and the one was handed to us. Does there exist a purity criterion amenable to a gradient descent apLOMtree becomes more dominant.
proach? The precise objective studied in theory
fails this test due to its discrete nature, and even natural approximations are challenging to tractably
optimize under computational constraints. As a result, we use the theoretical objective as a motivation and construct a new Logarithmic Online Multiclass Tree (LOMtree) algorithm for empirical
evaluation.
0.4

Creating a tree in an online fashion creates a new class of problems. What if some node is initially
created but eventually proves useless because no examples go to it? At best this results in a wasteful
solution, while in practice it starves other parts of the tree which need representational complexity.
To deal with this, we design an efficient process for recycling orphan nodes into locations where
they are needed, and prove that the number of times a node is recycled is at most logarithmic in the
number of examples. The algorithm is described in Section 3 and analyzed in Section 3.1.
And is it effective? Given the inherent non-convexity of the partition problem this is unavoidably
an empirical question which we answer on a range of datasets varying from 26 to 105K classes in
Section 4. We find that under constrained training times, this approach is quite effective compared
to all baselines while dominating other O(log k) train time approaches.
What’s new? To the best of our knowledge, the splitting criterion, the boosting statement, the
LOMtree algorithm, the swapping guarantee, and the experimental results are all new here.

2

1.1

Prior Work

Only a few authors address logarithmic time training. The Filter tree [5] addresses consistent (and
robust) multiclass classification, showing that it is possible in the statistical limit. The Filter tree
does not address the partition problem as we do here which as shown in our experimental section is
often helpful. The partition finding problem is addressed in the conditional probability tree [6], but
that paper addresses conditional probability estimation. Conditional probability estimation can be
converted into multiclass prediction [7], but doing so is not a logarithmic time operation.
Quite a few authors have addressed logarithmic testing time while allowing training time to be O(k)
or worse. While these approaches are intractable on our larger scale problems, we describe them
here for context. The partition problem can be addressed by recursively applying spectral clustering
on a confusion graph [8] (other clustering approaches include [9]). Empirically, this approach has
been found to sometimes lead to badly imbalanced splits [10]. In the context of ranking, another
approach uses k-means hierarchical clustering to recover the label sets for a given partition [11].
The more recent work [12] on the multiclass classification problem addresses it via sparse output
coding by tuning high-cardinality multiclass categorization into a bit-by-bit decoding problem. The
authors decouple the learning processes of coding matrix and bit predictors and use probabilistic
decoding to decode the optimal class label. The authors however specify a class similarity which is
O(k 2 ) to compute (see Section 2.1.1 in [12]), and hence this approach is in a different complexity
class than ours (this is also born out experimentally). The variant of the popular error correcting
output code scheme for solving multi-label prediction problems with large output spaces under the
assumption of output sparsity was also considered in [13]. Their approach in general requires O(k)
running time to decode since, in essence, the fit of each label to the predictions must be checked
and there are O(k) labels. Another approach [14] proposes iterative least-squares-style algorithms
for multi-class (and multi-label) prediction with relatively large number of examples and data dimensions, and the work of [15] focusing in particular on the cost-sensitive multiclass classification.
Both approaches however have O(k) training time.

Decision trees are naturally structured to allow logarithmic time prediction. Traditional decision
trees often have difficulties with a large number of classes because their splitting criteria are not
well-suited to the large class setting. However, newer approaches [16, 17] have addressed this effectively at significant scales in the context of multilabel classification (multilabel learning, with
missing labels, is also addressed in [18]). More specifically, the first work [16] performs brute force
optimization of a multilabel variant of the Gini index defined over the set of positive labels in the
node and assumes label independence during random forest construction. Their method makes fast
predictions, however has high training costs [17]. The second work [17] optimizes a rank sensitive
loss function (Discounted Cumulative Gain). Additionally, a well-known problem with hierarchical
classification is that the performance significantly deteriorates lower in the hierarchy [19] which
some authors solve by biasing the training distribution to reduce error propagation while simultaneously combining bottom-up and top-down approaches during training [20].
The reduction approach we use for optimizing partitions implicitly optimizes a differential objective.
A non-reductive approach to this has been tried previously [21] on other objectives yielding good
results in a different context.

2

Framework and theoretical analysis

In this section we describe the essential elements of the approach, and outline the theoretical properties of the resulting framework. We begin with high-level ideas.
2.1

Setting

We employ a hierarchical approach for learning a multiclass decision tree structure, training this
structure in a top-down fashion. We assume that we receive examples x 2 X ✓ Rd , with labels
y 2 {1, 2, . . . , k}. We also assume access to a hypothesis class H where each h 2 H is a binary
classifier, h : X 7! { 1, 1}. The overall objective is to learn a tree of depth O(log k), where
each node in the tree consists of a classifier from H. The classifiers are trained in such a way that
hn (x) = 1 (hn denotes the classifier in node n of the tree3 ) means that the example x is sent to the
right subtree of node n, while hn (x) = 1 sends x to the left subtree. When we reach a leaf, we
predict according to the label with the highest frequency amongst the examples reaching that leaf.
3
Further in the paper we skip index n whenever it is clear from the context that we consider a fixed tree
node.

3

In the interest of computational complexity, we want to encourage the number of examples going
to the left and right to be fairly balanced. For good statistical accuracy, we want to send examples
of class i almost exclusively to either the left or the right subtree, thereby refining the purity of the
class distributions at subsequent levels in the tree. The purity of a tree node is therefore a measure
of whether the examples of each class reaching the node are then mostly sent to its one child node
(pure split) or otherwise to both children (impure split). The formal definitions of balancedness and
purity are introduced in Section 2.2. An objective expressing both criteria4 and resulting theoretical
properties are illustrated in the following sections. A key consideration in picking this objective is
that we want to effectively optimize it over hypotheses h 2 H, while streaming over examples in
an online fashion5 . This seems unsuitable with some of the more standard decision tree objectives
such as Shannon or Gini entropy, which leads us to design a new objective. At the same time, we
show in Section 2.3 that under suitable assumptions, optimizing the objective also leads to effective
reduction of the average Shannon entropy over the entire tree.
2.2

An objective and analysis of resulting partitions

We now define a criterion to measure the quality of a hypothesis h 2 H in creating partitions at a
fixed node n in the tree. Let ⇡i denotes the proportion of label i amongst the examples reaching this
node. Let P (h(x) > 0) and P (h(x) > 0|i) denote the fraction of examples reaching n for which
h(x) > 0, marginally and conditional on class i respectively. Then we define the objective6 :
k
X
J(h) = 2
⇡i |P (h(x) > 0) P (h(x) > 0|i)| .
(1)
i=1

We aim to maximize the objective J(h) to obtain high quality partitions. Intuitively, the objective
encourages the fraction of examples going to the right from class i to be substantially different from
the background fraction for each class i. As a concrete simple scenario, if P (h(x) > 0) = 0.5 for
some hypothesis h, then the objective prefers P (h(x) > 0|i) to be as close to 0 or 1 as possible for
each class i, leading to pure partitions. We now make these intuitions more formal.
Definition 1 (Purity). The hypothesis h 2 H induces a pure split if
k
X
↵ :=
⇡i min(P (h(x) > 0|i), P (h(x) < 0|i))  ,
where

i=1

2 [0, 0.5), and ↵ is called the purity factor.

In particular, a partition is called maximally pure if ↵ = 0, meaning that each class is sent exclusively
to the left or the right. We now define a similar definition for the balancedness of a split.
Definition 2 (Balancedness). The hypothesis h 2 H induces a balanced split if
c  P (h(x) > 0)  1 c,
{z
}
|
where c 2 (0, 0.5], and

=

is called the balancing factor.

A partition is called maximally balanced if = 0.5, meaning that an equal number of examples
are sent to the left and right children of the partition. The balancing factor and the purity factor
are related as shown in Lemma 1 (the proofs of Lemma 1 and the following lemma (Lemma 2) are
deferred to the Supplementary material).
Lemma 1. For any hypothesis h, and any distribution over examples (x, y), the purity factor ↵ and
the balancing factor satisfy ↵  min{(2 J(h))/(4 )
, 0.5}.
A partition is called maximally pure and balanced if it satisfies both ↵ = 0 and = 0.5. We see
that J(h) = 1 for a hypothesis h inducing a maximally pure and balanced partition as captured in
the next lemma. Of course we do not expect to have hypotheses producing maximally pure and
balanced splits in practice.
Lemma 2. For any hypothesis h : X 7! { 1, 1}, the objective J(h) satisfies J(h) 2 [0, 1].
Furthermore, if h induces a maximally pure and balanced partition then J(h) = 1.
4

We want an objective to achieve its optimum for simultaneously pure and balanced split. The standard
entropy-based criteria, such as Shannon or Gini entropy, as well as the criterion we will propose, posed in
Equation 1, satisfy this requirement (for the entropy-based criteria see [4], for our criterion see Lemma 2).
5
Our algorithm could also be implemented as batch or streaming, where in case of the latter one can for
example make one pass through the data per every tree level, however for massive datasets making multiple
passes through the data is computationally costly, further justifying the need for an online approach.
6
The proposed objective function exhibits some similarities with the so-called Carnap’s measure [22, 23]
used in probability and inductive logic.

4

2.3

Quality of the entire tree

The above section helps us understand the quality of an individual split produced by effectively
maximizing J(h). We next reason about the quality of the entire tree as we add more and more
nodes. We measure the quality of trees using the average entropy over all the leaves in the tree, and
track the decrease of this entropy as a function of the number of nodes. Our analysis extends the
theoretical analysis in [4], originally developed to show the boosting properties of the decision trees
for binary classification problems, to the multiclass classification setting.
Given a tree T , we consider the entropy function Gt as the measure of the quality of tree:
✓
◆
k
X X
1
Gt =
wl
⇡l,i ln
⇡l,i
i=1
l2L

where ⇡l,i ’s are the probabilities that a randomly chosen data point x drawn from P, where P is
a fixed target distribution over X , has label i given that x reaches node l, L denotes the set of all
tree leaves, t denotes the number of internal tree nodes, and wl is the weight
P of leaf l defined as the
probability a randomly chosen x drawn from P reaches leaf l (note that l2L wl = 1).

We next state the main theoretical result of this paper (it is captured in Theorem 1). We adopt
the weak learning framework. The weak hypothesis assumption, captured in Definition 3, posits that
each node of the tree T has a hypothesis h in its hypothesis class H which guarantees simultaneously
a ”weak” purity and a ”weak” balancedness of the split on any distribution P over X . Under this
assumption, one can use the new decision tree approach to drive the error below any threshold.
Definition 3 (Weak Hypothesis Assumption). Let m denote any node of the tree T , and let m =
P (hm (x) > 0) and Pm,i = P (hm (x) > 0|i). Furthermore, let 2 R+ be such that for all m,
2 (0, min( m , 1
m )]. We say that the weak hypothesis assumption is satisfied when for any
distribution P over X at each node m of the tree T there exists a hypothesis hm 2 H such that
Pk
J(hm )/2 = i=1 ⇡m,i |Pm,i
.
m|
Theorem 1. Under the Weak Hypothesis Assumption, for any ↵ 2 [0, 1], to obtain Gt  ↵ it suffices
to make t

4(1

(1/↵)

)2 ln k
2

splits.

We defer the proof of Theorem 1 to the Supplementary material and provide its sketch now. The
analysis studies a tree construction algorithm where we recursively find the leaf node with the highest
weight, and choose to split it into two children. Let n be the heaviest leaf at time t. Consider splitting
it to two children. The contribution of node n to the tree entropy changes after it splits. This change
(entropy reduction) corresponds to a gap in the Jensen’s inequality applied to the concave function,
and thus can further be lower-bounded (we use the fact that Shannon entropy is strongly concave
with respect to `1 -norm (see e.g., Example 2.5 in Shalev-Shwartz [24])). The obtained lower-bound
turns out to depend proportionally on J(hn )2 . This implies that the larger the objective J(hn )
is at time t, the larger the entropy reduction ends up being, which further reinforces intuitions to
maximize J. In general, it might not be possible to find any hypothesis with a large enough objective
J(hn ) to guarantee sufficient progress at this point so we appeal to a weak learning assumption. This
assumption can be used to further lower-bound the entropy reduction and prove Theorem 1.

3

The LOMtree Algorithm

The objective function of Section 2 has another convenient form which yields a simple online algorithm for tree construction and training. Note that Equation 1 can be written (details are shown in
Section 12 in the Supplementary material) as
J(h) = 2Ei [|Ex [1(h(x) > 0)] Ex [1(h(x) > 0|i)]|].
Maximizing this objective is a discrete optimization problem that can be relaxed as follows
J(h) = 2Ei [|Ex [h(x)] Ex [h(x)|i]|],
where Ex [h(x)|i] is the expected score of class i.
We next explain our empirical approach for maximizing the relaxed objective. The empirical estimates of the expectations can be easily stored and updated online in every tree node. The decision
whether to send an example reaching a node to its left or right child node is based on the sign of the
difference between the two expectations: Ex [h(x)] and Ex [h(x)|y], where y is a label of the data
point, i.e. when Ex [h(x)] Ex [h(x)|y] > 0 the data point is sent to the left, else it is sent to the right.
This procedure is conveniently demonstrated on a toy example in Section 13 in the Supplement.
During training, the algorithm assigns a unique label to each node of the tree which is currently a
leaf. This is the label with the highest frequency amongst the examples reaching that leaf. While
5

Algorithm 1 LOMtree algorithm (online tree training)
Input: regression algorithm R, max number of tree non-leaf nodes T , swap resistance RS
Subroutine SetNode (v)
mv = ; (mv (y) - sum of the scores for class y)
lv = ; (lv (y) - number of points of class y reaching v)
nv = ; (nv (y) - number of points of class y which are used to train regressor in v)
ev = ; (ev (y) - expected score for class y)
Ev = 0 (expected total score)
Cv = 0 (the size of the smallest leaf7 in the subtree with root v)
Subroutine UpdateC (v)
While (v 6= r AND CPARENT(v) 6= Cv )
v = PARENT(v); Cv = min(CLEFT(v) , CRIGHT(v) )8
Subroutine Swap (v)
Find a leaf s for which (Cs = Cr )
sPA=PARENT(s); sGPA= GRANDPA(s); sSIB=SIBLING(s)9
If (sPA = LEFT(sGPA )) LEFT(sGPA ) = sSIB Else RIGHT(sGPA ) = sSIB
UpdateC (sSIB ); SetNode (s); LEFT(v) = s; SetNode (sPA ); RIGHT(v) = sPA
Create root r = 0: SetNode (r); t = 1
For each example (x, y) do
Set j = r
Do
If (lj (y) = ;)
mj (y) = 0; lj (y) = 0; nj (y) = 0; ej (y) = 0
lj (y)++
If(j is a leaf)
If(lj has at least 2 non-zero entries)
If(t<T OR Cj maxi lj (i)>RS (Cr+1))
If (t<T )
SetNode (LEFT(j)); SetNode (RIGHT(j)); t++
Else Swap(j)
CLEFT(j)=bCj /2c; CRIGHT(j)=Cj CLEFT(j) ; UpdateC (LEFT(j))
If(j is not a leaf)
If (Ej > ej (y)) c = 1 Else c = 1
Train hj with example (x, c): R(x, c)
Pk
mj (i) 10
nj (y) ++; mj (y) += hj (x); ej (y) = mj (y)/nj (y); Ej = Pi=1
k
i=1 nj (i)
Set j to the child of j corresponding to hj
Else
Cj ++
break
testing, a test example is pushed down the tree along the path from the root to the leaf, where in each
non-leaf node of the path its regressor directs the example either to the left or right child node. The
test example is then labeled with the label assigned to the leaf that this example descended to.
The training algorithm is detailed in Algorithm 1 where each tree node contains a classifier (we use
linear classifiers), i.e. hj is the regressor stored in node j and hj (x) is the value of the prediction
of hj on example x11 . The stopping criterion for expanding the tree is when the number of non-leaf
nodes reaches a threshold T .
3.1 Swapping
Consider a scenario where the current training example descends to leaf j. The leaf can split (create
two children) if the examples that reached it in the past were coming from at least two different
7

The smallest leaf is the one with the smallest total number of data points reaching it in the past.
PARENT (v), LEFT (v) and RIGHT (v) denote resp. the parent, and the left and right child of node v.
9
GRANDPA (v) and SIBLING (v) denote respectively the grandparent of node v and the sibling of node v, i.e.
the node which has the same parent as v.
10
In the implementation both sums are stored as variables thus updating Ev takes O(1) computations.
11
We also refer to this prediction value as the ’score’ in this section.
8

6

r
...
j

r

...
...

...

...

sGPA
...

s

sSIB

s

...

j

sPA

...
...

sPA

sGPA
...
sSIB
...
...

...
...
Figure 2: Illustration of the swapping procedure. Left: before the swap, right: after the swap.
classes. However, if the number of non-leaf nodes of the tree reaches threshold T , no more nodes
can be expanded and thus j cannot create children. Since the tree construction is done online, some
nodes created at early stages of training may end up useless because no examples reach them later
on. This prevents potentially useful splits such as at leaf j. This problem can be solved by recycling
orphan nodes (subroutine Swap in Algorithm 1). The general idea behind node recycling is to allow
nodes to split if a certain condition is met. In particular, node j splits if the following holds:
Cj

max

i2{1,2,...,k}

lj (i) > RS (Cr + 1),

(2)

where r denotes the root of the entire tree, Cj is the size of the smallest leaf in the subtree with root
j, where the smallest leaf is the one with the smallest total number of data points reaching it in the
past, lj is a k-dimensional vector of non-negative integers where the ith element is the count of the
number of data points with label i reaching leaf j in the past, and finally RS is a “swap resistance”.
The subtraction of maxi2{1,2,...,k} lj (i) in Equation 2 ensures that a pure node will not be recycled.
If the condition in Inequality 2 is satisfied, the swap of the nodes is performed where an orphan
leaf s, which was reached by the smallest number of examples in the past, and its parent sPA are
detached from the tree and become children of node j whereas the old sibling sSIB of an orphan node
s becomes a direct child of the old grandparent sGPA . The swapping procedure is shown in Figure 2.
The condition captured in the Inequality 2 allows us to prove that the number of times any given
node is recycled is upper-bounded by the logarithm of the number of examples whenever the swap
resistance is 4 or more (Lemma 3).
Lemma 3. Let the swap resistance RS be greater or equal to 4. Then for all sequences of examples,
the number of times Algorithm 1 recycles any given node is upper-bounded by the logarithm (with
base 2) of the sequence length.

4

Experiments

We address several hypotheses experimentally.
1. The LOMtree algorithm achieves true logarithmic time computation in practice.
2. The LOMtree algorithm is competitive with or better than all other logarithmic train/test
time algorithms for multiclass classification.
3. The LOMtree algorithm has statistical performance close to more common O(k) approaches.
To address these hypotheses, we conTable 1: Dataset sizes.
ducted experiments on a variety of
Isolet Sector Aloi ImNet ODP
benchmark multiclass datasets: Isosize
52.3MB 19MB 17.7MB104GB12 3GB
let, Sector, Aloi, ImageNet (Im# features 617 54K 128
6144 0.5M
Net) and ODP13 . The details of the
# examples 7797 9619 108K 14.2M 1577418
datasets are provided in Table 1. The
datasets were divided into training
# classes
26
105 1000 ⇠22K ⇠105K
(90%) and testing (10%). Furthermore, 10% of the training dataset was
used as a validation set.
The baselines we compared LOMtree with are a balanced random tree of logarithmic depth (Rtree)
and the Filter tree [5]. Where computationally feasible, we also compared with a one-against-all
classifier (OAA) as a representative O(k) approach. All methods were implemented in the Vowpal
Wabbit [25] learning system and have similar levels of optimization. The regressors in the tree nodes
for LOMtree, Rtree, and Filter tree as well as the OAA regressors were trained by online gradient
descent for which we explored step sizes chosen from the set {0.25, 0.5, 0.75, 1, 2, 4, 8}. We used
12
13

compressed
The details of the source of each dataset are provided in the Supplementary material.

7

linear regressors. For each method we investigated training with up to 20 passes through the data and
we selected the best setting of the parameters (step size and number of passes) as the one minimizing
the validation error. Additionally, for the LOMtree we investigated different settings of the stopping
criterion for the tree expansion: T = {k 1, 2k 1, 4k 1, 8k 1, 16k 1, 32k 1, 64k 1},
and swap resistance RS = {4, 8, 16, 32, 64, 128, 256}.

In Table 2 and 3 we report respectively train time and per-example test time (the best performer is
indicated in bold). Training time (and later reported test error) is not provided for OAA on ImageNet
and ODP due to intractability14 -both are petabyte scale computations15 .
Table 2: Training time on selected problems. Table 3: Per-example test time on all problems.
Isolet Sector
Aloi
Isolet Sector Aloi ImNet ODP
LOMtree 16.27s 12.77s 51.86s
LOMtree 0.14ms 0.13ms 0.06ms 0.52ms 0.26ms
OAA
19.58s 18.37s 11m2.43s
OAA 0.16 ms 0.24ms 0.33ms 0.21s 1.05s

log2(time ratio)

The first hypothesis is consistent with the experimental results. Time-wise LOMtree significantly
outperforms OAA due to building only close-to logarithmic depth trees. The improvement in the
training time increases with the number of classes in the classification problem. For instance on Aloi
training with LOMtree is 12.8 times faster than with OAA. The same can be said about the test time,
where the per-example test time for Aloi, ImageNet and ODP are respectively 5.5, 403.8 and 4038.5
times faster than OAA. The significant advantage of LOMtree over OAA is also captured in Figure 3.
Next, in Table 4 (the best logarithmic time perLOMtree vs one−against−all
former is indicated in bold) we report test error
12
of logarithmic train/test time algorithms. We
10
also show the binomial symmetrical 95% confidence intervals for our results. Clearly the sec8
ond hypothesis is also consistent with the experimental results. Since the Rtree imposes a
6
random label partition, the resulting error it ob4
tains is generally worse than the error obtained
by the competitor methods including LOMtree
2
which learns the label partitioning directly from
the data. At the same time LOMtree beats Fil6
8
10
12
14
16
ter tree on every dataset, though for ImageNet
log2(number of classes)
Figure 3: Logarithm of the ratio of per-example and ODP (both have a high level of noise) the
advantage of LOMtree is not as significant.
test times of OAA and LOMtree on all problems.
Table 4: Test error (%) and confidence interval on all problems.
LOMtree
Rtree
Filter tree
OAA
Isolet 6.36±1.71 16.92±2.63 15.10±2.51 3.56±1.30%
Sector 16.19±2.33 15.77±2.30 17.70±2.41 9.17±1.82%
Aloi 16.50±0.70 83.74±0.70 80.50±0.75 13.78±0.65%
ImNet 90.17±0.05 96.99±0.03 92.12±0.04
NA
ODP 93.46±0.12 93.85±0.12 93.76±0.12
NA
The third hypothesis is weakly consistent with the empirical results. The time advantage of LOMtree
comes with some loss of statistical accuracy with respect to OAA where OAA is tractable. We
conclude that LOMtree significantly closes the gap between other logarithmic time methods and
OAA, making it a plausible approach in computationally constrained large-k applications.

5

Conclusion

The LOMtree algorithm reduces the multiclass problem to a set of binary problems organized in a
tree structure where the partition in every tree node is done by optimizing a new partition criterion
online. The criterion guarantees pure and balanced splits leading to logarithmic training and testing
time for the tree classifier. We provide theoretical justification for our approach via a boosting
statement and empirically evaluate it on multiple multiclass datasets. Empirically, we find that this
is the best available logarithmic time approach for multiclass classification problems.
14
Note however that the mechanics of testing datastes are much easier - one can simply test with effectively
untrained parameters on a few examples to measure the test speed thus the per-example test time for OAA on
ImageNet and ODP is provided.
15
Also to the best of our knowledge there exist no state-of-the-art results of the OAA performance on these
datasets published in the literature.

8

Acknowledgments
We would like to thank Alekh Agarwal, Dean Foster, Robert Schapire and Matus Telgarsky for
valuable discussions.

References
[1] R. Rifkin and A. Klautau. In defense of one-vs-all classification. J. Mach. Learn. Res., 5:101–141, 2004.
[2] T. M. Cover and J. A. Thomas. Elements of Information Theory. John Wiley & Sons, Inc., 1991.
[3] L. Breiman, J. H. Friedman, R. A. Olshen, and C. J. Stone. Classification and Regression Trees. CRC
Press LLC, Boca Raton, Florida, 1984.
[4] M. Kearns and Y. Mansour. On the boosting ability of top-down decision tree learning algorithms. Journal
of Computer and Systems Sciences, 58(1):109–128, 1999 (also In STOC, 1996).
[5] A. Beygelzimer, J. Langford, and P. D. Ravikumar. Error-correcting tournaments. In ALT, 2009.
[6] A. Beygelzimer, J. Langford, Y. Lifshits, G. B. Sorkin, and A. L. Strehl. Conditional probability tree
estimation analysis and algorithms. In UAI, 2009.
[7] C. M. Bishop. Pattern Recognition and Machine Learning. Springer, 2006.
[8] S. Bengio, J. Weston, and D. Grangier. Label embedding trees for large multi-class tasks. In NIPS, 2010.
[9] G. Madzarov, D. Gjorgjevikj, and I. Chorbev. A multi-class svm classifier utilizing binary decision tree.
Informatica, 33(2):225–233, 2009.
[10] J. Deng, S. Satheesh, A. C. Berg, and L. Fei-Fei. Fast and balanced: Efficient label tree learning for large
scale object recognition. In NIPS, 2011.
[11] J. Weston, A. Makadia, and H. Yee. Label partitioning for sublinear ranking. In ICML, 2013.
[12] B. Zhao and E. P. Xing. Sparse output coding for large-scale visual recognition. In CVPR, 2013.
[13] D. Hsu, S. Kakade, J. Langford, and T. Zhang. Multi-label prediction via compressed sensing. In NIPS,
2009.
[14] A. Agarwal, S. M. Kakade, N. Karampatziakis, L. Song, and G. Valiant. Least squares revisited: Scalable
approaches for multi-class prediction. In ICML, 2014.
[15] O. Beijbom, M. Saberian, D. Kriegman, and N. Vasconcelos. Guess-averse loss functions for costsensitive multiclass boosting. In ICML, 2014.
[16] R. Agarwal, A. Gupta, Y. Prabhu, and M. Varma. Multi-label learning with millions of labels: Recommending advertiser bid phrases for web pages. In WWW, 2013.
[17] Y. Prabhu and M. Varma. Fastxml: A fast, accurate and stable tree-classifier for extreme multi-label
learning. In ACM SIGKDD, 2014.
[18] H.-F. Yu, P. Jain, P. Kar, and I. S. Dhillon. Large-scale multi-label learning with missing labels. In ICML,
2014.
[19] T.-Y. Liu, Y. Yang, H. Wan, H.-J. Zeng, Z. Chen, and W.-Y. Ma. Support vector machines classification
with a very large-scale taxonomy. In SIGKDD Explorations, 2005.
[20] P. N. Bennett and N. Nguyen. Refined experts: improving classification in large taxonomies. In SIGIR,
2009.
[21] A. Montillo, J. Tu, J. Shotton, J. Winn, J.E. Iglesias, D.N. Metaxas, and A. Criminisi. Entanglement and
differentiable information gain maximization. Decision Forests for Computer Vision and Medical Image
Analysis, 2013.
[22] K. Tentori, V. Crupi, N. Bonini, and D. Osherson. Comparison of confirmation measures. Cognition,
103(1):107 – 119, 2007.
[23] R. Carnap. Logical Foundations of Probability. 2nd ed. Chicago: University of Chicago Press. Par. 87
(pp. 468-478), 1962.
[24] S. Shalev-Shwartz. Online learning and online convex optimization. Found. Trends Mach. Learn.,
4(2):107–194, 2012.
[25] J. Langford, L. Li, and A. Strehl. http://hunch.net/˜vw, 2007.
[26] Y. Nesterov. Introductory lectures on convex optimization : a basic course. Applied optimization, Kluwer
Academic Publ., 2004.
[27] J. Deng, W. Dong, R. Socher, L.-J. Li, K. Li, and L. Fei-Fei. Imagenet: A large-scale hierarchical image
database. In CVPR, 2009.

9

",studi problem multiclass classif extrem larg number class k goal obtain train test time complex logarithm number class develop topdown tree construct approach construct logarithm depth tree theoret front formul new object function optim node tree creat dynam partit datum pure term class label balanc demonstr favor condit construct logarithm depth tree leav low label entropi howev object function nod challeng optim comput address empir problem new onlin decis tree construct procedur experi demonstr onlin algorithm quickli achiev improv test error compar common logarithm train time approach make plausibl method comput constrain largek applic,logarithm time onlin multiclass predict anna choromanska courant institut mathemat scienc new york ny usa achoromacim nyu edu john langford microsoft research new york ny usa jclmicrosoft com abstract studi problem multiclass classif extrem larg number class k goal obtain train test time complex logarithm number class develop topdown tree construct approach construct logarithm depth tree theoret front formul new object function optim node tree creat dynam partit datum pure term class label balanc demonstr favor condit construct logarithm depth tree leav low label entropi howev object function nod challeng optim comput address empir problem new onlin decis tree construct procedur experi demonstr onlin algorithm quickli achiev improv test error compar common logarithm train time approach make plausibl method comput constrain largek applic introduct central problem paper comput complex set number class k multiclass predict larg problem occur natur languag translat good search result good detect task almost machin learn algorithm except decis tree run time multiclass classif k canon exampl oneagainstal classifi [ ] set effici possibl accur approach give inform theori [ ] essenc multiclass classif algorithm must uniqu specifi bit label predict correctli consequ kraft inequ [ ] equat impli expect comput complex predict correctli h per exampl h shannon entropi label bad case distribut k class impli log k comput requir henc goal achiev log k comput time per exampl train test effect use onlin learn algorithm minim pass datum goal logarithm k complex natur motiv approach construct logarithm depth hierarchi label one label per leaf hierarchi sometim avail prior knowledg mani scenario need learn well natur lead partit problem aris node hierarchi partit problem find classifi c x divid exampl two subset purer set label origin set definit puriti vari canon exampl number label remain subset soft notion averag shannon entropi class label despit result classifi problem fundament differ standard binari classif see note replac c x c x bad binari classif impact qualiti partit partit problem fundament nonconvex throughout paper logarithm time mean logarithm time per exampl problem bear parallel cluster regard symmetr class sinc averag c x c x c x c x poor partit alway function place point side choic partit matter problem depend way exampl consid exampl line label posit threshold classifi case tri partit class label class label result poor perform accuraci partit problem typic solv decis tree learn via enumerateandt approach amongst small set possibl classifi see e g [ ] multiclass set desir achiev substanti error reduct node tree motiv use rich set classifi node minim number node therebi decreas comput complex main theoret contribut work establish boost algorithm learn tree k node log k depth therebi address goal logarithm time train test complex main theoret result present section generaliz binari boostingbydecisiontre theorem [ ] multiclass boost boost result perform critic depend qualiti weak learner support intuit need suffici rich partition node approach use new object decis tree learn optim node tree object theoret properti present section complet system multipl partit lomtre vs oneagainstal could construct top boost oaa e theorem bottom filter tree [ ] lomtre bottom partit process appear impossi ble represent constraint show section supplementari materi focu topdown tree creation whenev represent constraint partit linear classifi find strong partit function requir effici search set classifi ef ficient search larg function class routin perform via gradient descent tech niqu supervis learn seem number class like natur candid exist literatur figur comparison oneagainst exampl exist problem oaa logarithm onlin multi inde binari prespeciclass tree lomtre oneagainstal con fi hierarchi label need strain use train time find partition align hierarchi lomtre dataset truncat lomtre con neither case appliesw multistrain use represent complex ple label want dynam creat iti oneagainstal number class choic partit rather assum label grow problem becom hard one hand us exist puriti criterion amen gradient descent aplomtre becom domin proach precis object studi theori fail test due discret natur even natur approxim challeng tractabl optim comput constraint result use theoret object motiv construct new logarithm onlin multiclass tree lomtre algorithm empir evalu creat tree onlin fashion creat new class problem node initi creat eventu prove useless exampl go good result wast solut practic starv part tree need represent complex deal design effici process recycl orphan nod locat need prove number time node recycl logarithm number exampl algorithm describ section analyz section effect give inher nonconvex partit problem unavoid empir question answer rang dataset vari k class section find constrain train time approach quit effect compar baselin domin log k train time approach what s new good knowledg split criterion boost statement lomtre algorithm swap guarante experiment result new prior work author address logarithm time train filter tree [ ] address consist robust multiclass classif show possibl statist limit filter tree address partit problem show experiment section often help partit find problem address condit probabl tree [ ] paper address condit probabl estim condit probabl estim convert multiclass predict [ ] logarithm time oper quit author address logarithm test time allow train time k bad approach intract larg scale problem describ context partit problem address recurs appli spectral cluster confus graph [ ] cluster approach includ [ ] empir approach find sometim lead badli imbalanc split [ ] context rank anoth approach use kmean hierarch cluster recov label set give partit [ ] recent work [ ] multiclass classif problem address via spars output cod tune highcardin multiclass categor bitbybit decod problem author decoupl learn process cod matrix bit predictor use probabilist decod decod optim class label author howev specifi class similar k comput see section [ ] henc approach differ complex class also bear experiment variant popular error correct output code scheme solv multilabel predict problem larg output space assumpt output sparsiti also consid [ ] approach gener requir k run time decod sinc essenc fit label predict must check k label anoth approach [ ] propos iter leastsquaresstyl algorithm multiclass multilabel predict rel larg number exampl data dimens work [ ] focu particular costsensit multiclass classif approach howev k train time decis tree natur structur allow logarithm time predict tradit decis tree often difficulti larg number class split criterion wellsuit larg class set howev new approach [ ] address effect signific scale context multilabel classif multilabel learn miss label also address [ ] specif first work [ ] perform brute forc optim multilabel variant gini index defin set posit label node assum label independ random forest construct method make fast predict howev high train cost [ ] second work [ ] optim rank sensit loss function discount cumul gain addit wellknown problem hierarch classif perform significantli deterior low hierarchi [ ] author solv bia train distribut reduc error propag simultan combin bottomup topdown approach train [ ] reduct approach use optim partit implicitli optim differenti object nonreduct approach tri previous [ ] object yield good result differ context framework theoret analysi section describ essenti element approach outlin theoret properti result framework begin highlevel idea set employ hierarch approach learn multiclass decis tree structur train structur topdown fashion assum receiv exampl x x rd label k also assum access hypothesi class h h h binari classifi h x overal object learn tree depth log k node tree consist classifi h classifi train way hn x hn denot classifi node n tree mean exampl x send right subtre node n hn x send x leav subtre reach leaf predict accord label high frequenc amongst exampl reach leaf paper skip index n whenev clear context consid fix tree node interest comput complex want encourag number exampl go leav right fairli balanc good statist accuraci want send exampl class almost exclus either leav right subtre therebi refin puriti class distribut subsequ level tree puriti tree node therefor measur whether exampl class reach node mostli send one child node pure split otherwis child impur split formal definit balanced puriti introduc section object express criterion result theoret properti illustr follow section key consider pick object want effect optim hypothesi h h stream exampl onlin fashion seem unsuit standard decis tree object shannon gini entropi lead us design new object time show section suitabl assumpt optim object also lead effect reduct averag shannon entropi entir tree object analysi result partit defin criterion measur qualiti hypothesi h h creat partit fix node n tree let denot proport label amongst exampl reach node let p h x p h x denot fraction exampl reach n h x margin condit class respect defin object k x j h p h x p h x aim maxim object j h obtain high qualiti partit intuit object encourag fraction exampl go right class substanti differ background fraction class concret simpl scenario p h x hypothesi h object prefer p h x close possibl class lead pure partit make intuit formal definit puriti hypothesi h h induc pure split k x min p h x p h x [ call puriti factor particular partit call maxim pure mean class send exclus leav right defin similar definit balanced split definit balanced hypothesi h h induc balanc split c p h x c z c ] call balanc factor partit call maxim balanc mean equal number exampl send leav right child partit balanc factor puriti factor relat show lemma proof lemma follow lemma lemma defer supplementari materi lemma hypothesi h distribut exampl x puriti factor balanc factor satisfi min j h partit call maxim pure balanc satisfi see j h hypothesi h induc maxim pure balanc partit captur next lemma cours expect hypothesi produc maxim pure balanc split practic lemma hypothesi h x object j h satisfi j h [ ] furthermor h induc maxim pure balanc partit j h want object achiev optimum simultan pure balanc split standard entropybas criterion shannon gini entropi well criterion propos pose equat satisfi requir entropyba criterion see [ ] criterion see lemma algorithm could also implement batch stream case latter one exampl make one pass datum per everi tree level howev massiv dataset make multipl pass datum comput costli justifi need onlin approach propos object function exhibit similar socal carnap measur [ ] use probabl induct logic qualiti entir tree section help us understand qualiti individu split produc effect maxim j h next reason qualiti entir tree add node measur qualiti tree use averag entropi leaf tree track decreas entropi function number nod analysi extend theoret analysi [ ] origin develop show boost properti decis tree binari classif problem multiclass classif set give tree consid entropi function gt measur qualiti tree k x x gt wl li ln li li probabl randomli choos datum point x draw p p fix target distribut x label give x reach node l l denot set tree leaf denot number intern tree node wl weight p leaf l defin probabl randomli choos x draw p reach leaf l note wl next state main theoret result paper captur theorem adopt weak learn framework weak hypothesi assumpt captur definit posit node tree hypothesi h hypothesi class h guarante simultan weak puriti weak balanced split distribut p x assumpt one use new decis tree approach drive error threshold definit weak hypothesi assumpt let denot node tree let p hm x pmi p hm x furthermor let r min ] say weak hypothesi assumpt satisfi distribut p x node tree exist hypothesi hm h pk j hm mi pmi theorem weak hypothesi assumpt [ ] obtain gt suffic make ln k split defer proof theorem supplementari materi provid sketch analysi studi tree construct algorithm recurs find leaf node high weight choos split two child let n heavi leaf time consid split two child contribut node n tree entropi chang split chang entropi reduct correspond gap jensen inequ appli concav function thu lowerbound use fact shannon entropi strongli concav respect ` norm see e g exampl shalevshwartz [ ] obtain lowerbound turn depend proport j hn impli larg object j hn time larg entropi reduct end reinforc intuit maxim j gener may possibl find hypothesi larg enough object j hn guarante suffici progress point appeal weak learn assumpt assumpt use lowerbound entropi reduct prove theorem lomtre algorithm object function section anoth conveni form yield simpl onlin algorithm tree construct train note equat write detail show section supplementari materi j h ei [ ex [ h x ] ex [ h x ] ] maxim object discret optim problem relax follow j h ei [ ex [ h x ] ex [ h x ] ] ex [ h x ] expect score class next explain empir approach maxim relax object empir estim expect easili store updat onlin everi tree node decis whether send exampl reach node left right child node base sign differ two expect ex [ h x ] ex [ h x ] label datum point e ex [ h x ] ex [ h x ] data point send leav els send right procedur conveni demonstr toy exampl section supplement train algorithm assign uniqu label node tree current leaf label high frequenc amongst exampl reach leaf algorithm lomtre algorithm onlin tree train input regress algorithm r max number tree nonleaf node swap resist rs subroutin setnod v mv mv sum score class lv lv number point class reach v nv nv number point class use train regressor v ev ev expect score class ev expect total score cv size small leaf subtre root v subroutin updatec v v r cparent v cv v parent v cv min cleft v cright v subroutin swap v find leaf cs cr spapar sgpa grandpa ssibsibl spa leav sgpa left sgpa ssib els right sgpa ssib updatec ssib setnod leav v setnod spa right v spa creat root r setnod r exampl x set j r lj mj lj nj ej lj j leaf lj least nonzero entri tt cj maxi lj rs cr tt setnod leav j setnod right j els swap j cleft j bcj c cright j cj cleft j updatec leav j j leaf ej ej c els c train hj exampl x c r x c pk mj nj mj hj x ej mj nj ej pi k nj set j child j correspond hj els cj break test test exampl push tree along path root leaf nonleaf node path regressor direct exampl either leav right child node test exampl label label assign leaf exampl descend train algorithm detail algorithm tree node contain classifi use linear classifi e hj regressor store node j hj x valu predict hj exampl x stop criterion expand tree number nonleaf node reach threshold swap consid scenario current train exampl descend leaf j leaf split creat two child exampl reach past come least two differ small leaf one small total number data point reach past parent v leav v right v denot resp parent leav right child node v grandpa v sibl v denot respect grandpar node v sibl node v e node parent v implement sum store variabl thu updat ev take comput also refer predict valu score section r j r sgpa ssib j spa spa sgpa ssib figur illustr swap procedur leav swap right swap class howev number nonleaf node tree reach threshold node expand thu j can not creat child sinc tree construct do onlin node creat earli stage train may end useless exampl reach later prevent potenti use split leaf j problem solv recycl orphan nod subroutin swap algorithm gener idea behind node recycl allow node split certain condit meet particular node j split follow hold cj max k lj rs cr r denot root entir tree cj size small leaf subtre root j small leaf one small total number data point reach past lj kdimension vector nonneg integ ith element count number datum point label reach leaf j past final rs swap resist subtract maxi k lj equat ensur pure node recycl condit inequ satisfi swap node perform orphan leaf reach small number exampl past parent spa detach tree becom child node j wherea old sibl ssib orphan node becom direct child old grandpar sgpa swap procedur show figur condit captur inequ allow us prove number time give node recycl upperbound logarithm number exampl whenev swap resist lemma lemma let swap resist rs great equal sequenc exampl number time algorithm recycl give node upperbound logarithm base sequenc length experi address sever hypothesi experiment lomtre algorithm achiev true logarithm time comput practic lomtre algorithm competit better logarithm traint time algorithm multiclass classif lomtre algorithm statist perform close common k approach address hypothesi contabl dataset size duct experi varieti isolet sector aloi imnet odp benchmark multiclass dataset isos mb mb mbgb gb let sector aloi imagenet i be featur k net odp detail exampl k dataset provid tabl dataset divid train class k k test furthermor train dataset use valid set baselin compar lomtre balanc random tree logarithm depth rtree filter tree [ ] comput feasibl also compar oneagainstal classifi oaa repres k approach method implement vowpal wabbit [ ] learn system similar level optim regressor tree node lomtre rtree filter tree well oaa regressor train onlin gradient descent explor step size choos set use compress detail sourc dataset provid supplementari materi linear regressor method investig train pass datum select good set paramet step size number pass one minim valid error addit lomtre investig differ set stop criterion tree expans k k k k k k k swap resist rs tabl report respect train time perexampl test time good perform indic bold train time later report test error provid oaa imagenet odp due intract petabyt scale comput tabl train time select problem tabl perexampl test time problem isolet sector aloi isolet sector aloi imnet odp lomtre lomtre ms ms ms ms ms oaa oaa ms ms ms log time ratio first hypothesi consist experiment result timewis lomtre significantli outperform oaa due build closeto logarithm depth tree improv train time increas number class classif problem instanc aloi train lomtre time faster oaa say test time perexampl test time aloi imagenet odp respect time faster oaa signific advantag lomtre oaa also captur figur next tabl good logarithm time perlomtre vs oneagainstal former indic bold report test error logarithm traint time algorithm also show binomi symmetr confid interv result clearli sec ond hypothesi also consist experiment result sinc rtree impos random label partit result error ob tain gener bad error obtain competitor method includ lomtre learn label partit directli data time lomtre beat fil ter tree everi dataset though imagenet log number class figur logarithm ratio perexampl odp high level nois advantag lomtre signific test time oaa lomtre problem tabl test error confid interv problem lomtre rtree filter tree oaa isolet sector aloi imnet na odp na third hypothesi weakli consist empir result time advantag lomtre come loss statist accuraci respect oaa oaa tractabl conclud lomtre significantli close gap logarithm time method oaa make plausibl approach comput constrain largek applic conclus lomtre algorithm reduc multiclass problem set binari problem organ tree structur partit everi tree node do optim new partit criterion onlin criterion guarante pure balanc split lead logarithm train test time tree classifi provid theoret justif approach via boost statement empir evalu multipl multiclass dataset empir find best avail logarithm time approach multiclass classif problem note howev mechan test datast much easi one simpli test effect untrain paramet exampl measur test speed thu perexampl test time oaa imagenet odp provid also good knowledg exist stateoftheart result oaa perform dataset publish literatur acknowledg would like thank alekh agarw dean foster robert schapir matu telgarski valuabl discuss refer [ ] r rifkin klautau defens onevsal classif j mach learn re [ ] cover j thoma element inform theori john wiley son inc [ ] l breiman j h friedman r olshen c j stone classif regress tree crc press llc boca raton florida [ ] kearn mansour boost abil topdown decis tree learn algorithm journal comput system scienc also stoc [ ] beygelzim j langford p ravikumar errorcorrect tournament alt [ ] beygelzim j langford lifshit g b sorkin l strehl condit probabl tree estim analysi algorithm uai [ ] c bishop pattern recognit machin learn springer [ ] bengio j weston grangi label emb tree larg multiclass task nip [ ] g madzarov gjorgjevikj chorbev multiclass svm classifi util binari decis tree informatica [ ] j deng satheesh c berg l feifei fast balanc effici label tree learn larg scale object recognit nip [ ] j weston makadia h yee label partit sublinear rank icml [ ] b zhao e p x spars output cod largescal visual recognit cvpr [ ] hsu kakad j langford zhang multilabel predict via compress sens nip [ ] agarw kakad n karampatziaki l song g valiant least squar revisit scalabl approach multiclass predict icml [ ] beijbom saberian kriegman n vasconcelo guessavers loss function costsensit multiclass boost icml [ ] r agarw gupta prabhu varma multilabel learn million label recommend advertis bid phrase web page www [ ] prabhu varma fastxml fast accur stabl treeclassifi extrem multilabel learn acm sigkdd [ ] h f yu p jain p kar dhillon largescal multilabel learn miss label icml [ ] liu yang h wan h j zeng z chen w support vector machin classif largescal taxonomi sigkdd explor [ ] p n bennett n nguyen refin expert improv classif larg taxonomi sigir [ ] montillo j tu j shotton j winn j e iglesia n metaxa criminisi entangl differenti inform gain maxim decis forest comput vision medic imag analysi [ ] k tentori v crupi n bonini osherson comparison confirm measur cognit [ ] r carnap logic foundat probabl nd ed chicago univers chicago press par pp [ ] shalevshwartz onlin learn onlin convex optim find trend mach learn [ ] j langford l li strehl httphunch net vw [ ] nesterov introductori lectur convex optim basic cours appli optim kluwer academ publ [ ] j deng w dong r socher l j li k li l feifei imagenet largescal hierarch imag databas cvpr
7,5802,Planar Ultrametrics for Image Segmentation,Poster,5802-planar-ultrametrics-for-image-segmentation.pdf,We study the problem of hierarchical clustering on planar graphs. We formulate this in terms of finding the closest ultrametric to a specified set of distances and solve it using an LP relaxation that leverages minimum cost perfect matching as a subroutine to efficiently explore the space of planar partitions. We apply our algorithm to the problem of hierarchical image segmentation.,"Planar Ultrametrics for Image Segmentation

Charless C. Fowlkes
Department of Computer Science
University of California Irvine
fowlkes@ics.uci.edu

Julian Yarkony
Experian Data Lab
San Diego, CA 92130
julian.yarkony@experian.com

Abstract
We study the problem of hierarchical clustering on planar graphs. We formulate
this in terms of finding the closest ultrametric to a specified set of distances and
solve it using an LP relaxation that leverages minimum cost perfect matching as
a subroutine to efficiently explore the space of planar partitions. We apply our
algorithm to the problem of hierarchical image segmentation.

1

Introduction

We formulate hierarchical image segmentation from the perspective of estimating an ultrametric
distance over the set of image pixels that agrees closely with an input set of noisy pairwise distances.
An ultrametric space replaces the usual triangle inequality with the ultrametric inequality d(u, v) ≤
max{d(u, w), d(v, w)} which captures the transitive property of clustering (if u and w are in the
same cluster and v and w are in the same cluster, then u and v must also be in the same cluster).
Thresholding an ultrametric immediately yields a partition into sets whose diameter is less than
the given threshold. Varying this distance threshold naturally produces a hierarchical clustering in
which clusters at high thresholds are composed of clusters at lower thresholds.
Inspired by the approach of [1], our method represents an ultrametric explicitly as a hierarchical
collection of segmentations. Determining the appropriate segmentation at a single distance threshold
is equivalent to finding a minimum-weight multicut in a graph with both positive and negative edge
weights [3, 14, 2, 11, 20, 21, 4, 19, 7]. Finding an ultrametric imposes the additional constraint that
these multicuts are hierarchically consistent across different thresholds. We focus on the case where
the input distances are specified by a planar graph. This arises naturally in the domain of image
segmentation where elements are pixels or superpixels and distances are defined between neighbors
and allows us to exploit fast combinatorial algorithms for partitioning planar graphs that yield tighter
LP relaxations than the local polytope relaxation often used in graphical inference [20].
The paper is organized as follows. We first introduce the closest ultrametric problem and the relation between multicuts and ultrametrics. We then describe an LP relaxation that uses a delayed
column generation approach and exploits planarity to efficiently find cuts via the classic reduction
to minimum-weight perfect matching [13, 8, 9, 10]. We apply our algorithm to the task of natural
image segmentation and demonstrate that our algorithm converges rapidly and produces optimal or
near-optimal solutions in practice.

2

Closest Ultrametric and Multicuts

Let G = (V, E) be a weighted graph with non-negative edge weights θ indexed by edges e =
(u, v) ∈ E. Our goal is to find an ultrametric distance d(u,v) over vertices of the graph that is
P
close to θ in the sense that the distortion (u,v)∈E kθ(u,v) − d(u,v) k22 is minimized. We begin by
reformulating this closest ultrametric problem in terms of finding a set of nested multicuts in a family
of weighted graphs.
1

We specify a partitioning or multicut of the vertices of the graph G into components using a binary
vector X̄ ∈ {0, 1}|E| where X̄e = 1 indicates that the edge e = (u, v) is “cut” and that the vertices
u and v associated with the edge are in separate components of the partition. We use MCUT(G)
to denote the set of binary indicator vectors X̄ that represent valid multicuts of the graph G. For
notational simplicity, in the remainder of the paper we frequently omit the dependence on G which
is given as a fixed input.
A necessary and sufficient condition for an indicator vector X̄ to define a valid multicut in G is that
for every cycle of edges, if one edge on the cycle is cut then at least one other edge in the cycle must
also be cut. Let C denote the set of all cycles in G where each cycle c ∈ C is a set of edges and
c − ê is the set of edges in cycle c excluding edge ê. We can express MCUT in terms of these cycle
inequalities as:
(
)
X
|E|
X̄e ≥ X̄ê , ∀c ∈ C, ê ∈ c
(1)
MCUT = X̄ ∈ {0, 1} :
e∈c−ê

A hierarchical clustering of a graph can be described by a nested collection of multicuts. We denote
the space of valid hierarchical partitions with L layers by Ω̄L which we represent by a set of L
edge-indicator vectors X = (X̄ 1 , X̄ 2 , X̄ 3 , . . . , X̄ L ) in which any cut edge remains cut at all finer
layers of the hierarchy.
Ω̄L = {(X̄ 1 , X̄ 2 , . . . X̄ L ) : X̄ l ∈ MCUT, X̄ l ≥ X̄ l+1 ∀l}

(2)

Given a valid hierarchical clustering X , an ultrametric d can be specified over the vertices of the
graph by choosing a sequence of real values 0 = δ 0 < δ 1 < δ 2 < . . . < δ L that indicate a distance
threshold associated with each level l of the hierarchical clustering. The ultrametric distance d
specified by the pair (X , δ) assigns a distance to each pair of vertices d(u,v) based on the coarsest
level of the clustering at which they remain in separate clusters. For pairs corresponding to an edge
in the graph (u, v) = e ∈ E we can write this explicitly in terms of the multicut indicator vectors
as:
L
X
de =
max δ l X̄el =
δ l [X̄el > X̄el+1 ]
(3)
l∈{0,1,...,L}

l=0

X̄eL+1

X̄e0

= 0. Pairs (u, v) that do not correspond to an
= 1 and
We assume by convention that
edge in the original graph can still be assigned a unique distance based on the coarsest level l at
which they lie in different connected components of the cut specified by X l .
To compute the quality of an ultrametric d with respect to an input set of edge weights θ, we measure
the squared L2 difference between the edge weights and the ultrametric distance kθ − dk22 . To write
this compactly in terms of multicut
Pm indicator vectors, we construct a set of weights for each edge
and layer, denoted θel so that l=0 θel = kθe − δ m k2 . These weights are given explicitly by the
telescoping series:
θe0 = kθe k2
l

We use θ ∈ R

|E|

θel = kθe − δ l k2 − kθe − δ l−1 k2

to denote the vector containing

θel

∀l > 1

(4)

for all e ∈ E.

For a fixed number of levels L and fixed set of thresholds δ, the problem of finding the closest
ultrametric d can then be written as an integer linear program (ILP) over the edge cut indicators.


2
L
L

X
X
XX

l
l
l+1 
min
δ [X̄e > X̄e ]
 = min
kθe − δ l k2 (X̄el − X̄el+1 )
(5)

θe −


X ∈Ω̄L
X ∈Ω̄L
e∈E
e∈E l=0
l=0
!
L
X
X
 l
2 0
l 2
l−1 2
L 2 L+1
kθe − δ k − kθe − δ k X̄e + kθe − δ k X̄e
= min
kθe k X̄e +
X ∈Ω̄L

= min
X ∈Ω̄L

e∈E
L X
X
l=0 e∈E

l=1

θel X̄el = min

X ∈Ω̄L

L
X

θl · X̄ l

(6)

l=0

This optimization corresponds to solving a collection of minimum-weight multicut problems where
the multicuts are constrained to be hierarchically consistent.
2

(a) Linear combination of cut vectors

(b) Hierarchical cuts

Figure 1: (a) Any partitioning X can be represented as a linear superposition of cuts Z where
each cut isolates a connected component of the partition and is assigned a weight γ = 12 [20]. By
introducing an auxiliary slack variables β, we are able to represent a larger set of valid indicator
vectors X using fewer columns of Z. (b) By introducing additional slack variables at each layer of
the hierarchical segmentation, we can efficiently represent many hierarchical segmentations (here
{X 1 , X 2 , X 3 }) that are consistent from layer to layer while using only a small number of cut indicators as columns of Z.
Computing minimum-weight multicuts (also known as correlation clustering) is NP hard even in the
case of planar graphs [6]. A direct approach to finding an approximate solution to Eq 6 is to relax
the integrality constraints on X̄ l and instead optimize over the whole polytope defined by the set of
cycle inequalities. We use ΩL to denote the corresponding relaxation of Ω̄L . While the resulting
polytope is not the convex hull of MCUT, the integral vertices do correspond exactly to the set of
valid multicuts [12].
In practice, we found that applying a straightforward cutting-plane approach that successively adds
violated cycle inequalities to this relaxation of Eq 6 requires far too many constraints and is too
slow to be useful. Instead, we develop a column generation approach tailored for planar graphs that
allows for efficient and accurate approximate inference.

3

The Cut Cone and Planar Multicuts

Consider a partition of a planar graph into two disjoint sets of nodes. We denote the space of
indicator vectors corresponding to such two-way cuts by CUT. A cut may yield more than two
connected components but it can not produce every possible multicut (e.g., it can not split a triangle
of three nodes into three separate components). Let Z ∈ {0, 1}|E|×|CUT| be an indicator matrix
where each column specifies a valid two-way cut with Zek = 1 if and only if edge e is cut in twoway cut k. The indicator vector of any multicut in a planar graph can be generated by a suitable
linear combination of of cuts (columns of Z) that isolate the individual components from the rest of
the graph where the weight of each such cut is 12 .
Let γ ∈ R|CUT| be a vector specifying a positive weighted combination of cuts. The set CUT4 =
{Zγ : γ ≥ 0} is the conic hull of CUT or “cut cone”. Since any multicut can be expressed as a
superposition of cuts, the cut cone is identical to the conic hull of MCUT. This equivalence suggests
an LP relaxation of the minimum-cost multicut given by
min θ · Zγ

s.t. Zγ ≤ 1

γ≥0

(7)

where the vector θ ∈ R|E| specifies the edge weights. For the case of planar graphs, any solution to
this LP relaxation satisfies the cycle inequalities (see supplement and [12, 18, 10]).
Expanded Multicut Objective: Since the matrix Z contains an exponential number of cuts, Eq. 7
is still intractable. Instead we consider an approximation using a constraint set Ẑ which is a subset
3

of columns of Z. In previous work [20], we showed that since the optimal multicut may no longer
lie in the span of the reduced cut matrix Ẑ, it is useful to allow some values of Ẑγ exceed 1 (see
Figure 1(a) for an example).
We introduce a slack vector β ≥ 0 that tracks the presence of any “overcut” edges and prevents
them from contributing to the objective when the corresponding edge weight is negative. Let θe− =
min(θe , 0) denote the non-positive component of θe . The expanded multi-cut objective is given by:
min θ · Ẑγ − θ− · β

s.t. Ẑγ − β ≤ 1

γ≥0
β≥0

(8)

For any edge e such that θe < 0, any decrease in the objective from overcutting by an amount βe is
exactly compensated for in the objective by the term −θe− βe .
When Ẑ contains all cuts (i.e., Ẑ = Z) then Eq 7 and Eq 8 are equivalent [20]. Further, if γ ? is the
minimizer of Eq 8 when Ẑ only contains a subset of columns, then the edge indicator vector given
by X = min(1, Ẑγ ? ) still satisfies the cycle inequalities (see supplement for details).

4

Expanded LP for Finding the Closest Ultrametric

To develop an LP relaxation of the closest ultrametric problem, we replace the multicut problem at
each layer l with the expanded multicut objective described by Eq 8. We let γ = {γ 1 , γ 2 , γ 3 . . . γ L }
and β = {β 1 , β 2 , β 3 . . . β L } denote the collection of weights and slacks for the levels of the hierarchy and let θe+l = max(0, θel ) and θe−l = min(0, θel ) denote the positive and negative components
of θl .
To enforce hierarchical consistency between layers, we would like to add the constraint that
Zγ l+1 ≤ Zγ l . However, this constraint is too rigid when Z does not include all possible cuts.
It is thus computationally useful to introduce an additional slack vector associated with each level l
and edge e which we denote as α = {α1 , α2 , α3 . . . αL−1 }. The introduction of αel allows for cuts
represented by Zγ l to violate the hierarchical constraint. We modify the objective so that violations
to the original hierarchy constraint are paid for in proportion to θe+l . The introduction of α allows
us to find valid ultrametrics while using a smaller number of columns of Z to be used than would
otherwise be required (illustrated in Figure 1(b)).
We call this relaxed closest ultrametric problem including the slack variable α the expanded closest
ultrametric objective, written as:
min

L
L
L−1
X
X
X
θl · Zγ l +
−θ−l · β l +
θ+l · αl

γ≥0
β≥0 l=1
α≥0

l=1

s.t. Zγ l+1 + αl+1 ≤ Zγ l + αl
l

l

Zγ − β ≤ 1

(9)

l=1

∀l < L

∀l

where by convention we define αL = 0 and we have dropped the constant l = 0 term from Eq 6.
Given a solution (α, β, γ) we can recover a relaxed solution to the closest ultrametric problem (Eq.
6) over ΩL by setting Xel = min(1, maxm≥l (Zγ m )e ). In the supplement, we demonstrate that for
any (α, β, γ) that obeys the constraints in Eq 9, this thresholding operation yields a solution X that
lies in ΩL and achieves the same or lower objective value.

5

The Dual Objective

We optimize the dual of the objective in Eq 9 using an efficient column generation approach based
on perfect matching. We introduce two sets of Lagrange multipliers ω = {ω 1 , ω 2 , ω 3 . . . ω L−1 } and
λ = {λ1 , λ2 , λ3 . . . λL } corresponding to the between and within layer constraints respectively. For
4

Algorithm 1 Dual Closest Ultrametric via Cutting Planes
Ẑ l ← {} ∀l, residual ← −∞
while residual < 0 do
{ω}, {λ} ← Solve Eq 10 given Ẑ
residual = 0
for l = 1 : L do
z l ← arg minz∈CUT (θl + λl + ω l−1 − ω l ) · z
residual ← residual + 32 (θl + λl + ω l−1 − ω l ) · z l
{z(1), z(2), . . . , z(M )} ← isocuts(z l )
Ẑ l ← Ẑ l ∪ {z(1), z(2), . . . , z(M )}
end for
end while
notational convenience, let ω 0 = 0. The dual objective can then be written as
max

L
X

ω≥0,λ≥0

l=1
−l

θ

−λl · 1
≤ −λl

− (ω

l−1

l

(10)
∀l

− ω l ) ≤ θ+l

l

(θ + λ + ω

l−1

l

∀l

−ω )·Z ≥0

∀l

The dual LP can be interpreted as finding a small modification of the original edge weights θl so
that every possible two-way cut of each resulting graph at level l has non-negative weight. Observe
that the introduction of the two slack terms α and β in the primal problem (Eq 9) results in bounds
on the Lagrange multipliers λ and ω in the dual problem in Eq 10. In practice these dual constraints
turn out to be essential for efficient optimization and constitute the core contribution of this paper.

6

Solving the Dual via Cutting Planes

The chief complexity of the dual LP is contained in the constraints including Z which encodes
non-negativity of an exponential number of cuts of the graph represented by the columns of Z. To
circumvent the difficulty of explicitly enumerating the columns of Z, we employ a cutting plane
method that efficiently searches for additional violated constraints (columns of Z) which are then
successively added.
Let Ẑ denote the current working set of columns. Our dual optimization algorithm iterates over
the following three steps: (1) Solve the dual LP with Ẑ, (2) find the most violated constraint of the
form (θl + λl + ω l−1 − ω l ) · Z ≥ 0 for layer l, (3) Append a column to the matrix Ẑ for each
such cut found. We terminate when no violated constraints exist or a computational budget has been
exceeded.
Finding Violated Constraints: Identifying columns to add to Ẑ is carried out for each layer l
separately. Finding the most violated constraint of the full problem corresponds to computing the
minimum-weight cut of a graph with edge weights θl + λl + ω l−1 − ω l . If this cut has non-negative
weight then all the constraints are satisfied, otherwise we add the corresponding cut indicator vector
as an additional column of Z.
To generate a new constraint for layer l based on the current Lagrange multipliers, we solve
X
z l = arg min
(θel + λle + ωel−1 − ωel )ze
z∈CUT

(11)

e∈E

and subsequently add the new constraints from all layers to our LP, Ẑ ← [Ẑ, z 1 , z 2 , . . . z L ].
Unlike the multicut problem, finding a (two-way) cut in a planar graph can be solved exactly by a
reduction to minimum-weight perfect matching. This is a classic result that, e.g. provides an exact
solution for the ground state of a 2D lattice Ising model without a ferromagnetic field [13, 8, 9, 10]
3
in O(N 2 log N ) time [15].
5

80

UB
LB

60

−2

Bound

Counts

10

40

−4

10

20

0

10

1

10

2

10

0
0.2

3

10

Time (sec)

0.4
0.6
0.8
Objective ratio (UCM / UM)

1

Figure 2: (a): The average convergence of the upper (blue) and lower-bounds (red) as a function
of running time. Values plotted are the gap between the bound and the best lower-bound computed
(at termination) for a given problem instance. This relative gap is averaged over problem instances
which have not yet converged at a given time point. We indicate the percentage of problem instances
that have yet to terminate using black bars marking [95, 85, 75, 65, .....5] percent. (b) Histogram of
the ratio of closest ultrametric objective values for our algorithm (UM) and the baseline clustering
produced by UCM. All ratios were less than 1 showing that in no instances did UM produce a worse
solution than UCM

Computing a lower bound: At a given iteration, prior to adding a newly generated set of constraints
P
we can compute the total residual constraint violation over all layers of hierarchy by ∆ = l (θl +
λl + ω l−1 − ω l ) · z l . In the supplement we demonstrate that the value of the dual objective plus
3
2 ∆ is a lower-bound on the relaxed closest ultrametric problem in Eq 9. Thus, as the costs of the
minimum-weight matchings approach zero from below, the objective of the reduced problem over
Ẑ approaches an accurate lower-bound on optimization over Ω̄L
Expanding generated cut constraints: When a given cut z l produces more than two connected
components, we found it useful to add a constraint corresponding to each component, following the
approach of [20]. Let the number of connected components of z l be denoted M . For each of the
M components then we add one column to Z corresponding to the cut that isolates that connected
component from the rest. This allows more flexibility in representing the final optimum multicut as
superpositions of these components. In addition, we also found it useful in practice to maintain a
separate set of constraints Ẑ l for each layer l. Maintaining independent constraints Ẑ 1 , Ẑ 2 , . . . , Ẑ L
can result in a smaller overall LP.
Speeding convergence of ω: We found that adding an explicit penalty term to the objective that
encourages small values of ω speeds up convergence dramatically with no loss in solution quality.
In our experiments, this penalty is scaled by a parameter  = 10−4 which is chosen to be extremely
small in magnitude relative to the values of θ so that it only has an influence when no other “forces”
are acting on a given term in ω.
Primal Decoding: Algorithm 1 gives a summary of the dual solver which produces a lower-bound
as well as a set of cuts described by the constraint matrices Ẑ l . The subroutine isocuts(z l ) computes
the set of cuts that isolate each connected component of z l . To generate a hierarchical clustering,
we solve the primal, Eq 9, using the reduced set Ẑ in order to recover a fractional solution Xel =
min(1, maxm≥l (Ẑ m γ m )e ). We use an LP solver (IBM CPLEX) which provides this primal solution
“for free” when solving the dual in Alg. 1.
We round the fractional primal solution X to a discrete hierarchical clustering by thresholding:
X̄el ← [Xel > t]. We then repair (uncut) any cut edges that lie inside a connected component. In our
implementation we test a few discrete thresholds t ∈ {0, 0.2, 0.4, 0.6, 0.8} and take that threshold
that yields X̄ with the lowest cost. After each pass through the loop of Alg. 1 we compute these
upper-bounds and retain the optimum solution observed thus far.
6

1

Precision

0.8

Maximum F−measure

UCM
UCM−L
UM

0.9

0.7
0.6
0.5
0.4
0

0.2

0.4

0.6

0.8

0.7
0.6
0.5

0.3 0
10

1

Recall

UM
UCM−L
UCM

0.4

1

10

2

10
Time (sec)

3

10

Figure 3: (a) Boundary detection performance of our closest ultrametric algorithm (UM) and the
baseline ultrametric contour maps algorithm with (UCM) and without (UCM-L) length weighting
[5] on BSDS. Black circles indicate thresholds used in the closest UM optimization. (b) Anytime
performance: F-measure on the BSDS benchmark as a function of run-time. UM, UCM with and
without length weighting achieve a maximum F-measure of 0.728, 0.726, and 0.718 respectively.

7

Experiments

We applied our algorithm to segmenting images from the Berkeley Segmentation Data set (BSDS)
[16]. We use superpixels generated by performing an oriented watershed transform on the output
of the global probability of boundary (gPb) edge detector [17] and construct a planar graph whose
vertices are superpixels with edges connecting neighbors in the image plane whose base distance θ
is derived from gP b.
Let gP be be the local estimate of boundary contrast given by averaging the gP b classifier output
over the boundary between a pair of neighboring superpixels.
We 
truncate extreme values to enforce


gP be
that gP be ∈ [, 1 − ] with  = 0.001 and set θe = log 1−gP be + log 1−
The additive offset

assures that θe ≥ 0. In our experiments we use a fixed set of eleven distance threshold levels {δl }
chosen to uniformly span the useful range of threshold values [9.6, 12.6]. Finally, we weighted edges
proportionally to the length of the corresponding boundary in the image.
We performed dual cutting plane iterations until convergence or 2000 seconds had passed. Lowerbounds for the BSDS segmentations were on the order of −103 or −104 . We terminate when the
total residual is greater than −2 × 10−4 . All codes were written in MATLAB using the Blossom
V implementation of minimum-weight perfect matching [15] and the IBM ILOG CPLEX LP solver
with default options.
Baseline: We compare our results with the hierarchical clusterings produced by the Ultrametric
Contour Map (UCM) [5]. UCM performs agglomerative clustering of superpixels and assigns the
length-weighted averaged gP b value as the distance between each pair of merged regions. While
UCM was not explicitly designed to find the closest ultrametric, it provides a strong baseline for
hierarchical clustering. To compute the closest l-level ultrametric corresponding to the UCM clustering result, we solve the minimization in Eq. 6 while restricting each multicut to be the partition
at some level of the UCM hierarchy.
Convergence and Timing: Figure 2 shows the average behavior of convergence as a function of
runtime. We found the upper-bound given by the cost of the decoded integer solution and the lowerbound estimated by the dual LP are very close. The integrality gap is typically within 0.1% of the
lower-bound and never more than 1 %. Convergence of the dual is achieved quite rapidly; most
instances require less than 100 iterations to converge with roughly linear growth in the size of the
LP at each iteration as cutting planes are added. In Fig 2 we display a histogram, computed over test
image problem instances, of the cost of UCM solutions relative to those produced by closest ultrametric (UM) estimated by our method. A ratio of less than 1 indicates that our approach generated
a solution with a lower distortion ultrametric. In no problem instance did UCM outperform our UM
algorithm.
7

UM

MC

UM

MC

Figure 4: The proposed closest ultrametric (UM) enforces consistency across levels while performing independent multi-cut clustering (MC) at each threshold does not guarantee a hierarchical
segmentation (c.f. first image, columns 3 and 4). In the second image, hierarchical segmentation
(UM) better preserves semantic parts of the two birds while correctly merging the background regions.
Segmentation Quality: Figure 3 shows the segmentation benchmark accuracy of our closest ultrametric algorithm (denoted UM) along with the baseline ultrametric contour maps algorithm (UCM)
with and without length weighting [5]. In terms of segmentation accuracy, UM performs nearly identically to the state of the art UCM algorithm with some small gains in the high-precision regime. It
is worth noting that the BSDS benchmark does not provide strong penalties for small leaks between
two segments when the total number of boundary pixels involved is small. Our algorithm may find
strong application in domains where the local boundary signal is noisier (e.g., biological imaging)
or when under-segmentation is more heavily penalized.
While our cutting-plane approach is slower than agglomerative clustering, it is not necessary to wait
for convergence in order to produce high quality results. We found that while the upper and lower
bounds decrease as a function of time, the clustering performance as measured by precision-recall
is often nearly optimal after only ten seconds and remains stable. Figure 3 shows a plot of the
F-measure achieved by UM as a function of time.
Importance of enforcing hierarchical constraints: Although independently finding multicuts at
different thresholds often produces hierarchical clusterings, this is by no means guaranteed. We ran
Algorithm 1 while setting ωel = 0, allowing each layer to be solved independently. Fig 4 shows
examples where hierarchical constraints between layers improves segmentation quality relative to
independent clustering at each threshold.

8

Conclusion

We have introduced a new method for approximating the closest ultrametric on planar graphs that
is applicable to hierarchical image segmentation. Our contribution is a dual cutting plane approach
that exploits the introduction of novel slack terms that allow for representing a much larger space of
solutions with relatively few cutting planes. This yields an efficient algorithm that provides rigorous
bounds on the quality the resulting solution. We empirically observe that our algorithm rapidly
produces compelling image segmentations along with lower- and upper-bounds that are nearly tight
on the benchmark BSDS test data set.
Acknowledgements: JY acknowledges the support of Experian, CF acknowledges support of NSF
grants IIS-1253538 and DBI-1262547
8

References
[1] Nir Ailon and Moses Charikar. Fitting tree metrics: Hierarchical clustering and phylogeny. In
Foundations of Computer Science, 2005., pages 73–82, 2005.
[2] Bjoern Andres, Joerg H. Kappes, Thorsten Beier, Ullrich Kothe, and Fred A. Hamprecht. Probabilistic image segmentation with closedness constraints. In Proc. of ICCV, pages 2611–2618,
2011.
[3] Bjoern Andres, Thorben Kroger, Kevin L. Briggman, Winfried Denk, Natalya Korogod, Graham Knott, Ullrich Kothe, and Fred. A. Hamprecht. Globally optimal closed-surface segmentation for connectomics. In Proc. of ECCV, 2012.
[4] Bjoern Andres, Julian Yarkony, B. S. Manjunath, Stephen Kirchhoff, Engin Turetken, Charless
Fowlkes, and Hanspeter Pfister. Segmenting planar superpixel adjacency graphs w.r.t. nonplanar superpixel affinity graphs. In Proc. of EMMCVPR, 2013.
[5] Pablo Arbelaez, Michael Maire, Charless Fowlkes, and Jitendra Malik. Contour detection and
hierarchical image segmentation. IEEE Trans. Pattern Anal. Mach. Intell., 33(5):898–916,
May 2011.
[6] Yoram Bachrach, Pushmeet Kohli, Vladimir Kolmogorov, and Morteza Zadimoghaddam. Optimal coalition structure generation in cooperative graph games. In Proc. of AAAI, 2013.
[7] Shai Bagon and Meirav Galun. Large scale correlation clustering. In CoRR, abs/1112.2903,
2011.
[8] F Barahona. On the computational complexity of ising spin glass models. Journal of Physics
A: Mathematical, Nuclear and General, 15(10):3241–3253, april 1982.
[9] F Barahona. On cuts and matchings in planar graphs. Mathematical Programming, 36(2):53–
68, november 1991.
[10] F Barahona and A Mahjoub. On the cut polytope. Mathematical Programming, 60(1-3):157–
173, September 1986.
[11] Thorsten Beier, Thorben Kroeger, Jorg H Kappes, Ullrich Kothe, and Fred A Hamprecht. Cut,
glue, and cut: A fast, approximate solver for multicut partitioning. In Computer Vision and
Pattern Recognition (CVPR), 2014 IEEE Conference on, pages 73–80, 2014.
[12] Michel Deza and Monique Laurent. Geometry of cuts and metrics, volume 15. Springer
Science & Business Media, 1997.
[13] Michael Fisher. On the dimer solution of planar ising models. Journal of Mathematical
Physics, 7(10):1776–1781, 1966.
[14] Sungwoong Kim, Sebastian Nowozin, Pushmeet Kohli, and Chang Dong Yoo. Higher-order
correlation clustering for image segmentation. In Advances in Neural Information Processing
Systems,25, pages 1530–1538, 2011.
[15] Vladimir Kolmogorov. Blossom v: a new implementation of a minimum cost perfect matching
algorithm. Mathematical Programming Computation, 1(1):43–67, 2009.
[16] David Martin, Charless Fowlkes, Doron Tal, and Jitendra Malik. A database of human segmented natural images and its application to evaluating segmentation algorithms and measuring
ecological statistics. In Proc. of ICCV, pages 416–423, 2001.
[17] David Martin, Charless C. Fowlkes, and Jitendra Malik. Learning to detect natural image
boundaries using local brightness, color, and texture cues. IEEE Trans. Pattern Anal. Mach.
Intell., 26(5):530–549, May 2004.
[18] Julian Yarkony. Analyzing PlanarCC. NIPS 2014 workshop, 2014.
[19] Julian Yarkony, Thorsten Beier, Pierre Baldi, and Fred A Hamprecht. Parallel multicut segmentation via dual decomposition. In New Frontiers in Mining Complex Patterns, 2014.
[20] Julian Yarkony, Alexander Ihler, and Charless Fowlkes. Fast planar correlation clustering for
image segmentation. In Proc. of ECCV, 2012.
[21] Chong Zhang, Julian Yarkony, and Fred A. Hamprecht. Cell detection and segmentation using
correlation clustering. In MICCAI, volume 8673, pages 9–16, 2014.

9

",studi problem hierarch cluster planar graph formul term find close ultrametr specifi set distanc solv use lp relax leverag minimum cost perfect match subroutin effici explor space planar partit appli algorithm problem hierarch imag segment,planar ultrametr imag segment charless c fowlk depart comput scienc univers california irvin fowlkes uci edu julian yarkoni experian datum lab san diego ca julian yarkonyexperian com abstract studi problem hierarch cluster planar graph formul term find close ultrametr specifi set distanc solv use lp relax leverag minimum cost perfect match subroutin effici explor space planar partit appli algorithm problem hierarch imag segment introduct formul hierarch imag segment perspect estim ultrametr distanc set imag pixel agre close input set noisi pairwis distanc ultrametr space replac usual triangl inequ ultrametr inequ u v max u w v w captur transit properti cluster u w cluster v w cluster u v must also cluster threshold ultrametr immedi yield partit set whose diamet less give threshold vari distanc threshold natur produc hierarch cluster cluster high threshold compos cluster low threshold inspir approach [ ] method repres ultrametr explicitli hierarch collect segment determin appropri segment singl distanc threshold equival find minimumweight multicut graph posit neg edg weight [ ] find ultrametr impos addit constraint multicut hierarch consist across differ threshold focu case input distanc specifi planar graph aris natur domain imag segment element pixel superpixel distanc defin neighbor allow us exploit fast combinatori algorithm partit planar graph yield tight lp relax local polytop relax often use graphic infer [ ] paper organ follow first introduc close ultrametr problem relat multicut ultrametr describ lp relax use delay column gener approach exploit planar effici find cut via classic reduct minimumweight perfect match [ ] appli algorithm task natur imag segment demonstr algorithm converg rapidli produc optim nearoptim solut practic close ultrametr multicut let g v e weight graph nonneg edg weight index edg e u v e goal find ultrametr distanc uv vertex graph p close sens distort uv e k uv uv k minim begin reformul close ultrametr problem term find set nest multicut famili weight graph specifi partit multicut vertex graph g compon use binari vector x e xe indic edg e u v cut vertex u v associ edg separ compon partit use mcut g denot set binari indic vector x repres valid multicut graph g notat simplic remaind paper frequent omit depend g give fix input necessari suffici condit indic vector x defin valid multicut g everi cycl edg one edg cycl cut least one edg cycl must also cut let c denot set cycl g cycl c c set edg c e set edg cycl c exclud edg e express mcut term cycl inequ x e xe xe c c e c mcut x ece hierarch cluster graph describ nest collect multicut denot space valid hierarch partit l layer l repres set l edgeind vector x x x x x l cut edg remain cut fine layer hierarchi l x x x l x l mcut x l x l l give valid hierarch cluster x ultrametr specifi vertex graph choos sequenc real valu l indic distanc threshold associ level l hierarch cluster ultrametr distanc specifi pair x assign distanc pair vertex uv base coars level cluster remain separ cluster pair correspond edg graph u v e e write explicitli term multicut indic vector l x de max l xel l [ xel xel ] l l l xel xe pair u v correspond assum convent edg origin graph still assign uniqu distanc base coars level l lie differ connect compon cut specifi x l comput qualiti ultrametr respect input set edg weight measur squar l differ edg weight ultrametr distanc k dk write compactli term multicut pm indic vector construct set weight edg layer denot el l el ke k weight give explicitli telescop seri e ke k l use r e el ke l k ke l k denot vector contain el l e e fix number level l fix set threshold problem find close ultrametr write integ linear program ilp edg cut indic l l x x xx l l l min [ xe xe ] min ke l k xel xel e x l x l ee ee l l l x x l l l l l ke k ke k xe ke k xe min ke k xe x l min x l ee l x x l ee l el xel min x l l x l x l l optim correspond solv collect minimumweight multicut problem multicut constrain hierarch consist linear combin cut vector b hierarch cut figur partit x repres linear superposit cut z cut isol connect compon partit assign weight [ ] introduc auxiliari slack variabl abl repres larg set valid indic vector x use few column z b introduc addit slack variabl layer hierarch segment effici repres mani hierarch segment x x x consist layer layer use small number cut indic column z comput minimumweight multicut also know correl cluster np hard even case planar graph [ ] direct approach find approxim solut eq relax integr constraint x l instead optim whole polytop defin set cycl inequ use l denot correspond relax l result polytop convex hull mcut integr vertex correspond exactli set valid multicut [ ] practic find appli straightforward cuttingplan approach success add violat cycl inequ relax eq requir far mani constraint slow use instead develop column gener approach tailor planar graph allow effici accur approxim infer cut cone planar multicut consid partit planar graph two disjoint set node denot space indic vector correspond twoway cut cut cut may yield two connect compon produc everi possibl multicut e g split triangl three node three separ compon let z e cut indic matrix column specifi valid twoway cut zek edg e cut twoway cut k indic vector multicut planar graph gener suitabl linear combin cut column z isol individu compon rest graph weight cut let r cut vector specifi posit weight combin cut set cut z conic hull cut cut cone sinc multicut express superposit cut cut cone ident conic hull mcut equival suggest lp relax minimumcost multicut give min z z vector r e specifi edg weight case planar graph solut lp relax satisfi cycl inequ see supplement [ ] expand multicut object sinc matrix z contain exponenti number cut eq still intract instead consid approxim use constraint set z subset column z previou work [ ] show sinc optim multicut may longer lie span reduc cut matrix z use allow valu z exceed see figur exampl introduc slack vector track presenc overcut edg prevent contribut object correspond edg weight neg let e min e denot nonposit compon e expand multicut object give min z z edg e e decreas object overcut amount e exactli compens object term e e z contain cut e z z eq eq equival [ ] minim eq z contain subset column edg indic vector give x min z still satisfi cycl inequ see supplement detail expand lp find close ultrametr develop lp relax close ultrametr problem replac multicut problem layer l expand multicut object describ eq let l l denot collect weight slack level hierarchi let el max el el min el denot posit neg compon l enforc hierarch consist layer would like add constraint z l z l howev constraint rigid z includ possibl cut thu comput use introduc addit slack vector associ level l edg e denot l introduct el allow cut repres z l violat hierarch constraint modifi object violat origin hierarchi constraint pay proport el introduct allow us find valid ultrametr use small number column z use would otherwis requir illustr figur b call relax close ultrametr problem includ slack variabl expand close ultrametr object write min l l l x x x l z l l l l l l l z l l z l l l l z l l l l convent defin l drop constant l term eq give solut recov relax solut close ultrametr problem eq l set xel min maxml z e supplement demonstr obey constraint eq threshold oper yield solut x lie l achiev low object valu dual object optim dual object eq use effici column gener approach base perfect match introduc two set lagrang multipli l l correspond within layer constraint respect algorithm dual close ultrametr via cut plane z l l residu residu solv eq give z residu l l z l arg minzcut l l l l z residu residu l l l l z l z z z isocut z l z l z l z z z end end notat conveni let dual object write max l x l l l l l l l l l l l l l z l dual lp interpret find small modif origin edg weight l everi possibl twoway cut result graph level l nonneg weight observ introduct two slack term primal problem eq result bound lagrang multipli dual problem eq practic dual constraint turn essenti effici optim constitut core contribut paper solv dual via cut plane chief complex dual lp contain constraint includ z encod nonneg exponenti number cut graph repres column z circumv difficulti explicitli enumer column z employ cut plane method effici search addit violat constraint column z success add let z denot current work set column dual optim algorithm iter follow three step solv dual lp z find violat constraint form l l l l z layer l append column matrix z cut find termin violat constraint exist comput budget exceed find violat constraint identifi column add z carri layer l separ find violat constraint full problem correspond comput minimumweight cut graph edg weight l l l l cut nonneg weight constraint satisfi otherwis add correspond cut indic vector addit column z gener new constraint layer l base current lagrang multipli solv x z l arg min el le el el ze zcut ee subsequ add new constraint layer lp z [ z z z z l ] unlik multicut problem find twoway cut planar graph solv exactli reduct minimumweight perfect match classic result e g provid exact solut ground state lattic is model without ferromagnet field [ ] n log n time [ ] ub lb bind count time sec object ratio ucm um figur averag converg upper blue lowerbound red function run time valu plot gap bind good lowerbound comput termin give problem instanc rel gap averag problem instanc yet converg give time point indic percentag problem instanc yet termin use black bar mark [ ] percent b histogram ratio close ultrametr object valu algorithm um baselin cluster produc ucm ratio less show instanc um produc bad solut ucm comput lower bind give iter prior add newli gener set constraint p comput total residu constraint violat layer hierarchi l l l l l z l supplement demonstr valu dual object plu lowerbound relax close ultrametr problem eq thu cost minimumweight match approach zero object reduc problem z approach accur lowerbound optim l expand gener cut constraint give cut z l produc two connect compon find use add constraint correspond compon follow approach [ ] let number connect compon z l denot compon add one column z correspond cut isol connect compon rest allow flexibl repres final optimum multicut superposit compon addit also find use practic maintain separ set constraint z l layer l maintain independ constraint z z z l result small overal lp speed converg find add explicit penalti term object encourag small valu speed converg dramat loss solut qualiti experi penalti scale paramet choos extrem small magnitud rel valu influenc forc act give term primal decod algorithm give summari dual solver produc lowerbound well set cut describ constraint matric z l subroutin isocut z l comput set cut isol connect compon z l gener hierarch cluster solv primal eq use reduc set z order recov fraction solut xel min maxml z e use lp solver ibm cplex provid primal solut free solv dual alg round fraction primal solut x discret hierarch cluster threshold xel [ xel ] repair uncut cut edg lie insid connect compon implement test discret threshold take threshold yield x low cost pass loop alg comput upperbound retain optimum solut observ thu far precis maximum fmeasur ucm ucml um recal um ucml ucm time sec figur boundari detect perform close ultrametr algorithm um baselin ultrametr contour map algorithm ucm without ucml length weight [ ] bsd black circl indic threshold use close um optim b anytim perform fmeasur bsd benchmark function runtim um ucm without length weight achiev maximum fmeasur respect experi appli algorithm segment imag berkeley segment datum set bsd [ ] use superpixel gener perform orient watersh transform output global probabl boundari gpb edg detector [ ] construct planar graph whose vertex superpixel edg connect neighbor imag plane whose base distanc deriv gp b let gp local estim boundari contrast give averag gp b classifi output boundari pair neighbor superpixel truncat extrem valu enforc gp gp [ ] set e log gp log addit offset assur e experi use fix set eleven distanc threshold level l choos uniformli span use rang threshold valu [ ] final weight edg proport length correspond boundari imag perform dual cut plane iter converg second pass lowerbound bsd segment order termin total residu great code write matlab use blossom v implement minimumweight perfect match [ ] ibm ilog cplex lp solver default option baselin compar result hierarch cluster produc ultrametr contour map ucm [ ] ucm perform agglom cluster superpixel assign lengthweight averag gp b valu distanc pair merg region ucm explicitli design find close ultrametr provid strong baselin hierarch cluster comput close llevel ultrametr correspond ucm cluster result solv minim eq restrict multicut partit level ucm hierarchi converg time figur show averag behavior converg function runtim find upperbound give cost decod integ solut lowerbound estim dual lp close integr gap typic within lowerbound never converg dual achiev quit rapidli instanc requir less iter converg roughli linear growth size lp iter cut plane add fig display histogram comput test imag problem instanc cost ucm solut rel produc close ultrametr um estim method ratio less indic approach gener solut low distort ultrametr problem instanc ucm outperform um algorithm um mc um mc figur propos close ultrametr um enforc consist across level perform independ multicut cluster mc threshold guarante hierarch segment c f first imag column second imag hierarch segment um good preserv semant part two bird correctli merg background region segment qualiti figur show segment benchmark accuraci close ultrametr algorithm denot um along baselin ultrametr contour map algorithm ucm without length weight [ ] term segment accuraci um perform nearli ident state art ucm algorithm small gain highprecis regim worth note bsd benchmark provid strong penalti small leak two segment total number boundari pixel involv small algorithm may find strong applic domain local boundari signal noisier e g biolog imag undersegment heavili penal cuttingplan approach slow agglom cluster necessari wait converg order produc high qualiti result find upper low bound decreas function time cluster perform measur precisionrecal often nearli optim ten second remain stabl figur show plot fmeasur achiev um function time import enforc hierarch constraint although independ find multicut differ threshold often produc hierarch cluster mean guarante run algorithm set el allow layer solv independ fig show exampl hierarch constraint layer improv segment qualiti rel independ cluster threshold conclus introduc new method approxim close ultrametr planar graph applic hierarch imag segment contribut dual cut plane approach exploit introduct novel slack term allow repres much larg space solut rel cut plane yield effici algorithm provid rigor bound qualiti result solut empir observ algorithm rapidli produc compel imag segment along low upperbound nearli tight benchmark bsd test datum set acknowledg jy acknowledg support experian cf acknowledg support nsf grant ii dbi refer [ ] nir ailon mo charikar fit tree metric hierarch cluster phylogeni foundat comput scienc page [ ] bjoern andr joerg h kapp thorsten bei ullrich koth fr hamprecht probabilist imag segment closed constraint proc iccv page [ ] bjoern andr thorben kroger kevin l briggman winfri denk natalya korogod graham knott ullrich koth fred hamprecht global optim closedsurfac segment connectom proc eccv [ ] bjoern andr julian yarkoni b manjunath stephen kirchhoff engin turetken charless fowlk hanspet pfister segment planar superpixel adjac graph w r nonplanar superpixel affin graph proc emmcvpr [ ] pablo arbelaez michael mair charless fowlk jitendra malik contour detect hierarch imag segment ieee tran pattern anal mach intel may [ ] yoram bachrach pushmeet kohli vladimir kolmogorov morteza zadimoghaddam optim coalit structur gener cooper graph game proc aaai [ ] shai bagon meirav galun larg scale correl cluster corr ab [ ] f barahona comput complex is spin glass model journal physic mathemat nuclear gener april [ ] f barahona cut match planar graph mathemat program novemb [ ] f barahona mahjoub cut polytop mathemat program septemb [ ] thorsten bei thorben kroeger jorg h kapp ullrich koth fred hamprecht cut glue cut fast approxim solver multicut partit comput vision pattern recognit cvpr ieee confer page [ ] michel deza moniqu laurent geometri cut metric volum springer scienc busi medium [ ] michael fisher dimer solut planar is model journal mathemat physic [ ] sungwoong kim sebastian nowozin pushmeet kohli chang dong yoo higherord correl cluster imag segment advanc neural inform process system page [ ] vladimir kolmogorov blossom v new implement minimum cost perfect match algorithm mathemat program comput [ ] david martin charless fowlk doron tal jitendra malik databas human segment natur imag applic evalu segment algorithm measur ecolog statist proc iccv page [ ] david martin charless c fowlk jitendra malik learn detect natur imag boundari use local bright color textur cue ieee tran pattern anal mach intel may [ ] julian yarkoni analyz planarcc nip workshop [ ] julian yarkoni thorsten bei pierr baldi fr hamprecht parallel multicut segment via dual decomposit new frontier mine complex pattern [ ] julian yarkoni alexand ihler charless fowlk fast planar correl cluster imag segment proc eccv [ ] chong zhang julian yarkoni fr hamprecht cell detect segment use correl cluster miccai volum page
8,5776,Expressing an Image Stream with a Sequence of Natural Sentences,Poster,5776-expressing-an-image-stream-with-a-sequence-of-natural-sentences.pdf,"We propose an approach for generating a sequence of natural sentences for an image stream. Since general users usually take a series of pictures on their special moments, much online visual information exists in the form of image streams, for which it would better take into consideration of the whole set to generate natural language descriptions. While almost all previous studies have dealt with the relation between a single image and a single natural sentence, our work extends both input and output dimension to a sequence of images and a sequence of sentences. To this end, we design a novel architecture called coherent recurrent convolutional network (CRCN), which consists of convolutional networks, bidirectional recurrent networks, and entity-based local coherence model. Our approach directly learns from vast user-generated resource of blog posts as text-image parallel training data. We demonstrate that our approach outperforms other state-of-the-art candidate methods, using both quantitative measures (e.g. BLEU and top-K recall) and user studies via Amazon Mechanical Turk.","Expressing an Image Stream with a Sequence of
Natural Sentences
Cesc Chunseong Park
Gunhee Kim
Seoul National University, Seoul, Korea
{park.chunseong,gunhee}@snu.ac.kr
https://github.com/cesc-park/CRCN

Abstract
We propose an approach for retrieving a sequence of natural sentences for an
image stream. Since general users often take a series of pictures on their special
moments, it would better take into consideration of the whole image stream to produce natural language descriptions. While almost all previous studies have dealt
with the relation between a single image and a single natural sentence, our work
extends both input and output dimension to a sequence of images and a sequence
of sentences. To this end, we design a multimodal architecture called coherence
recurrent convolutional network (CRCN), which consists of convolutional neural
networks, bidirectional recurrent neural networks, and an entity-based local coherence model. Our approach directly learns from vast user-generated resource of
blog posts as text-image parallel training data. We demonstrate that our approach
outperforms other state-of-the-art candidate methods, using both quantitative measures (e.g. BLEU and top-K recall) and user studies via Amazon Mechanical Turk.

1

Introduction

Recently there has been a hike of interest in automatically generating natural language descriptions
for images in the research of computer vision, natural language processing, and machine learning
(e.g. [5, 8, 9, 12, 14, 15, 26, 21, 30]). While most of existing work aims at discovering the relation
between a single image and a single natural sentence, we extend both input and output dimension to
a sequence of images and a sequence of sentences, which may be an obvious next step toward joint
understanding of the visual content of images and language descriptions, albeit under-addressed in
current literature. Our problem setup is motivated by that general users often take a series of pictures
on their memorable moments. For example, many people who visit New York City (NYC) would
capture their experiences with large image streams, and thus it would better take the whole photo
stream into consideration for the translation to a natural language description.

Figure 1: An intuition of our problem statement with a New York City example. We aim at expressing an image
stream with a sequence of natural sentences. (a) We leverage natural blog posts to learn the relation between
image streams and sentence sequences. (b) We propose coherence recurrent convolutional networks (CRCN)
that integrate convolutional networks, bidirectional recurrent networks, and the entity-based coherence model.

1

Fig.1 illustrates an intuition of our problem statement with an example of visiting NYC. Our objective
is, given a photo stream, to automatically produce a sequence of natural language sentences that
best describe the essence of the input image set. We propose a novel multimodal architecture named
coherence recurrent convolutional networks (CRCN) that integrate convolutional neural networks
for image description [13], bidirectional recurrent neural networks for the language model [20], and
the local coherence model [1] for a smooth flow of multiple sentences. Since our problem deals with
learning the semantic relations between long streams of images and text, it is more challenging to
obtain appropriate text-image parallel corpus than previous research of single sentence generation.
Our idea to this issue is to directly leverage online natural blog posts as text-image parallel training
data, because usually a blog consists of a sequence of informative text and multiple representative
images that are carefully selected by authors in a way of storytelling. See an example in Fig.1.(a).
We evaluate our approach with the blog datasets of the NYC and Disneyland, consisting of more than
20K blog posts with 140K associated images. Although we focus on the tourism topics in our experiments, our approach is completely unsupervised and thus applicable to any domain that has a large
set of blog posts with images. We demonstrate the superior performance of our approach by comparing with other state-of-the-art alternatives, including [9, 12, 21]. We evaluate with quantitative
measures (e.g. BLEU and Top-K recall) and user studies via Amazon Mechanical Turk (AMT).
Related work. Due to a recent surge of volume of literature on this subject of generating natural language descriptions for image data, here we discuss a representative selection of ideas that are closely
related to our work. One of the most popular approaches is to pose the text generation as a retrieval
problem that learns ranking and embedding, in which the caption of a test image is transferred from
the sentences of its most similar training images [6, 8, 21, 26]. Our approach partly involves the
text retrieval, because we search for candidate sentences for each image of a query sequence from
training database. However, we then create a final paragraph by considering both compatibilities
between individual images and text, and the coherence that captures text relatedness at the level of
sentence-to-sentence transitions. There have been also video-sentence works (e.g. [23, 32]); our key
novelty is that we explicitly include the coherence model. Unlike videos, consecutive images in the
streams may show sharp changes of visual content, which cause the abrupt discontinuity between
consecutive sentences. Thus the coherence model is more demanded to make output passages fluent.
Many recent works have exploited multimodal networks that combine deep convolutional neural networks (CNN) [13] and recurrent neural network (RNN) [20]. Notable architectures in this category
integrate the CNN with bidirectional RNNs [9], long-term recurrent convolutional nets [5], longshort term memory nets [30], deep Boltzmann machines [27], dependency-tree RNN [26], and other
variants of multimodal RNNs [3, 19]. Although our method partly take advantage of such recent
progress of multimodal neural networks, our major novelty is that we integrate it with the coherence
model as a unified end-to-end architecture to retrieve fluent sequential multiple sentences.
In the following, we compare more previous work that bears a particular resemblance to ours.
Among multimodal neural network models, the long-term recurrent convolutional net [5] is related
to our objective because their framework explicitly models the relations between sequential inputs
and outputs. However, the model is applied to a video description task of creating a sentence for a
given short video clip and does not address the generation of multiple sequential sentences. Hence,
unlike ours, there is no mechanism for the coherence between sentences. The work of [11] addresses
the retrieval of image sequences for a query paragraph, which is the opposite direction of our problem. They propose a latent structural SVM framework to learn the semantic relevance relations from
text to image sequences. However, their model is specialized only for the image sequence retrieval,
and thus not applicable to the natural sentence generation.
Contributions. We highlight main contributions of this paper as follows. (1) To the best of our
knowledge, this work is the first to address the problem of expressing image streams with sentence
sequences. We extend both input and output to more elaborate forms with respect to a whole body of
existing methods: image streams instead of individual images and sentence sequences instead of individual sentences. (2) We develop a multimodal architecture of coherence recurrent convolutional
networks (CRCN), which integrates convolutional networks for image representation, recurrent networks for sentence modeling, and the local coherence model for fluent transitions of sentences. (3)
We evaluate our method with large datasets of unstructured blog posts, consisting of 20K blog posts
with 140K associated images. With both quantitative evaluation and user studies, we show that our
approach is more successful than other state-of-the-art alternatives in verbalizing an image stream.

2

2

Text-Image Parallel Dataset from Blog Posts

We discuss how to transform blog posts to a training set B of image-text parallel data streams, each
l
l
of which is a sequence of image-sentence pairs: B l = {(I1l , T1l ),· · ·, (IN
l , TN l )} ∈ B. The training
set size is denoted by L = |B|. Fig.2.(a) shows the summary of pre-processing steps for blog posts.
2.1

Blog Pre-processing

We assume that blog authors augment their text with multiple images in a semantically meaningful
manner. In order to decompose each blog into a sequence of images and associated text, we first
perform text segmentation and then text summarization. The purpose of text segmentation is to
divide the input blog text into a set of text segments, each of which is associated with a single
image. Thus, the number of segments is identical to the number of images in the blog. The objective
of text summarization is to reduce each text segment into a single key sentence. As a result of these
l
l
two processes, we can transform each blog into a form of B l = {(I1l , T1l ), · · · , (IN
l , TN l )}.
Text segmentation. We first divide the blog passage into text blocks according to paragraphs. We
apply a standard paragraph tokenizer of NLTK [2] that uses rule-based regular expressions to detect
paragraph divisions. We then use the heuristics based on the image-to-text block distances proposed
in [10]. Simply, we assign each text block to the image that has the minimum index distance where
each text block and image is counted as a single index distance in the blog.
Text summarization. We summarize each text segment into a single key sentence. We apply the
Latent Semantic Analysis (LSA)-based summarization method [4], which uses the singular value
decomposition to obtain the concept dimension of sentences, and then recursively finds the most
representative sentences that maximize the inter-sentence similarity for each topic in a text segment.
Data augmentation. The data augmentation is a well-known technique for convolutional neural
networks to improve image classification accuracies [13]. Its basic idea is to artificially increase
the number of training examples by applying transformations, horizontal reflection or adding noise
to training images. We empirically observe that this idea leads better performance in our problem
l
l
as well. For each image-sentence sequence B l = {(I1l , T1l ), · · · , (IN
l , TN l )}, we augment each
l
sentence Tn with multiple sentences for training. That is, when we perform the LSA-based text
summarization, we select top-κ highest ranked summary sentences, among which the top-ranked
one becomes the summary sentence for the associated image, and all the top-κ ones are used for
training in our model. With a slight abuse of notation, we let Tnl to denote both the single summary
sentence and κ augmented sentences. We choose κ = 3 after thorough empirical tests.
2.2

Text Description

Once we represent each text segment with κ sentences, we extract the paragraph vector [17] to represent the content of text. The paragraph vector is a neural-network based unsupervised algorithm
that learns fixed-length feature representation from variable-length pieces of passage. We learn 300dimensional dense vector representation separately from the two classes of the blog dataset using
the gensim doc2vec code. We use pn to denote the paragraph vector representation for text Tn .
We then extract a parsed tree for each Tn to identify coreferent entities and grammatical roles of the
words. We use the Stanford core NLP library [18]. The parse trees are used for the local coherence
model, which will be discussed in section 3.2.

3

Our Architecture

Many existing sentence generation models (e.g. [9, 19]) combine words or phrases from training
data to generate a sentence for a novel image. Our approach is one level higher; we use sentences
from training database to author a sequence of sentences for a novel image stream. Although our
model can be easily extended to use words or phrases as basic building blocks, such granularity
makes sequences too long to train the language model, which may cause several difficulties for
learning the RNN models. For example, the vanishing gradient effect is a well-known hardship to
backpropagate an error signal through a long-range temporal interval. Therefore, we design our
approach that retrieves individual candidate sentences for each query image from training database
and crafts a best sentence sequence, considering both the fitness of individual image-to-sentence
pairs and coherence between consecutive sentences.
3

Figure 2: Illustration of (a) pre-processing steps of blog posts, and (b) the proposed CRCN architecture.
Fig.2.(b) illustrates the structure of our CRCN. It consists of three main components, which are
convolutional neural networks (CNN) [13] for image representation, bidirectional recurrent neural
networks (BRNN) [24] for sentence sequence modeling, and the local coherence model [1] for a
smooth flow of multiple sentences. Each data stream is a variable-length sequence denoted by
{(I1 , T1 ), · · · , (IN , TN )}. We use t ∈ {1, · · · , N } to denote a position of a sentence/image in a
sequence. We define the CNN and BRNN model for each position separately, and the coherence
model for a whole data stream. For the CNN component, our choice is the VGGNet [25] that
represents images as 4,096-dimensional vectors. We discuss the details of our BRNN and coherence
model in section 3.1 and section 3.2 respectively, and finally present how to combine the output of
the three components to create a single compatibility score in section 3.3.
3.1

The BRNN Model

The role of BRNN model is to represent a content flow of text sequences. In our problem, the BRNN
is more suitable than the normal RNN, because the BRNN can simultaneously model forward and
backward streams, which allow us to consider both previous and next sentences for each sentence to
make the content of a whole sequence interact with one another. As shown in Fig.2.(b), our BRNN
has five layers: input layer, forward/backward layer, output layer, and ReLU activation layer, which
are finally merged with that of the coherence model into two fully connected layers. Note that each
text is represented by 300-dimensional paragraph vector pt as discussed in section 2.2. The exact
form of our BRNN is as follows. See Fig.2.(b) together for better understanding.
xft = f (Wif pt + bfi );
hft

=

f (xft

+

Wf hft−1

xbt = f (Wib pt + bbi );
+ bf ); hbt = f (xbt + Wb hbt+1 + bb ); ot =

(1)
Wo (hft

+ hbt ) + bo .

The BRNN takes a sequence of text vectors pt as input. We then compute xft and xbt , which are the
activations of input units to forward and backward units. Unlike other BRNN models, we separate
the input activation into forward and backward ones with different sets of parameters Wif and Wib ,
which empirically leads a better performance. We set the activation function f to the Rectified
Linear Unit (ReLU), f (x) = max(0, x). Then, we create two independent forward and backward
hidden units, denoted by hft and hbt . The final activation of the BRNN ot can be regarded as a
description for the content of the sentence at location t, which also implicitly encodes the flow of
the sentence and its surrounding context in the sequence. The parameter sets to learn include weights
{Wif , Wib , Wf , Wb , Wo } ∈ R300×300 and biases {bfi , bbi , bf , bb , bo } ∈ R300×1 .
3.2

The Local Coherence Model

The BRNN model can capture the flow of text content, but it lacks learning the coherence of passage
that reflects distributional, syntactic, and referential information between discourse entities. Thus,
we explicitly include a local coherence model based on the work of [1], which focuses on resolving
the patterns of local transitions of discourse entities (i.e. coreferent noun phrases) in the whole
text. As shown in Fig.2.(b), we first extract parse trees for every summarized text denoted by Zt
and then concatenate all sequenced parse trees into one large one, from which we make an entity
grid for the whole sequence. The entity grid is a table where each row corresponds to a discourse
4

entity and each column represents a sentence. Grammatical role are expressed by three categories
and one for absent (i.e. not referenced in the sentence): S (subjects), O (objects), X (other than
subject or object) and −(absent). After making the entity grid, we enumerate the transitions of the
grammatical roles of entities in the whole text. We set the history parameter to three, which means
we can obtain 43 = 64 transition descriptions (e.g. SO− or OOX). By computing the ratio of
the occurrence frequency of each transition, we finally create a 64-dimensional representation that
captures the coherence of a sequence. Finally, we make this descriptor to a 300-dimensional vector
by zero-padding, and forward it to ReLU layer as done for the BRNN output.
3.3

Combination of CNN, RNN, and Coherence Model

After the ReLU activation layers of the RNN and the coherence model, their output (i.e. {ot }N
t=1 and
q) goes through two fully connected (FC) layers, whose role is to decide a proper combination of the
BRNN language factors and the coherence factors. We drop the bias terms for the fully-connected
layers, and the dimensions of variables are Wf 1 ∈ R512×300 , Wf 2 ∈ R4,096×512 , ot , q ∈ R300×1 ,
st , g ∈ R4,096×1 , O ∈ R300×N , and S ∈ R4,096×N .
O = [o1 |o2 |..|oN ];

S = [s1 |s2 |..|sN ];

Wf 2 Wf 1 [O|q] = [S|g].

(2)

We use the shared parameters for O and q so that the output mixes well the interaction between the
content flows and coherency. In our tests, joint learning outperforms learning the two terms with
separate parameters. Note that the multiplication Wf 2 Wf 1 of the last two FC layers does not reduce
to a single linear mapping, thanks to dropout. We assign 0.5 and 0.7 dropout rates to the two layers.
Empirically, it improves generalization performance much over a single FC layer with dropout.
3.4

Training the CRCN

To train our CRCN model, we first define the compatibility score between an image stream and a
paragraph sequence. While our score function is inspired by Karpathy et al. [9], there are two major
differences. First, the score function of [9] deals between sentence fragments and image fragments,
and thus the algorithm considers all combinations between them to find out the best matching. On
the other hand, we define the score by an ordered and paired compatibility between a sentence
sequence and an image sequence. Second, we also add the term that measures the relevance relation
of coherency between an image sequence and a text sequence. Finally, the score Skl for a sentence
sequence k and an image stream l is defined by
Skl =

X

skt · vtl + g k · vtl

(3)

t=1...N

where vtl denotes the CNN feature vector for t-th image of stream l. We then define the cost function
to train our CRCN model as follows [9].
C(θ) =

XhX
k

max(0, 1 + Skl − Skk ) +

l

X

i
max(0, 1 + Slk − Skk ) ,

(4)

l

where Skk denotes the score between a training pair of corresponding image and sentence sequence.
The objective, based on the max-margin structured loss, encourages aligned image-sentence sequence pairs to have a higher score by a margin than misaligned pairs. For each positive training
example, we randomly sample 100 ne examples from the training set. Since each contrastive example has a random length, and is sampled from the dataset of a wide range of content, it is extremely
unlikely that the negative examples have the same length and the same content order of sentences
with positive examples.
Optimization. We use the backpropagation through time (BPTT) algorithm [31] to train our model.
We apply the stochastic gradient descent (SGD) with mini-batches of 100 data streams. Among
many SGD techniques, we select RMSprop optimizer [28], which leads the best performance in
our experiments. We initialize the weights of our CRCN model using the method of He et al. [7],
which is robust in deep rectified models. We observe that it is better than a simple Gaussian random
initialization, although our model is not extremely deep. We use dropout regularization in all layers
except the BRNN, with 0.7 dropout for the last FC layer and 0.5 for the other remaining layers.
5

3.5

Retrieval of Sentence Sequences

At test time, the objective is to retrieve a best sentence sequence for a given query image stream
{Iq1 , · · · , IqN }. First, we select K-nearest images for each query image from training database using the `2 -distance on the CNN VGGNet fc7 features [25]. In our experiments K = 5 is successful.
We then generate a set of sentence sequence candidates C by concatenating the sentences associated
with the K-nearest images at each location t. Finally, we use our learned CRCN model to compute
the compatibility score between the query image stream and each sequence candidate, according to
which we rank the candidates.
However, one major difficulty of this scenario is that there are exponentially many candidates (i.e.
|C| = K N ). To resolve this issue, we use an approximate divide-and-conquer strategy; we recursively halve the problem into subproblems, until the size of the subproblem is manageable. For
example, if we halve the search candidate length Q times, then the search space of each subproblem
Q
becomes K N/2 . Using the beam search idea, we first find the top-M best sequence candidates in
the subproblem of the lowest level, and recursively increase the candidate lengths while the maximum candidate size is limited to M . We set M = 50. Though it is an approximate search, our
experiments assure that it achieves almost optimal solutions with plausible combinatorial search,
mainly because the local fluency and coherence is undoubtedly necessary for the global one. That
is, in order for a whole sentence sequence to be fluent and coherent, its any subparts must be as well.

4

Experiments

We compare the performance of our approach with other state-of-the-art candidate methods via
quantitative measures and user studies using Amazon Mechanical Turk (AMT). Please refer to the
supplementary material for more results and the details of implementation and experimental setting.
4.1

Experimental Setting

Dataset. We collect blog datasets of the two topics: NYC and Disneyland. We reuse the blog data
of Disneyland from the dataset of [11], and newly collect the data of NYC, using the same crawling
method with [11], in which we first crawl blog posts and their associated pictures from two popular
blog publishing sites, BLOGSPOT and WORDPRESS by changing query terms from Google search.
Then, we manually select the travelogue posts that describe stories and events with multiple images.
Finally, the dataset includes 11,861 unique blog posts and 78,467 images for NYC and 7,717 blog
posts and 60,545 images for Disneyland.
Task. For quantitative evaluation, we randomly split our dataset into 80% as a training set, 10% as
a validation, and the others as a test set. For each test post, we use the image sequence as a query
Iq and the sequence of summarized sentences as groundtruth TG . Each algorithm retrieves the best
sequences from training database for a query image sequence, and ideally the retrieved sequences
match well with TG . Since the training and test data are disjoint, each algorithm can only retrieve
similar (but not identical) sentences at best.
For quantitative measures, we exploit two types of metrics of language similarity (i.e. BLEU [22],
CIDEr [29], and METEOR [16] scores) and retrieval accuracies (i.e. top-K recall and median rank),
which are popularly used in text generation literature [8, 9, 19, 26]. The top-K recall R@K is
the recall rate of a groundtruth retrieval given top K candidates, and the median rank indicates the
median ranking value of the first retrieved groundtruth. A better performance is indicated by higher
BLEU, CIDEr, METEOR, R@K scores, and lower median rank values.
Baselines. Since the sentence sequence generation from image streams has not been addressed yet
in previous research, we instead extend several state-of-the-art single-sentence models that have
publicly available codes as baselines, including the log-bilinear multimodal models by Kiros et
al. [12], and recurrent convolutional models by Karpathy et al. [9] and Vinyals et al. [30]. For
[12], we use the three variants introduced in the paper, which are the standard log-bilinear model
(LBL), and two multi-modal extensions: modality-based LBL (MLBL-B) and factored three-way
LBL (MLBL-F). We use the NeuralTalk package authored by Karpathy et al. for the baseline
of [9] denoted by (CNN+RNN), and [30] denoted by (CNN+LSTM). As the simplest baseline, we
also compare with the global matching (GloMatch) in [21]. For all the baselines, we create final
sentence sequences by concatenating the sentences generated for each image in the query stream.
6

B-1

B-2

(CNN+LSTM) [30]
(CNN+RNN) [9]
(MLBL-F) [12]
(MLBL-B) [12]
(LBL) [12]
(GloMatch) [21]
(1NN)
(RCN)
(CRCN)

21.31
6.21
21.03
20.43
20.96
19.00
25.97
27.09
26.83

3.65
0.01
1.92
1.54
1.68
1.59
3.42
5.45
5.37

(CNN+LSTM) [30]
(CNN+RNN) [9]
(MLBL-F) [12]
(MLBL-B) [12]
(LBL) [12]
(GloMatch) [21]
(1NN)
(RCN)
(CRCN)

27.99
6.04
15.75
15.65
18.94
11.94
25.92
28.15
28.40

3.55
0.00
1.61
1.32
1.70
0.37
3.34
6.84
6.88

Language metrics
Retrieval metrics
B-3 B-4 CIDEr METEOR R@1 R@5 R@10 MedRank
New York City
0.57 0.14
9.1
5.73
0.95 5.24
8.57
84.5
0.00 0.00
0.5
1.34
0.48 2.86
4.29
120.5
0.12 0.01
4.3
6.03
0.71 4.52
7.86
87.0
0.09 0.01
2.6
5.30
0.48 3.57
5.48
101.5
0.08 0.01
2.6
5.29
1.19 4.52
7.38
100.5
0.04 0.0
2.80
5.17
0.24 2.62
4.05
95.00
0.60 0.22 15.9
7.06
5.95 13.57 20.71
63.50
2.56 2.10 33.5
7.87
3.80 18.33 30.24
29.00
2.57 2.08 30.9
7.69
11.67 31.19 43.57
14.00
Disneyland
0.38 0.08 10.0
4.51
3.06 8.16 14.29
65.0
0.00 0.00
0.4
1.34
1.02 3.40
5.78
88.0
0.07 0.01
4.9
7.12
0.68 4.08 10.54
63.0
0.05 0.00
3.8
5.83
0.34 2.72
6.80
69.0
0.06 0.01
3.4
4.99
1.02 4.08
7.82
62.0
0.01 0.00
2.2
4.31
2.04 5.78
7.48
73.0
0.71 0.38 19.5
7.46
9.18 19.05 27.21
45.0
4.11 3.52 51.3
8.87
5.10 20.07 28.57
29.5
4.11 3.49 52.7
8.78
14.29 31.29 43.20
16.0

Table 1: Evaluation of sentence generation for the two datasets, New York City and Disneyland, with language
similarity metrics (BLEU) and retrieval metrics (R@K, median Rank). A better performance is indicated by
higher BLEU, CIDEr, METEOR, R@K scores, and lower median rank values.

We also compare between different variants of our method to validate the contributions of key components of our method. We test the K-nearest search (1NN) without the RNN part as the simplest
variant; for each image in a test query, we find its K(= 1) most similar training images and simply
concatenate their associated sentences. The second variant is the BRNN-only method denoted by
(RCN) that excludes the entity-based coherence model from our approach. Our complete method is
denoted by (CRCN), and this comparison quantifies the improvement by the coherence model. To be
fair, we use the same VGGNet fc7 feature [25] for all the algorithms.
4.2

Quantitative Results

Table 1 shows the quantitative results of experiments using both language and retrieval metrics.
Our approach (CRCN) and (RCN) outperform, with large margins, other state-of-the-art baselines,
which generate passages without consideration of sentence-to-sentence transitions unlike ours. The
(MLBL-F) shows the best performance among the three models of [12] albeit with a small margin,
partly because they share the same word dictionary in training. Among mRNN-based models, the
(CNN+LSTM) significantly outperforms the (CNN+RNN), because the LSTM units help learn models
from irregular and lengthy data of natural blogs more robustly.
We also observe that (CRCN) outperforms (1NN) and (RCN), especially with the retrieval metrics.
It shows that the integration of two key components, the BRNN and the coherence model, indeed
contributes the performance improvement. The (CRCN) is only slightly better than the (RCN) in language metrics but significantly better in retrieval metrics. It means that (RCN) is fine with retrieving
fairly good solutions, but not good at ranking the only correct solution high compared to (CRCN).
The small margins in language metrics are also attributed by their inherent limitation; for example,
the BLEU focuses on counting the matches of n-gram words and thus is not good at comparing
between sentences, even worse between paragraphs for fully evaluating their fluency and coherency.
Fig.3 illustrates several examples of sentence sequence retrieval. In each set, we show a query
image stream and text results created by our method and baselines. Except Fig.3.(d), we show parts
of sequences because they are rather long for illustration. These qualitative examples demonstrate
that our approach is more successful to verbalize image sequences that include a variety of content.
4.3

User Studies via Amazon Mechanical Turk

We perform user studies using AMT to observe general users’ preferences between text sequences
by different algorithms. Since our evaluation involves multiple images and long passages of text, we
design our AMT task to be sufficiently simple for general turkers with no background knowledge.
7

Figure 3: Examples of sentence sequence retrieval for NYC (top) and Disneyland (bottom). In each set, we
present a part of a query image stream, and its corresponding text output by our method and a baseline.
Baselines
(GloMatch)
(CNN+LSTM)
(MLBL-B)
(RCN)
(RCN N>=8)
NYC
92.7% (139/150) 80.0% (120/150) 69.3% (104/150) 54.0% (81/150) 57.0% (131/230)
Disneyland 95.3% (143/150) 82.0% (123/150) 70.7% (106/150) 56.0% (84/150) 60.1% (143/238)

Table 2: The results of AMT pairwise preference tests. We present the percentages of responses that turkers
vote for our (CRCN) over baselines. The length of query streams is 5 except the last column, which has 8–10.

We first randomly sample 100 test streams from the two datasets. We first set the maximum number
of images per query to 5. If a query is longer than that, we uniformly sample it to 5. In an AMT
test, we show a query image stream Iq , and a pair of passages generated by our method (CRCN) and
one baseline in a random order. We ask turkers to choose more agreed text sequence with Iq . We
design the test as a pairwise comparison instead of a multiple-choice question to make answering
and analysis easier. The questions look very similar to the examples of Fig.3. We obtain answers
from three different turkers for each query. We compare with four baselines; we choose (MLBL-B)
among the three variants of [12], and (CNN+LSTM) among mRNN-based methods. We also select
(GloMatch), and (RCN) as the variants of our method.
Table 2 shows the results of AMT tests, which validate that AMT annotators prefer our results to
those of baselines. The (GloMatch) is the worst because it uses too weak image representation
(i.e. GIST and Tiny images). The differences between (CRCN) and (RCN) (i.e. 4th column of Table
2) are not as significant as previous quantitative measures, mainly because our query image stream
is sampled to relatively short 5. The coherence becomes more critical as the passage is longer. To
justify this argument, we run another set of AMT tests in which we use 8–10 images per query. As
shown in the last column of Table 2, the performance margins between (CRCN) and (RCN) become
larger as the lengths of query image streams increase. This result assures that as passages are longer,
the coherence becomes more important, and thus (CRCN)’s output is more preferred by turkers.

5

Conclusion

We proposed an approach for retrieving sentence sequences for an image stream. We developed coherence recurrent convolutional network (CRCN), which consists of convolutional networks, bidirectional recurrent networks, and entity-based local coherence model. With quantitative evaluation
and users studies using AMT on large collections of blog posts, we demonstrated that our CRCN
approach outperformed other state-of-the-art candidate methods.
Acknowledgements. This research is partially supported by Hancom and Basic Science Research
Program through National Research Foundation of Korea (2015R1C1A1A02036562).
8

References
[1] R. Barzilay and M. Lapata. Modeling Local Coherence: An Entity-Based Approach. In ACL, 2008.
[2] S. Bird, E. Loper, and E. Klein. Natural Language Processing with Python. O’Reilly Media Inc., 2009.
[3] X. Chen and C. L. Zitnick. Mind’s Eye: A Recurrent Visual Representation for Image Caption Generation.
In CVPR, 2015.
[4] F. Y. Y. Choi, P. Wiemer-Hastings, and J. Moore. Latent Semantic Analysis for Text Segmentation. In
EMNLP, 2001.
[5] J. Donahue, L. A. Hendricks, S. Guadarrama, M. Rohrbach, S. Venugopalan, K. Saenko, and T. Darrell.
Long-term Recurrent Convolutional Networks for Visual Recognition and Description. In CVPR, 2015.
[6] Y. Gong, L. Wang, M. Hodosh, J. Hockenmaier, and S. Lazebnik. Improving Image-Sentence Embeddings
Using Large Weakly Annotated Photo Collections. In ECCV, 2014.
[7] K. He, X. Zhang, S. Ren, and J. Sun. Delving Deep into Rectifiers: Surpassing Human-Level Performance
on ImageNet Classification. In arXiv, 2015.
[8] M. Hodosh, P. Young, and J. Hockenmaier. Framing Image Description as a Ranking Task: Data, Models
and Evaluation Metrics. JAIR, 47:853–899, 2013.
[9] A. Karpathy and L. Fei-Fei. Deep Visual-Semantic Alignments for Generating Image Descriptions. In
CVPR, 2015.
[10] G. Kim, S. Moon, and L. Sigal. Joint Photo Stream and Blog Post Summarization and Exploration. In
CVPR, 2015.
[11] G. Kim, S. Moon, and L. Sigal. Ranking and Retrieval of Image Sequences from Multiple Paragraph
Queries. In CVPR, 2015.
[12] R. Kiros, R. Salakhutdinov, and R. Zemel. Multimodal Neural Language Models. In ICML, 2014.
[13] A. Krizhevsky, I. Sutskever, and G. E. Hinton. Imagenet Classification with Deep Convolutional Neural
Networks. In NIPS, 2012.
[14] G. Kulkarni, V. Premraj, S. Dhar, S. Li, Y. Choi, A. C. Berg, and T. L. Berg. Baby Talk: Understanding
and Generating Image Descriptions. In CVPR, 2011.
[15] P. Kuznetsova, V. Ordonez, T. L. Berg, and Y. Choi. TreeTalk: Composition and Compression of Trees
for Image Descriptions. In TACL, 2014.
[16] S. B. A. Lavie. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with
Human Judgments. In ACL, 2005.
[17] Q. Le and T. Mikolov. Distributed Representations of Sentences and Documents. In ICML, 2014.
[18] C. D. Manning, M. Surdeanu, J. Bauer, J. Finkel, S. J. Bethard, and D. McClosky. The Stanford CoreNLP
Natural Language Processing Toolkit. In ACL, 2014.
[19] J. Mao, W. Xu, Y. Yang, J. Wang, Z. Huang, and A. L. Yuille. Deep Captioning with Multimodal Recurrent
Neural Networks (m-RNN). In ICLR, 2015.
[20] T. Mikolov. Statistical Language Models based on Neural Networks. In Ph. D. Thesis, Brno University
of Technology, 2012.
[21] V. Ordonez, G. Kulkarni, and T. L. Berg. Im2Text: Describing Images Using 1 Million Captioned Photographs. In NIPS, 2011.
[22] K. Papineni, S. Roukos, T. Ward, and W.-J. Zhu. BLEU: A Method for Automatic Evaluation of Machine
Translation. In ACL, 2002.
[23] M. Rohrbach, W. Qiu, I. Titov, S. Thater, M. Pinkal, and B. Schiele. Translating Video Content to Natural
Language Descriptions. In ICCV, 2013.
[24] M. Schuster and K. K. Paliwal. Bidirectional Recurrent Neural Networks. In IEEE TSP, 1997.
[25] K. Simonyan and A. Zisserman. Very Deep Convolutional Networks for Large-Scale Image Recognition.
In ICLR, 2015.
[26] R. Socher, A. Karpathy, Q. V. Le, C. D. Manning, and A. Y. Ng. Grounded Compositional Semantics for
Finding and Describing Images with Sentences. In TACL, 2013.
[27] N. Srivastava and R. Salakhutdinov. Multimodal Learning with Deep Boltzmann Machines. In NIPS,
2012.
[28] T. Tieleman and G. E. Hinton. Lecture 6.5 – RMSProp. In Coursera, 2012.
[29] R. Vedantam, C. L. Zitnick, and D. Parikh. CIDEr: Consensus-based Image Description Evaluation. In
arXiv:1411.5726, 2014.
[30] O. Vinyals, A. Toshev, S. Bengio, and D. Erhan. Show and Tell: A Neural Image Caption Generator. In
CVPR, 2015.
[31] P. J. Werbos. Generalization of Backpropagation with Application to a Recurrent Gas Market Model.
Neural Networks, 1:339–356, 1988.
[32] R. Xu, C. Xiong, W. Chen, and J. J. Corso. Jointly Modeling Deep Video and Compositional Text to
Bridge Vision and Language in a Unified Framework. In AAAI, 2015.

9

",propos approach gener sequenc natur sentenc imag stream sinc gener user usual take seri pictur special moment much onlin visual inform exist form imag stream would better take consider whole set gener natur languag descript almost previou studi deal relat singl imag singl natur sentenc work extend input output dimens sequenc imag sequenc sentenc end design novel architectur call coher recurr convolut network crcn consist convolut network bidirect recurr network entityba local coher model approach directli learn vast usergener resourc blog post textimag parallel train datum demonstr approach outperform stateoftheart candid method use quantit measur e g bleu topk recal user studi via amazon mechan turk,express imag stream sequenc natur sentenc cesc chunseong park gunhe kim seoul nation univers seoul korea park chunseonggunhe snu ac kr httpsgithub comcescparkcrcn abstract propos approach retriev sequenc natur sentenc imag stream sinc gener user often take seri pictur special moment would better take consider whole imag stream produc natur languag descript almost previou studi deal relat singl imag singl natur sentenc work extend input output dimens sequenc imag sequenc sentenc end design multimod architectur call coher recurr convolut network crcn consist convolut neural network bidirect recurr neural network entityba local coher model approach directli learn vast usergener resourc blog post textimag parallel train datum demonstr approach outperform stateoftheart candid method use quantit measur e g bleu topk recal user studi via amazon mechan turk introduct recent hike interest automat gener natur languag descript imag research comput vision natur languag process machin learn e g [ ] exist work aim discov relat singl imag singl natur sentenc extend input output dimens sequenc imag sequenc sentenc may obviou next step toward joint understand visual content imag languag descript albeit underaddress current literatur problem setup motiv gener user often take seri pictur memor moment exampl mani peopl visit new york citi nyc would captur experi larg imag stream thu would better take whole photo stream consider translat natur languag descript figur intuit problem statement new york citi exampl aim express imag stream sequenc natur sentenc leverag natur blog post learn relat imag stream sentenc sequenc b propos coher recurr convolut network crcn integr convolut network bidirect recurr network entityba coher model fig illustr intuit problem statement exampl visit nyc object give photo stream automat produc sequenc natur languag sentenc best describ essenc input imag set propos novel multimod architectur name coher recurr convolut network crcn integr convolut neural network imag descript [ ] bidirect recurr neural network languag model [ ] local coher model [ ] smooth flow multipl sentenc sinc problem deal learn semant relat long stream imag text challeng obtain appropri textimag parallel corpu previou research singl sentenc gener idea issu directli leverag onlin natur blog post textimag parallel train datum usual blog consist sequenc inform text multipl repres imag care select author way storytel see exampl fig evalu approach blog dataset nyc disneyland consist k blog post k associ imag although focu tourism topic experi approach complet unsupervis thu applic domain larg set blog post imag demonstr superior perform approach compar stateoftheart altern includ [ ] evalu quantit measur e g bleu topk recal user studi via amazon mechan turk amt relat work due recent surg volum literatur subject gener natur languag descript imag datum discuss repres select idea close relat work one popular approach pose text gener retriev problem learn rank emb caption test imag transfer sentenc similar train imag [ ] approach partli involv text retriev search candid sentenc imag queri sequenc train databas howev creat final paragraph consid compat individu imag text coher captur text related level sentencetosent transit also videosent work e g [ ] key novelti explicitli includ coher model unlik video consecut imag stream may show sharp chang visual content becaus abrupt discontinu consecut sentenc thu coher model demand make output passag fluent mani recent work exploit multimod network combin deep convolut neural network cnn [ ] recurr neural network rnn [ ] notabl architectur categori integr cnn bidirect rnn [ ] longterm recurr convolut net [ ] longshort term memori net [ ] deep boltzmann machin [ ] dependencytre rnn [ ] variant multimod rnn [ ] although method partli take advantag recent progress multimod neural network major novelti integr coher model unifi endtoend architectur retriev fluent sequenti multipl sentenc follow compar previou work bear particular resembl among multimod neural network model longterm recurr convolut net [ ] relat object framework explicitli model relat sequenti input output howev model appli video descript task creat sentenc give short video clip address gener multipl sequenti sentenc henc unlik mechan coher sentenc work [ ] address retriev imag sequenc queri paragraph opposit direct problem propos latent structur svm framework learn semant relev relat text imag sequenc howev model special imag sequenc retriev thu applic natur sentenc gener contribut highlight main contribut paper follow good knowledg work first address problem express imag stream sentenc sequenc extend input output elabor form respect whole bodi exist method imag stream instead individu imag sentenc sequenc instead individu sentenc develop multimod architectur coher recurr convolut network crcn integr convolut network imag represent recurr network sentenc model local coher model fluent transit sentenc evalu method larg dataset unstructur blog post consist k blog post k associ imag quantit evalu user studi show approach success stateoftheart altern verbal imag stream textimag parallel dataset blog post discuss transform blog post train set b imagetext parallel datum stream l l sequenc imagesent pair b l il tl l tn l b train set size denot l b fig show summari preprocess step blog post blog preprocess assum blog author augment text multipl imag semant meaning manner order decompos blog sequenc imag associ text first perform text segment text summar purpos text segment divid input blog text set text segment associ singl imag thu number segment ident number imag blog object text summar reduc text segment singl key sentenc result l l two process transform blog form b l il tl l tn l text segment first divid blog passag text block accord paragraph appli standard paragraph token nltk [ ] use ruleba regular express detect paragraph divis use heurist base imagetotext block distanc propos [ ] simpli assign text block imag minimum index distanc text block imag count singl index distanc blog text summar summar text segment singl key sentenc appli latent semant analysi lsa base summar method [ ] use singular valu decomposit obtain concept dimens sentenc recurs find repres sentenc maxim intersent similar topic text segment datum augment data augment wellknown techniqu convolut neural network improv imag classif accuraci [ ] basic idea artifici increas number train exampl appli transform horizont reflect add nois train imag empir observ idea lead good perform problem l l well imagesent sequenc b l il tl l tn l augment l sentenc tn multipl sentenc train perform lsaba text summar select top high rank summari sentenc among toprank one becom summari sentenc associ imag top one use train model slight abus notat let tnl denot singl summari sentenc augment sentenc choos thorough empir test text descript repres text segment sentenc extract paragraph vector [ ] repres content text paragraph vector neuralnetwork base unsupervis algorithm learn fixedlength featur represent variablelength piec passag learn dimension dens vector represent separ two class blog dataset use gensim docvec code use pn denot paragraph vector represent text tn extract pars tree tn identifi corefer entiti grammat role word use stanford core nlp librari [ ] pars tree use local coher model discuss section architectur mani exist sentenc gener model e g [ ] combin word phrase train datum gener sentenc novel imag approach one level high use sentenc train databas author sequenc sentenc novel imag stream although model easili extend use word phrase basic build block granular make sequenc long train languag model may becaus sever difficulti learn rnn model exampl vanish gradient effect wellknown hardship backpropag error signal longrang tempor interv therefor design approach retriev individu candid sentenc queri imag train databas craft good sentenc sequenc consid fit individu imagetosent pair coher consecut sentenc figur illustr preprocess step blog post b propos crcn architectur fig b illustr structur crcn consist three main compon convolut neural network cnn [ ] imag represent bidirect recurr neural network brnn [ ] sentenc sequenc model local coher model [ ] smooth flow multipl sentenc datum stream variablelength sequenc denot tn use n denot posit sentenceimag sequenc defin cnn brnn model posit separ coher model whole data stream cnn compon choic vggnet [ ] repres imag dimension vector discuss detail brnn coher model section section respect final present combin output three compon creat singl compat score section brnn model role brnn model repres content flow text sequenc problem brnn suitabl normal rnn brnn simultan model forward backward stream allow us consid previou next sentenc sentenc make content whole sequenc interact one anoth show fig b brnn five layer input layer forwardbackward layer output layer relu activ layer final merg coher model two fulli connect layer note text repres dimension paragraph vector pt discuss section exact form brnn follow see fig b togeth good understand xft f wif pt bfi hft f xft wf hft xbt f wib pt bbi bf hbt f xbt wb hbt bb ot wo hft hbt bo brnn take sequenc text vector pt input comput xft xbt activ input unit forward backward unit unlik brnn model separ input activ forward backward one differ set paramet wif wib empir lead good perform set activ function f rectifi linear unit relu f x max x creat two independ forward backward hidden unit denot hft hbt final activ brnn ot regard descript content sentenc locat also implicitli encod flow sentenc surround context sequenc paramet set learn includ weight wif wib wf wb wo r bia bfi bbi bf bb bo r local coher model brnn model captur flow text content lack learn coher passag reflect distribut syntact referenti inform discours entiti thu explicitli includ local coher model base work [ ] focu resolv pattern local transit discours entiti e corefer noun phrase whole text show fig b first extract pars tree everi summar text denot zt concaten sequenc pars tree one larg one make entiti grid whole sequenc entiti grid tabl row correspond discours entiti column repres sentenc grammat role express three categori one absent e refer sentenc subject object x subject object absent make entiti grid enumer transit grammat role entiti whole text set histori paramet three mean obtain transit descript e g oox comput ratio occurr frequenc transit final creat dimension represent captur coher sequenc final make descriptor dimension vector zeropad forward relu layer do brnn output combin cnn rnn coher model relu activ layer rnn coher model output e ot n q go two fulli connect fc layer whose role decid proper combin brnn languag factor coher factor drop bia term fullyconnect layer dimens variabl wf r wf r ot q r st g r rn rn [ ] [ sn ] wf wf [ q ] [ g ] use share paramet q output mix well interact content flow coher test joint learn outperform learn two term separ paramet note multipl wf wf last two fc layer reduc singl linear map thank dropout assign dropout rate two layer empir improv gener perform much singl fc layer dropout train crcn train crcn model first defin compat score imag stream paragraph sequenc score function inspir karpathi et al [ ] two major differ first score function [ ] deal sentenc fragment imag fragment thu algorithm consid combin find good match hand defin score order pair compat sentenc sequenc imag sequenc second also add term measur relev relat coher imag sequenc text sequenc final score skl sentenc sequenc k imag stream l defin skl x skt vtl g k vtl n vtl denot cnn featur vector tth imag stream l defin cost function train crcn model follow [ ] c xhx k max skl skk l x max slk skk l skk denot score train pair correspond imag sentenc sequenc object base maxmargin structur loss encourag align imagesent sequenc pair high score margin misalign pair posit train exampl randomli sampl ne exampl train set sinc contrast exampl random length sampl dataset wide rang content extrem unlik neg exampl length content order sentenc posit exampl optim use backpropag time bptt algorithm [ ] train model appli stochast gradient descent sgd minibatch data stream among mani sgd techniqu select rmsprop optim [ ] lead good perform experi initi weight crcn model use method et al [ ] robust deep rectifi model observ good simpl gaussian random initi although model extrem deep use dropout regular layer except brnn dropout last fc layer remain layer retriev sentenc sequenc test time object retriev good sentenc sequenc give queri imag stream iq iqn first select knearest imag queri imag train databas use ` distanc cnn vggnet fc featur [ ] experi k success gener set sentenc sequenc candid c concaten sentenc associ knearest imag locat final use learn crcn model comput compat score queri imag stream sequenc candid accord rank candid howev one major difficulti scenario exponenti mani candid e c k n resolv issu use approxim divideandconqu strategi recurs halv problem subproblem size subproblem manag exampl halv search candid length q time search space subproblem q becom k n use beam search idea first find topm good sequenc candid subproblem low level recurs increas candid length maximum candid size limit set though approxim search experi assur achiev almost optim solut plausibl combinatori search mainli local fluenci coher undoubtedli necessari global one order whole sentenc sequenc fluent coher subpart must well experi compar perform approach stateoftheart candid method via quantit measur user studi use amazon mechan turk amt pleas refer supplementari materi result detail implement experiment set experiment set dataset collect blog dataset two topic nyc disneyland reus blog datum disneyland dataset [ ] newli collect datum nyc use crawl method [ ] first crawl blog post associ pictur two popular blog publish site blogspot wordpress chang queri term googl search manual select travelogu post describ stori event multipl imag final dataset includ uniqu blog post imag nyc blog post imag disneyland task quantit evalu randomli split dataset train set valid other test set test post use imag sequenc queri iq sequenc summar sentenc groundtruth tg algorithm retrief good sequenc train databas queri imag sequenc ideal retriev sequenc match well tg sinc train test datum disjoint algorithm retriev similar ident sentenc best quantit measur exploit two type metric languag similar e bleu [ ] cider [ ] meteor [ ] score retriev accuraci e topk recal median rank popularli use text gener literatur [ ] topk recal rk recal rate groundtruth retriev give top k candid median rank indic median rank valu first retriev groundtruth good perform indic high bleu cider meteor rk score low median rank valu baselin sinc sentenc sequenc gener imag stream address yet previou research instead extend sever stateoftheart singlesent model publicli avail code baselin includ logbilinear multimod model kiro et al [ ] recurr convolut model karpathi et al [ ] vinyal et al [ ] [ ] use three variant introduc paper standard logbilinear model lbl two multimod extens modalityba lbl mlblb factor threeway lbl mlblf use neuraltalk packag author karpathi et al baselin [ ] denot cnnrnn [ ] denot cnnlstm simpl baselin also compar global match glomatch [ ] baselin creat final sentenc sequenc concaten sentenc gener imag queri stream b b cnnlstm [ ] cnnrnn [ ] mlblf [ ] mlblb [ ] lbl [ ] glomatch [ ] nn rcn crcn cnnlstm [ ] cnnrnn [ ] mlblf [ ] mlblb [ ] lbl [ ] glomatch [ ] nn rcn crcn languag metric retriev metric b b cider meteor r r r medrank new york citi disneyland tabl evalu sentenc gener two dataset new york citi disneyland languag similar metric bleu retriev metric rk median rank good perform indic high bleu cider meteor rk score low median rank valu also compar differ variant method valid contribut key compon method test knearest search nn without rnn part simpl variant imag test queri find k similar train imag simpli concaten associ sentenc second variant brnnonli method denot rcn exclud entitybas coher model approach complet method denot crcn comparison quantifi improv coher model fair use vggnet fc featur [ ] algorithm quantit result tabl show quantit result experi use languag retriev metric approach crcn rcn outperform larg margin stateoftheart baselin gener passag without consider sentencetosent transit unlik mlblf show good perform among three model [ ] albeit small margin partli share word dictionari train among mrnnbase model cnnlstm significantli outperform cnnrnn lstm unit help learn model irregular lengthi datum natur blog robustli also observ crcn outperform nn rcn especi retriev metric show integr two key compon brnn coher model inde contribut perform improv crcn slightli good rcn languag metric significantli good retriev metric mean rcn fine retriev fairli good solut good rank correct solut high compar crcn small margin languag metric also attribut inher limit exampl bleu focu count match ngram word thu good compar sentenc even bad paragraph fulli evalu fluenci coher fig illustr sever exampl sentenc sequenc retriev set show queri imag stream text result creat method baselin except fig show part sequenc rather long illustr qualit exampl demonstr approach success verbal imag sequenc includ varieti content user studi via amazon mechan turk perform user studi use amt observ gener user prefer text sequenc differ algorithm sinc evalu involv multipl imag long passag text design amt task suffici simpl gener turker background knowledg figur exampl sentenc sequenc retriev nyc top disneyland bottom set present part queri imag stream correspond text output method baselin baselin glomatch cnnlstm mlblb rcn rcn n nyc disneyland tabl result amt pairwis prefer test present percentag respon turker vote crcn baselin length queri stream except last column first randomli sampl test stream two dataset first set maximum number imag per queri queri longer uniformli sampl amt test show queri imag stream iq pair passag gener method crcn one baselin random order ask turker choos agre text sequenc iq design test pairwis comparison instead multiplechoic question make answer analysi easi question look similar exampl fig obtain answer three differ turker queri compar four baselin choos mlblb among three variant [ ] cnnlstm among mrnnbase method also select glomatch rcn variant method tabl show result amt test valid amt annot prefer result baselin glomatch bad use weak imag represent e gist tini imag differ crcn rcn e th column tabl signific previou quantit measur mainli queri imag stream sampl rel short coher becom critic passag longer justifi argument run anoth set amt test use imag per queri show last column tabl perform margin crcn rcn becom larg length queri imag stream increas result assur passag long coher becom import thu crcn output prefer turker conclus propos approach retriev sentenc sequenc imag stream develop coher recurr convolut network crcn consist convolut network bidirect recurr network entityba local coher model quantit evalu user studi use amt larg collect blog post demonstr crcn approach outperform stateoftheart candid method acknowledg research partial support hancom basic scienc research program nation research foundat korea rcaa refer [ ] r barzilay lapata model local coher entityba approach acl [ ] bird e loper e klein natur languag process python oreilli media inc [ ] x chen c l zitnick mind eye recurr visual represent imag caption gener cvpr [ ] f choi p wiemerhast j moor latent semant analysi text segment emnlp [ ] j donahu l hendrick guadarrama rohrbach venugopalan k saenko darrel longterm recurr convolut network visual recognit descript cvpr [ ] gong l wang hodosh j hockenmai lazebnik improv imagesent embed use larg weakli annot photo collect eccv [ ] k x zhang ren j sun delv deep rectifi surpass humanlevel perform imagenet classif arxiv [ ] hodosh p young j hockenmai frame imag descript rank task datum model evalu metric jair [ ] karpathi l feifei deep visualsemant align gener imag descript cvpr [ ] g kim moon l sigal joint photo stream blog post summar explor cvpr [ ] g kim moon l sigal rank retriev imag sequenc multipl paragraph queri cvpr [ ] r kiro r salakhutdinov r zemel multimod neural languag model icml [ ] krizhevski sutskev g e hinton imagenet classif deep convolut neural network nip [ ] g kulkarni v premraj dhar li choi c berg l berg babi talk understand gener imag descript cvpr [ ] p kuznetsova v ordonez l berg choi treetalk composit compress tree imag descript tacl [ ] b lavi meteor automat metric mt evalu improv correl human judgment acl [ ] q le mikolov distribut represent sentenc document icml [ ] c man surdeanu j bauer j finkel j bethard mccloski stanford corenlp natur languag process toolkit acl [ ] j mao w xu yang j wang z huang l yuill deep caption multimod recurr neural network mrnn iclr [ ] mikolov statist languag model base neural network ph thesi brno univers technolog [ ] v ordonez g kulkarni l berg imtext describ imag use million caption photograph nip [ ] k papineni rouko ward w j zhu bleu method automat evalu machin translat acl [ ] rohrbach w qiu titov thater pinkal b schiel translat video content natur languag descript iccv [ ] schuster k k paliw bidirect recurr neural network ieee tsp [ ] k simonyan zisserman deep convolut network largescal imag recognit iclr [ ] r socher karpathi q v le c man ng ground composit semant find describ imag sentenc tacl [ ] n srivastava r salakhutdinov multimod learn deep boltzmann machin nip [ ] tieleman g e hinton lectur rmsprop coursera [ ] r vedantam c l zitnick parikh cider consensusba imag descript evalu arxiv [ ] vinyal toshev bengio erhan show tell neural imag caption gener cvpr [ ] p j werbo gener backpropag applic recurr ga market model neural network [ ] r xu c xiong w chen j j corso jointli model deep video composit text bridg vision languag unifi framework aaai
9,5814,Parallel Correlation Clustering on Big Graphs,Poster,5814-parallel-correlation-clustering-on-big-graphs.pdf,"Given a similarity graph between items, correlation clustering (CC) groups similar items together and dissimilar ones apart. One of the most popular CC algorithms is KwikCluster:  an algorithm that serially clusters neighborhoods of vertices, and obtains a 3-approximation ratio. Unfortunately, in practice KwikCluster requires a large number of clustering rounds, a potential bottleneck for large graphs.We present C4 and ClusterWild!, two algorithms for parallel correlation clustering that run in a polylogarithmic number of rounds, and provably achieve nearly linear speedups. C4 uses concurrency control to enforce serializability of a parallel clustering process, and guarantees a 3-approximation ratio. ClusterWild! is a coordination free algorithm that abandons consistency for the benefit of better scaling; this leads to a provably small loss in the 3 approximation ratio.We provide extensive experimental results for both algorithms,  where we outperform the state of the art, both in terms of clustering accuracy and running time. We show that our algorithms can cluster billion-edge graphs in under 5 seconds on 32 cores, while achieving a 15x speedup.","Parallel Correlation Clustering on Big Graphs
Xinghao Pan↵,✏ , Dimitris Papailiopoulos↵,✏ , Samet Oymak↵,✏ ,
Benjamin Recht↵,✏, , Kannan Ramchandran✏ , and Michael I. Jordan↵,✏,
↵
AMPLab, ✏ EECS at UC Berkeley, Statistics at UC Berkeley

Abstract
Given a similarity graph between items, correlation clustering (CC) groups similar
items together and dissimilar ones apart. One of the most popular CC algorithms
is KwikCluster: an algorithm that serially clusters neighborhoods of vertices, and
obtains a 3-approximation ratio. Unfortunately, in practice KwikCluster requires
a large number of clustering rounds, a potential bottleneck for large graphs.
We present C4 and ClusterWild!, two algorithms for parallel correlation clustering that run in a polylogarithmic number of rounds, and provably achieve nearly
linear speedups. C4 uses concurrency control to enforce serializability of a parallel clustering process, and guarantees a 3-approximation ratio. ClusterWild! is
a coordination free algorithm that abandons consistency for the benefit of better
scaling; this leads to a provably small loss in the 3 approximation ratio.
We demonstrate experimentally that both algorithms outperform the state of the
art, both in terms of clustering accuracy and running time. We show that our
algorithms can cluster billion-edge graphs in under 5 seconds on 32 cores, while
achieving a 15⇥ speedup.

1

Introduction

Clustering items according to some notion of similarity is a major primitive in machine learning.
Correlation clustering serves as a basic means to achieve this goal: given a similarity measure
between items, the goal is to group similar items together and dissimilar items apart. In contrast to
other clustering approaches, the number of clusters is not determined a priori, and good solutions
aim to balance the tension between grouping all items together versus isolating them.
The simplest CC variant can be described on a
complete signed graph. Our input is a graph
G on n vertices, with +1 weights on edges between similar items, and 1 edges between dissimilar ones. Our goal is to generate a partition
of vertices into disjoint sets that minimizes the
number of disagreeing edges: this equals the
number of “+” edges cut by the clusters plus
the number of “ ” edges inside the clusters.
This metric is commonly called the number of
disagreements. In Figure 1, we give a toy example of a CC instance.

cluster 1

cluster 2

cost = (#“ ” edges inside clusters) + (#“+” edges across clusters) = 2

Figure 1: In the above graph, solid edges denote similarity and dashed dissimilarity. The number of disagreeing edges in the above clustering clustering is 2; we
color the bad edges with red.

Entity deduplication is the archetypal motivating example for correlation clustering, with applications in chat disentanglement, co-reference resolution, and spam detection [1, 2, 3, 4, 5, 6]. The
input is a set of entities (say, results of a keyword search), and a pairwise classifier that indicates—
with some error—similarities between entities. Two results of a keyword search might refer to the
same item, but might look different if they come from different sources. By building a similarity
1

graph between entities and then applying CC, the hope is to cluster duplicate entities in the same
group; in the context of keyword search, this implies a more meaningful and compact list of results.
CC has been further applied to finding communities in signed networks, classifying missing edges
in opinion or trust networks [7, 8], gene clustering [9], and consensus clustering [3].
KwikCluster is the simplest CC algorithm that achieves a provable 3-approximation ratio [10], and
works in the following way: pick a vertex v at random (a cluster center), create a cluster for v
and its positive neighborhood N (v) (i.e., vertices connected to v with positive edges), peel these
vertices and their associated edges from the graph, and repeat until all vertices are clustered. Beyond
its theoretical guarantees, experimentally KwikCluster performs well when combined with local
heuristics [3].
KwikCluster seems like an inherently sequential algorithm, and in most cases of interest it requires
many peeling rounds. This happens because a small number of vertices are clustered per round. This
can be a bottleneck for large graphs. Recently, there have been efforts to develop scalable variants
of KwikCluster [5, 6]. In [6] a distributed peeling algorithm was presented in the context of MapReduce. Using an elegant analysis, the authors establish a (3 + ✏)-approximation in a polylogarithmic
number of rounds. The algorithm employs a simple step that rejects vertices that are executed in
parallel but are “conflicting”; however, we see in our experiments, this seemingly minor coordination step hinders scale-ups in a parallel core setting. In [5], a sketch of a distributed algorithm was
presented. This algorithm achieves the same approximation as KwikCluster, in a logarithmic number of rounds, in expectation. However, it performs significant redundant work, per iteration, in its
effort to detect in parallel which vertices should become cluster centers.
Our contributions We present C4 and ClusterWild!, two parallel CC algorithms with provable
performance guarantees, that in practice outperform the state of the art, both in terms of running
time and clustering accuracy. C4 is a parallel version of KwikCluster that uses concurrency control
to establish a 3-approximation ratio. ClusterWild! is a simple to implement, coordination-free
algorithm that abandons consistency for the benefit of better scaling, while having a provably small
loss in the 3 approximation ratio.
C4 achieves a 3 approximation ratio, in a poly-logarithmic number of rounds, by enforcing consistency between concurrently running peeling threads. Consistency is enforced using concurrency
control, a notion extensively studied for databases transactions, that was recently used to parallelize
inherently sequential machine learning algorithms [11].
ClusterWild! is a coordination-free parallel CC algorithm that waives consistency in favor of speed.
The cost we pay is an arbitrarily small loss in ClusterWild!’s accuracy. We show that ClusterWild!
achieves a (3 + ✏)OPT + O(✏ · n · log2 n) approximation, in a poly-logarithmic number of rounds,
with provable nearly linear speedups. Our main theoretical innovation for ClusterWild! is analyzing
the coordination-free algorithm as a serial variant of KwikCluster that runs on a “noisy” graph.
In our experimental evaluation, we demonstrate that both algorithms gracefully scale up to graphs
with billions of edges. In these large graphs, our algorithms output a valid clustering in less than
5 seconds, on 32 threads, up to an order of magnitude faster than KwikCluster. We observe how,
not unexpectedly, ClusterWild! is faster than C4, and quite surprisingly, abandoning coordination in
this parallel setting, only amounts to a 1% of relative loss in the clustering accuracy. Furthermore,
we compare against state of the art parallel CC algorithms, showing that we consistently outperform
these algorithms in terms of both running time and clustering accuracy.
Notation G denotes a graph with n vertices and m edges. G is complete and only has ±1 edges.
We denote by dv the positive degree of a vertex, i.e., the number of vertices connected to v with
positive edges. denotes the positive maximum degree of G, and N (v) denotes the positive neighborhood of v; moreover, let Cv = {v, N (v)}. Two vertices u, v are termed as “friends” if u 2 N (v)
and vice versa. We denote by ⇡ a permutation of {1, . . . , n}.

2

2

Two Parallel Algorithms for Correlation Clustering

The formal definition of correlation clustering is given below.
Correlation Clustering. Given a graph G on n vertices, partition the vertices into an arbitrary
number k of disjoint subsets C1 , . . . , Ck such that the sum of negative edges within the subsets plus
the sum of positive edges across the subsets is minimized:
OPT = min

1kn

min

Ci \Cj =0,8i6=j

[k
i=1 Ci ={1,...,n}

k
X
i=1

E (Ci , Ci ) +

k
k
X
X

i=1 j=i+1

E + (Ci , Cj )

where E + and E are the sets of positive and negative edges in G.
KwikCluster is a remarkably simple algorithm that approximately solves the above combinatorial
problem, and operates as follows. A random vertex v is picked, a cluster Cv is created with v and
its positive neighborhood, then the vertices in Cv are peeled from the graph, and this process is
repeated until all vertices are clustered KwikCluster can be equivalently executed, as noted by [5], if
we substitute the random choice of a vertex per peeling round, with a random order ⇡ preassigned to
vertices, (see Alg. 1). That is, select a random permutation on vertices, then peel the vertex indexed
by ⇡(1), and its friends. Remove from ⇡ the vertices in Cv and repeat this process. Having an order
among vertices makes the discussion of parallel algorithms more convenient.
C4: Parallel CC using Concurency Control. Algorithm 1 KwikCluster with ⇡
Suppose we now wish to run a parallel version
of KwikCluster, say on two threads: one thread 1: ⇡ = a random permutation of {1, . . . , n}
picks vertex v indexed by ⇡(1) and the other 2: while V 6= ; do
thread picks u indexed by ⇡(2), concurrently. 3: select the vertex v indexed by ⇡(1)
4: Cv = {v, N (v)}
Can both vertices be cluster centers? They can, 5: Remove
clustered vertices from G and ⇡
iff they are not friends in G. If v and u are con- 6: end while
nected with a positive edge, then the vertex with
the smallest order wins. This is our concurency
rule no. 1. Now, assume that v and u are not friends in G, and both v and u become cluster centers.
Moreover, assume that v and u have a common, unclustered friend, say w: should w be clustered
with v, or u? We need to follow what would happen with KwikCluster in Alg. 1: w will go with
the vertex that has the smallest permutation number, in this case v. This is concurency rule no. 2.
Following the above simple rules, we develop C4, our serializable parallel CC algorithm. Since, C4
constructs the same clusters as KwikCluster (for a given ordering ⇡), it inherits its 3 approximation.
The above idea of identifying the cluster centers in rounds was first used in [12] to obtain a parallel
algorithm for maximal independent set (MIS).
C4, shown as Alg. 2, starts by assigning a random permutation ⇡ to the vertices, it then samples an
active set A of n unclustered vertices; this sample is taken from the prefix of ⇡. After sampling
A, each of the P threads picks a vertex with the smallest order in A, then checks if that vertex can
become a cluster center. We first enforce concurrency rule no. 1: adjacent vertices cannot be cluster
centers at the same time. C4 enforces it by making each thread check the friends of the vertex, say
v, that is picked from A. A thread will check in attemptCluster whether its vertex v has any
preceding friends that are cluster centers. If there are none, it will go ahead and label v as cluster
center, and proceed with creating a cluster. If a preceding friend of v is a cluster center, then v is
labeled as not being a cluster center. If a preceding friend of v, call it u, has not yet received a
label (i.e., u is currently being processed and is not yet labeled as cluster center or not), then the
thread processing v, will wait on u to receive a label. The major technical detail is in showing that
this wait time is bounded; we show that no more than O(log n) threads can be in conflict at the
same time, using a new subgraph sampling lemma [13]. Since C4 is serializable, it has to respect
concurrency rule no. 2: if a vertex u is adjacency to two cluster centers, then it gets assigned to the
one with smaller permutation order. This is accomplished in createCluster. After processing
all vertices in A, all threads are synchronized in bulk, the clustered vertices are removed, a new
active set is sampled, and the same process is repeated until everything has been clustered. In the
following section, we present the theoretical guarantees for C4.
3

Algorithm 2 C4 & ClusterWild!
1:
2:
3:
4:
5:
6:
7:
8:
9:
10:
11:
12:
13:
14:
15:
16:
17:
18:

createCluster(v):
clusterID(v) = ⇡(v)
for u 2 (v) \ A do
clusterID(u) = min(clusterID(u), ⇡(v))
end for

Input: G, ✏
clusterID(1) = . . . = clusterID(n) = 1
⇡ = a random permutation of {1, . . . , n}
while V 6= ; do
attemptCluster(v):
= maximum vertex degree in G(V )
if clusterID(u) = 1 and isCenter(v) then
A = the first ✏ · n vertices in V [⇡].
createCluster(v)
while A 6= ; do in parallel
end if
v = first element in A
A = A {v}
isCenter(v):
if C4 then // concurrency control
for u 2 (v) do // check friends (in order of ⇡)
attemptCluster(v)
if ⇡(u) < ⇡(v) then // if they precede you, wait
else if ClusterWild! then // coordination free
wait until clusterID(u) 6= 1 // till clustered
createCluster(v)
if isCenter(u) then
end if
return 0 //a friend is center, so you can’t be
end while
end if
Remove clustered vertices from V and ⇡
end if
end while
end for
Output: {clusterID(1), . . . , clusterID(n)}.
return 1 // no earlier friends are centers, so you are

ClusterWild!: Coordination-free Correlation Clustering. ClusterWild! speeds up computation
by ignoring the first concurrency rule. It uniformly samples unclustered vertices, and builds clusters
around all of them, without respecting the rule that cluster centers cannot be friends in G. In ClusterWild!, threads bypass the attemptCluster routine; this eliminates the “waiting” part of C4.
ClusterWild! samples a set A of vertices from the prefix of ⇡. Each thread picks the first ordered
vertex remaining in A, and using that vertex as a cluster center, it creates a cluster around it. It peels
away the clustered vertices and repeats the same process, on the next remaining vertex in A. At
the end of processing all vertices in A, all threads are synchronized in bulk, the clustered vertices
are removed, a new active set is sampled, and the parallel clustering is repeated. A careful analysis along the lines of [6] shows that the number of rounds (i.e., bulk synchronization steps) is only
poly-logarithmic.
Quite unsurprisingly, ClusterWild! is faster than C4. Interestingly, abandoning consistency does not
incur much loss in the approximation ratio. We show how the error introduced in the accuracy of the
solution can be bounded. We characterize this error theoretically, and show that in practice it only
translates to only a relative 1% loss in the objective. The main intuition of why ClusterWild! does
not introduce too much error is that the chance of two randomly selected vertices being friends is
small, hence the concurrency rules are infrequently broken.

3

Theoretical Guarantees

In this section, we bound the number of rounds required for each algorithms, and establish the
theoretical speedup one can obtain with P parallel threads. We proceed to present our approximation
guarantees. We would like to remind the reader that—as in relevant literature—we consider graphs
that are complete, signed, and unweighted. The omitted proofs can be found in the Appendix.
3.1

Number of rounds and running time

Our analysis follows those of [12] and [6]. The main idea is to track how fast the maximum degree
decreases in the remaining graph at the end of each round.
Lemma 1. C4 and ClusterWild! terminate after O 1✏ log n · log
rounds w.h.p.
We now analyze the running time of both algorithms under a simplified BSP model. The main idea
is that the the running time of each “super step” (i.e., round) is determined by the “straggling” thread
(i.e., the one that gets assigned the most amount of work), plus the time needed for synchronization
at the end of each round.
Assumption 1. We assume that threads operate asynchronously within a round and synchronize at
the end of a round. A memory cell can be written/read concurrently by multiple threads. The time
4

spent per round of the algorithm is proportional to the time of the slowest thread. The cost of thread
synchronization at the end of each batch takes time O(P ), where P is the number of threads. The
total computation cost is proportional to the sum of the time spent for all rounds, plus the time spent
during the bulk synchronization step.
Under this simplified model, we show that both algorithms obtain nearly linear speedup, with ClusterWild! being faster than C4, precisely due to lack of coordination. Our main tool for analyzing C4
is a recent graph-theoretic result from [13] (Theorem 1), which guarantees that if one samples an
O(n/ ) subset of vertices in a graph, the sampled subgraph has a connected component of size at
most O(log n). Combining the above, in the appendix we show the following result.
Theorem
2. The ⌘theoretical running
time of C4 on P cores is upper bounded by
⇣⇣
⌘
m+n log n
O
+ P log n · log
as long as the number of cores P is smaller than mini nii ,
P
where nii is the size of the batch in the i-th round of each algorithm. The running time of ClusterWild! on P cores is upper bounded by O m+n
+ P log n · log
.
P
3.2

Approximation ratio

We now proceed with establishing the approximation ratios of C4 and ClusterWild!.
C4 is serializable. It is straightforward that C4 obtains precisely the same approximation ratio as
KwikCluster. One has to simply show that for any permutation ⇡, KwikCluster and C4 will output
the same clustering. This is indeed true, as the two simple concurrency rules mentioned in the
previous section are sufficient for C4 to be equivalent to KwikCluster.
Theorem 3. C4 achieves a 3 approximation ratio, in expectation.
ClusterWild! as a serial procedure on a noisy graph. Analyzing ClusterWild! is a bit more
involved. Our guarantees are based on the fact that ClusterWild! can be treated as if one was
running a peeling algorithm on a “noisy” graph. Since adjacent active vertices can still become
cluster centers in ClusterWild!, one can view the edges between them as “deleted,” by a somewhat
unconventional adversary. We analyze this new, noisy graph and establish our theoretical result.
Theorem 4. ClusterWild! achieves a (3 + ✏)·OPT+O(✏·n·log2 n) approximation, in expectation.
We provide a sketch of the proof, and delegate the details to the appendix. Since ClusterWild!
ignores the edges among active vertices, we treat these edges as deleted. In our main result, we
quantify the loss of clustering accuracy that is caused by ignoring these edges. Before we proceed,
we define bad triangles, a combinatorial structure that is used to measure the clustering quality of a
peeling algorithm.
Definition 1. A bad triangle in G is a set of three vertices, such that two pairs are joined with a
positive edge, and one pair is joined with a negative edge. Let Tb denote the set of bad triangles in
G.
To quantify the cost of ClusterWild!, we make the below observation.
Lemma 5. The cost of any greedy algorithm that picks a vertex v (irrespective of the sampling
order), creates Cv , peels it away and repeats, is equal to the number of bad triangles adjacent to
each cluster center v.
Lemma 6. Let Ĝ denote the random graph induced by deleting all edges between active vertices per
round, for a given run of ClusterWild!, and let ⌧new denote the number of additional bad triangles
thatP
Ĝ has compared to G. Then, the expected cost of ClusterWild! can be upper bounded as
E
t2Tb 1Pt + ⌧new , where Pt is the event that triangle t, with end points i, j, k, is bad, and at
least one of its end points becomes active, while t is still part of the original unclustered graph.
Proof. We begin by bounding the second term E{⌧new }, by considering the number of new bad
triangles ⌧new,i created at each round i:
E {⌧new,i } 

X

(u,v)2E

P(u, v 2 Ai )·|N (u)[N (v)| 

X ✓ ✏ ◆2

(u,v)2E

5

i

·2·

i



2·✏2 ·

E
i



2·✏2 ·n.

Using the result that ClusterWild! terminates after at most O( 1✏ log n log ) rounds, we get that1
E {⌧new }  O(✏ · n · log2 n).
P
P
We are left to bound E
t2Tb 1Pt =
t2Tb pt . To do that we use the following lemma.
P
P
pt
Lemma 7. If pt satisfies 8e,
t:e⇢t2Tb ↵  1, then,
t2Tb pt  ↵ · OP T.

Proof. Let B⇤ be one (of the
many) sets
thatPattribute a +1 in theP
cost of an optimal
P possibly P
P of edges
pt
pt
pt
algorithm. Then, OPT = e2B⇤ 1
e2B⇤
t:e⇢t2Tb ↵ =
t2Tb |B⇤ \ t| ↵
t2Tb ↵ .
| {z }
1

Now, as with [6],
P we will simply have to boundSthe expectation of the bad triangles, adjacent to
an edge (u, v): t:{u,v}⇢t2Tb 1Pt . Let Su,v = {u,v}⇢t2Tb t be the union of the sets of nodes of
the bad triangles that contain both vertices u and v. Observe that if some w 2 S\{u, v} becomes
active before u and v, then a cost of 1 (i.e., the cost of the bad triangle {u, v, w}) is incurred. On
the other hand, if either u or v, or both, are selected as pivots in some round, then Cu,v can be
as high as |S| 2, i.e., at most equal to all bad triangles containing the edge {u, v}. Let Auv =
{u or v are activated before any other vertices in Su,v }. Then,
⇥
⇤
C
E [Cu,v ] = E [ Cu,v | Au,v ] · P(Au,v ) + E Cu,v | AC
u,v · P(Au,v )
 1 + (|S|

2) · P({u, v} \ A =
6 ;|S \ A 6= ;)  1 + 2|S| · P(v \ A =
6 ;|S \ A 6= ;)

where the last inequality is obtained by a union bound over u and v. We now bound the following
probability:
P { v 2 A| S \ A 6= ;} =

P {v 2 A} · P {S \ A 6= ; |v 2 A }
P {v 2 A}
=
=
P {S \ A =
6 ;}
P {S \ A 6= ;}
1

P {v 2 A}
.
P {S \ A = ;}

Observe that P {v 2 A} = ✏ , hence we need to upper bound P {S \ A = ;}. The probability, per
round, that no positive neighbors in S become activated is upper bounded by
""✓
◆ ✓
◆|S|
◆n/P #|S|n/P ✓ ◆|S|n/P
|S| ✓
n |S|
Y
P
P
P
1
P
=
1
 1
=
1

.
n
n
|S|
+
t
n
n
e
P
t=1
Hence, the probability can be upper bounded as

|S|P { v \ A =
6 ;| S \ A =
6 ;} 

✏ · |S|/
.
1 e ✏·|S|/

We know that |S|  2 · + 2 and also ✏  1. Then, 0  ✏ · |S|  ✏ · 2 + 2 n  4 Hence, we have
o
P
4✏
E(Cu,v )  1 + 2 · 1 exp{

t2Tb 1Pt + ⌧new
4✏} . The overall expectation is then bounded by E
⇣

1+2·

4·✏
1 e 4·✏

⌘

· OPT + ✏ · n · ln(n/ ) · log

our approximation ratio for ClusterWild!.
3.3

 (3 + ✏) · OPT + O(✏ · n · log2 n) which establishes

BSP Algorithms as a Proxy for Asynchronous Algorithms

We would like to note that the analysis under the BSP model can be a useful proxy for the performance of completely asynchronous variants of our algorithms. Specifically, see Alg. 3, where we
remove the synchronization barriers.
The only difference between the asynchronous execution in Alg. 3, compared to Alg. 2, is the complete lack of bulk synchronization, at the end of the processing of each active set A. Although the
analysis of the BSP variants of the algorithms is tractable, unfortunately analyzing precisely the
speedup of the asynchronous C4 and the approximation guarantees for the asynchronous ClusterWild! is challenging. However, in our experimental section we test the completely asynchronous
algorithms against the BSP algorithms of the previous section, and observe that they perform quite
similarly both in terms of accuracy of clustering, and running times.
1

We skip the constants to simplify the presentation; however they are all smaller than 10.

6

4

Related Work

Correlation clustering was formally introduced
by Bansal et al. [14]. In the general case, minimizing disagreements is NP-hard and hard to
approximate within an arbitrarily small constant (APX-hard) [14, 15]. There are two variations of the problem: i) CC on complete graphs
where all edges are present and all weights are
±1, and ii) CC on general graphs with arbitrary
edge weights. Both problems are hard, however the general graph setup seems fundamentally harder. The best known approximation ratio for the latter is O(log n), and a reduction to
the minimum multicut problem indicates that
any improvement to that requires fundamental
breakthroughs in theoretical algorithms [16].

Algorithm 3 C4 & ClusterWild!
(asynchronous execution)
1: Input: G
2: clusterID(1) = . . . = clusterID(n) = 1
3: ⇡ = a random permutation of {1, . . . , n}
4: while V 6= ; do
5: v = first element in V
6: V = V {v}
7: if C4 then // concurrency control
8:
attemptCluster(v)
9: else if ClusterWild! then // coordination free
10:
createCluster(v)
11: end if
12: Remove clustered vertices from V and ⇡
13: end while
14: Output: {clusterID(1), . . . , clusterID(n)}.

In the case of complete unweighted graphs, a long series of results establishes a 2.5 approximation
via a rounded linear program (LP) [10]. A recent result establishes a 2.06 approximation using an
elegant rounding to the same LP relaxation [17]. By avoiding the expensive LP, and by just using the
rounding procedure of [10] as a basis for a greedy algorithm yields KwikCluster: a 3 approximation
for CC on complete unweighted graphs.
Variations of the cost metric for CC change the algorithmic landscape: maximizing agreements (the
dual measure of disagreements) [14, 18, 19], or maximizing the difference between the number of
agreements and disagreements [20, 21], come with different hardness and approximation results.
There are also several variants: chromatic CC [22], overlapping CC [23], small number of clusters
CC with added constraints that are suitable for some biology applications [24].
The way C4 finds the cluster centers can be seen as a variation of the MIS algorithm of [12]; the
main difference is that in our case, we “passively” detect the MIS, by locking on memory variables,
and by waiting on preceding ordered threads. This means, that a vertex only “pushes” its cluster
ID and status (cluster center/clustered/unclustered) to its friends, versus “pulling” (or asking) for its
friends’ cluster status. This saves a substantial amount of computational effort.

5

Experiments

Our parallel algorithms were all implemented2 in Scala—we defer a full discussion of the implementation details to Appendix C. We ran all our experiments on Amazon EC2’s r3.8xlarge (32
vCPUs, 244Gb memory) instances, using 1-32 threads. The real graphs listed in Table 1 were each
Graph
DBLP-2011
ENWiki-2013
UK-2005
IT-2004
WebBase-2001

# vertices

# edges

986,324
4,206,785
39,459,925
41,291,594
118,142,155

6,707,236
101,355,853
921,345,078
1,135,718,909
1,019,903,190

Description
2011 DBLP co-authorship network [25, 26, 27].
2013 link graph of English part of Wikipedia [25, 26, 27].
2005 crawl of the .uk domain [25, 26, 27].
2004 crawl of the .it domain [25, 26, 27].
2001 crawl by WebBase crawler [25, 26, 27].

Table 1: Graphs used in the evaluation of our parallel algorithms.
tested with 100 different random ⇡ orderings. We measured the runtimes, speedups (ratio of runtime on 1 thread to runtime on p threads), and objective values obtained by our parallel algorithms.
For comparison, we also implemented the algorithm presented in [6], which we denote as CDK for
short3 . Values of ✏ = 0.1, 0.5, 0.9 were used for C4 BSP, ClusterWild! BSP and CDK. In the interest
of space, we present only representative plots of our results; full results are given in our appendix.
2

Code available at https://github.com/pxinghao/ParallelCorrelationClustering.
CDK was only tested on the smaller graphs of DBLP-2011 and ENWiki-2013, because CDK was prohibitively slow, often 2-3 orders of magnitude slower than C4, ClusterWild!, and even KwikCluster.
3

7

Mean Runtime, UK−2005

Mean runtime / ms

Mean runtime / ms

Mean Runtime, IT−2004

5

10

Serial
C4 As
C4 BSP ε=0.1
CW As
CW BSP ε=0.1

4

10

Mean Speedup, Webbase−2001

Serial
C4 As
C4 BSP ε=0.5
CW As
CW BSP ε=0.5

Ideal
C4 As
C4 BSP ε=0.9
CW As
CW BSP ε=0.9

16
14
12
Speedup

5

10

4

10

10
8
6
4
2

3

1

2

4
8
Number of threads

16

10

32

(a) Mean runtimes, UK-2005, ✏ = 0.1

1

4000

2000

0.08
0.07
% of blocked vertices

Number of rounds

6000

16

0.06

0.2

0.4

0.04
0.03
0.02

0.6

0.8

1

ε

(d)

Mean number of synchronization
rounds for BSP algorithms

5

10

15
20
25
Number of threads

30

10

15
20
25
Number of threads

30

35

(c) Mean speedup, WebBase, ✏ = 0.9
1.12

0.05

0
0

5

Objective Value Relative to Serial, DBLP−2011

C4 BSP ε=0.9 Min
C4 BSP ε=0.9 Mean
C4 BSP ε=0.9 Max
C4 BSP Min
C4 BSP Mean
C4 BSP Max

0.01

0
0

0
0

32

% of Blocked Vertices, ENWiki−2013

C4/CW BSP, UK−2005
C4/CW BSP, IT−2004
C4/CW BSP, Webbase−2001
C4/CW BSP, DBLP−2011
CDK, DBLP−2011
C4/CW BSP, ENWiki−2013
CDK, ENWiki−2013

8000

4
8
Number of threads

(b) Mean runtimes, IT-2004, ✏ = 0.5

Mean Number of Rounds
10000

2

Algo obj value : Serial obj value

10

3

1.1
1.08
1.06
1.04
1.02
1
0

35

(e)

Percent of blocked vertices for C4,
ENWiki-2013. BSP run with ✏ = 0.9.

CW BSP ε=0.9 mean
CW BSP ε=0.9 median
CW As mean
CW As median
CDK ε=0.9 mean
CDK ε=0.9 median

5

10

15
20
25
Number of threads

30

35

(f)

Median objective values, DBLP-2011.
CW BSP and CDK run with ✏ = 0.9

Figure 2: In the above figures, ‘CW’ is short for ClusterWild!, ‘BSP’ is short for the bulk-synchronous variants
of the parallel algorithms, and ‘As’ is short for the asynchronous variants.

Runtimes & Speedups: C4 and ClusterWild! are initially slower than serial, due to the overheads
required for atomic operations in the parallel setting. However, all our parallel algorithms outperform KwikCluster with 3-4 threads. As more threads are added, the asychronous variants become
faster than their BSP counterparts as there are no synchronization barrriers. The difference between
BSP and asychronous variants is greater for smaller ✏. ClusterWild! is also always faster than
C4 since there are no coordination overheads. The asynchronous algorithms are able to achieve a
speedup of 13-15x on 32 threads. The BSP algorithms have a poorer speedup ratio, but nevertheless
achieve 10x speedup with ✏ = 0.9.
Synchronization rounds: The main overhead of the BSP algorithms lies in the need for synchronization rounds. As ✏ increases, the amount of synchronization decreases, and with ✏ = 0.9, our
algorithms have less than 1000 synchronization rounds, which is small considering the size of the
graphs and our multicore setting.
Blocked vertices: Additionally, C4 incurs an overhead in the number of vertices that are blocked
waiting for earlier vertices to complete. We note that this overhead is extremely small in practice—
on all graphs, less than 0.2% of vertices are blocked. On the larger and sparser graphs, this drops to
less than 0.02% (i.e., 1 in 5000) of vertices.
Objective value: By design, the C4 algorithms also return the same output (and thus objective
value) as KwikCluster. We find that ClusterWild! BSP is at most 1% worse than serial across all
graphs and values of ✏. The behavior of asynchronous ClusterWild! worsens as threads are added,
reaching 15% worse than serial for one of the graphs. Finally, on the smaller graphs we were able
to test CDK on, CDK returns a worse median objective value than both ClusterWild! variants.

6

Conclusions and Future Directions

In this paper, we have presented two parallel algorithms for correlation clustering with nearly linear
speedups and provable approximation ratios. Overall, the two approaches support each other—when
C4 is relatively fast relative to ClusterWild!, we may prefer C4 for its guarantees of accuracy, and
when ClusterWild! is accurate relative to C4, we may prefer ClusterWild! for its speed.
In the future, we intend to implement our algorithms in the distributed environment, where synchronization and communication often account for the highest cost. Both C4 and ClusterWild! are
well-suited for the distributed environment, since they have polylogarithmic number of rounds.
8

References
[1] Ahmed K Elmagarmid, Panagiotis G Ipeirotis, and Vassilios S Verykios. Duplicate record detection: A survey. Knowledge and Data
Engineering, IEEE Transactions on, 19(1):1–16, 2007.
[2] Arvind Arasu, Christopher Ré, and Dan Suciu. Large-scale deduplication with constraints using dedupalog. In Data Engineering, 2009.
ICDE’09. IEEE 25th International Conference on, pages 952–963. IEEE, 2009.
[3] Micha Elsner and Warren Schudy. Bounding and comparing methods for correlation clustering beyond ilp. In Proceedings of the
Workshop on Integer Linear Programming for Natural Langauge Processing, pages 19–27. Association for Computational Linguistics,
2009.
[4] Bilal Hussain, Oktie Hassanzadeh, Fei Chiang, Hyun Chul Lee, and Renée J Miller. An evaluation of clustering algorithms in duplicate
detection. Technical report, 2013.
[5] Francesco Bonchi, David Garcia-Soriano, and Edo Liberty. Correlation clustering: from theory to practice. In Proceedings of the 20th
ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1972–1972. ACM, 2014.
[6] Flavio Chierichetti, Nilesh Dalvi, and Ravi Kumar. Correlation clustering in mapreduce. In Proceedings of the 20th ACM SIGKDD
international conference on Knowledge discovery and data mining, pages 641–650. ACM, 2014.
[7] Bo Yang, William K Cheung, and Jiming Liu. Community mining from signed social networks. Knowledge and Data Engineering,
IEEE Transactions on, 19(10):1333–1348, 2007.
[8] N Cesa-Bianchi, C Gentile, F Vitale, G Zappella, et al. A correlation clustering approach to link classification in signed networks. In
Annual Conference on Learning Theory, pages 34–1. Microtome, 2012.
[9] Amir Ben-Dor, Ron Shamir, and Zohar Yakhini. Clustering gene expression patterns. Journal of computational biology, 6(3-4):281–297,
1999.
[10] Nir Ailon, Moses Charikar, and Alantha Newman. Aggregating inconsistent information: ranking and clustering. Journal of the ACM
(JACM), 55(5):23, 2008.
[11] Xinghao Pan, Joseph E Gonzalez, Stefanie Jegelka, Tamara Broderick, and Michael Jordan. Optimistic concurrency control for distributed unsupervised learning. In Advances in Neural Information Processing Systems, pages 1403–1411, 2013.
[12] Guy E Blelloch, Jeremy T Fineman, and Julian Shun. Greedy sequential maximal independent set and matching are parallel on average.
In Proceedings of the twenty-fourth annual ACM symposium on Parallelism in algorithms and architectures, pages 308–317. ACM, 2012.
[13] Michael Krivelevich. The phase transition in site percolation on pseudo-random graphs. arXiv preprint arXiv:1404.5731, 2014.
[14] Nikhil Bansal, Avrim Blum, and Shuchi Chawla. Correlation clustering. In 2013 IEEE 54th Annual Symposium on Foundations of
Computer Science, pages 238–238. IEEE Computer Society, 2002.
[15] Moses Charikar, Venkatesan Guruswami, and Anthony Wirth. Clustering with qualitative information. In Foundations of Computer
Science, 2003. Proceedings. 44th Annual IEEE Symposium on, pages 524–533. IEEE, 2003.
[16] Erik D Demaine, Dotan Emanuel, Amos Fiat, and Nicole Immorlica. Correlation clustering in general weighted graphs. Theoretical
Computer Science, 361(2):172–187, 2006.
[17] Shuchi Chawla, Konstantin Makarychev, Tselil Schramm, and Grigory Yaroslavtsev. Near optimal LP rounding algorithm for correlation
clustering on complete and complete k-partite graphs. In Proceedings of the Forty-Seventh Annual ACM on Symposium on Theory of
Computing, STOC ’15, pages 219–228, 2015.
[18] Chaitanya Swamy. Correlation clustering: maximizing agreements via semidefinite programming. In Proceedings of the fifteenth annual
ACM-SIAM symposium on Discrete algorithms, pages 526–527. Society for Industrial and Applied Mathematics, 2004.
[19] Ioannis Giotis and Venkatesan Guruswami. Correlation clustering with a fixed number of clusters. In Proceedings of the seventeenth
annual ACM-SIAM symposium on Discrete algorithm, pages 1167–1176. ACM, 2006.
[20] Moses Charikar and Anthony Wirth. Maximizing quadratic programs: extending grothendieck’s inequality. In Foundations of Computer
Science, 2004. Proceedings. 45th Annual IEEE Symposium on, pages 54–60. IEEE, 2004.
[21] Noga Alon, Konstantin Makarychev, Yury Makarychev, and Assaf Naor. Quadratic forms on graphs. Inventiones mathematicae, 163(3):
499–522, 2006.
[22] Francesco Bonchi, Aristides Gionis, Francesco Gullo, and Antti Ukkonen. Chromatic correlation clustering. In Proceedings of the 18th
ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1321–1329. ACM, 2012.
[23] Francesco Bonchi, Aristides Gionis, and Antti Ukkonen. Overlapping correlation clustering. In Data Mining (ICDM), 2011 IEEE 11th
International Conference on, pages 51–60. IEEE, 2011.
[24] Gregory J Puleo and Olgica Milenkovic. Correlation clustering with constrained cluster sizes and extended weights bounds. arXiv
preprint arXiv:1411.0547, 2014.
[25] P. Boldi and S. Vigna. The WebGraph framework I: Compression techniques. In WWW, 2004.
[26] P. Boldi, M. Rosa, M. Santini, and S. Vigna. Layered label propagation: A multiresolution coordinate-free ordering for compressing
social networks. In WWW. ACM Press, 2011.
[27] P. Boldi, B. Codenotti, M. Santini, and S. Vigna. Ubicrawler: A scalable fully distributed web crawler. Software: Practice & Experience,
34(8):711–726, 2004.

9

",give similar graph item correl cluster cc group similar item togeth dissimilar one apart one popular cc algorithm kwikclust algorithm serial cluster neighborhood vertex obtain approxim ratio unfortun practic kwikclust requir larg number cluster round potenti bottleneck larg graph present c clusterwild two algorithm parallel correl cluster run polylogarithm number round provabl achiev nearli linear speedup c use concurr control enforc serializ parallel cluster process guarante approxim ratio clusterwild coordin free algorithm abandon consist benefit good scale lead provabl small loss approxim ratio provid extens experiment result algorithm outperform state art term cluster accuraci run time show algorithm cluster billionedg graph second core achiev x speedup,parallel correl cluster big graph xinghao pan dimitri papailiopoulo samet oymak benjamin recht kannan ramchandran michael jordan amplab eec uc berkeley statist uc berkeley abstract give similar graph item correl cluster cc group similar item togeth dissimilar one apart one popular cc algorithm kwikclust algorithm serial cluster neighborhood vertex obtain approxim ratio unfortun practic kwikclust requir larg number cluster round potenti bottleneck larg graph present c clusterwild two algorithm parallel correl cluster run polylogarithm number round provabl achiev nearli linear speedup c use concurr control enforc serializ parallel cluster process guarante approxim ratio clusterwild coordin free algorithm abandon consist benefit good scale lead provabl small loss approxim ratio demonstr experiment algorithm outperform state art term cluster accuraci run time show algorithm cluster billionedg graph second core achiev speedup introduct cluster item accord notion similar major primit machin learn correl cluster serv basic mean achiev goal give similar measur item goal group similar item togeth dissimilar item apart contrast cluster approach number cluster determin priori good solut aim balanc tension group item togeth versu isol simpl cc variant describ complet sign graph input graph g n vertex weight edg similar item edg dissimilar one goal gener partit vertex disjoint set minimiz number disagre edg equal number edg cut cluster plu number edg insid cluster metric commonli call number disagr figur give toy exampl cc instanc cluster cluster cost edg insid cluster edg across cluster figur graph solid edg denot similar dash dissimilar number disagre edg cluster cluster color bad edg red entiti dedupl archetyp motiv exampl correl cluster applic chat disentangl corefer resolut spam detect [ ] input set entiti say result keyword search pairwis classifi indic errorsimilariti entiti two result keyword search may refer item may look differ come differ sourc build similar graph entiti appli cc hope cluster duplic entiti group context keyword search impli meaning compact list result cc appli find commun sign network classifi miss edg opinion trust network [ ] gene cluster [ ] consensu cluster [ ] kwikclust simpl cc algorithm achiev provabl approxim ratio [ ] work follow way pick vertex v random cluster center creat cluster v posit neighborhood n v e vertex connect v posit edg peel vertex associ edg graph repeat vertex cluster beyond theoret guarante experiment kwikclust perform well combin local heurist [ ] kwikclust seem like inher sequenti algorithm case interest requir mani peel round happen small number vertex cluster per round bottleneck larg graph recent effort develop scalabl variant kwikclust [ ] [ ] distribut peel algorithm present context mapreduc use eleg analysi author establish approxim polylogarithm number round algorithm employ simpl step reject vertex execut parallel conflict howev see experi seemingli minor coordin step hinder scaleup parallel core set [ ] sketch distribut algorithm present algorithm achiev approxim kwikclust logarithm number round expect howev perform signific redund work per iter effort detect parallel vertex becom cluster center contribut present c clusterwild two parallel cc algorithm provabl perform guarante practic outperform state art term run time cluster accuraci c parallel version kwikclust use concurr control establish approxim ratio clusterwild simpl implement coordinationfre algorithm abandon consist benefit good scale provabl small loss approxim ratio c achiev approxim ratio polylogarithm number round enforc consist concurr run peel thread consist enforc use concurr control notion extens studi databas transact recent use parallel inher sequenti machin learn algorithm [ ] clusterwild coordinationfre parallel cc algorithm waif consist favor speed cost pay arbitrarili small loss clusterwild accuraci show clusterwild achief opt n log n approxim polylogarithm number round provabl nearli linear speedup main theoret innov clusterwild analyz coordinationfre algorithm serial variant kwikclust run noisi graph experiment evalu demonstr algorithm grace scale graph billion edg larg graph algorithm output valid cluster less second thread order magnitud fast kwikclust observ unexpectedli clusterwild faster c quit surprisingli abandon coordin parallel set amount rel loss cluster accuraci furthermor compar state art parallel cc algorithm show consist outperform algorithm term run time cluster accuraci notat g denot graph n vertex edg g complet edg denot dv posit degre vertex e number vertex connect v posit edg denot posit maximum degre g n v denot posit neighborhood v moreov let cv v n v two vertex u v term friend u n v vice versa denot permut n two parallel algorithm correl cluster formal definit correl cluster give correl cluster give graph g n vertex partit vertex arbitrari number k disjoint subset c ck sum neg edg within subset plu sum posit edg across subset minim opt min kn min ci \cj ij [ k ci n k x e ci ci k k x x ji e ci cj e e set posit neg edg g kwikclust remark simpl algorithm approxim solv combinatori problem oper follow random vertex v pick cluster cv creat v posit neighborhood vertex cv peel graph process repeat vertex cluster kwikclust equival execut note [ ] substitut random choic vertex per peel round random order preassign vertex see alg select random permut vertex peel vertex index friend remov vertex cv repeat process order among vertex make discuss parallel algorithm conveni c parallel cc use concur control algorithm kwikclust suppos wish run parallel version kwikclust say two thread one thread random permut n pick vertex v index v thread pick u index concurr select vertex v index cv v n v vertex cluster center remov cluster vertex g iff friend g v u con end nect posit edg vertex small order win concur rule assum v u friend g v u becom cluster center moreov assum v u common unclust friend say w w cluster v u need follow would happen kwikclust alg w go vertex small permut number case v concur rule follow simpl rule develop c serializ parallel cc algorithm sinc c construct cluster kwikclust give order inherit approxim idea identifi cluster center round first use [ ] obtain parallel algorithm maxim independ set mi c show alg start assign random permut vertex sampl activ set n unclust vertex sampl take prefix sampl p thread pick vertex small order check vertex becom cluster center first enforc concurr rule adjac vertex can not cluster center time c enforc make thread check friend vertex say v pick thread check attemptclust whether vertex v preced friend cluster center none go ahead label v cluster center proceed creat cluster preced friend v cluster center v label cluster center preced friend v call u yet receiv label e u current process yet label cluster center thread process v wait u receiv label major technic detail show wait time bound show log n thread conflict time use new subgraph sampl lemma [ ] sinc c serializ respect concurr rule vertex u adjac two cluster center get assign one small permut order accomplish createclust process vertex thread synchron bulk cluster vertex remov new activ set sampl process repeat everyth cluster follow section present theoret guarante c algorithm c clusterwild createclust v clusterid v v u v \ clusterid u min clusterid u v end input g clusterid clusterid n random permut n v attemptclust v maximum vertex degre g v clusterid u iscent v first n vertex v [ ] createclust v parallel end v first element v iscent v c concurr control u v check friend order attemptclust v u v preced wait els clusterwild coordin free wait clusterid u till cluster createclust v iscent u end return friend center can not end end remov cluster vertex v end end end output clusterid clusterid n return earli friend center clusterwild coordinationfre correl cluster clusterwild speed comput ignor first concurr rule uniformli sampl unclust vertex build cluster around without respect rule cluster center can not friend g clusterwild thread bypass attemptclust routin elimin wait part c clusterwild sampl set vertex prefix thread pick first order vertex remain use vertex cluster center creat cluster around peel away cluster vertex repeat process next remain vertex end process vertex thread synchron bulk cluster vertex remov new activ set sampl parallel cluster repeat care analysi along line [ ] show number round e bulk synchron step polylogarithm quit unsurprisingli clusterwild faster c interestingli abandon consist incur much loss approxim ratio show error introduc accuraci solut bound character error theoret show practic translat rel loss object main intuit clusterwild introduc much error chanc two randomli select vertex friend small henc concurr rule infrequ break theoret guarante section bind number round requir algorithm establish theoret speedup one obtain p parallel thread proceed present approxim guarante would like remind reader thata relev literaturew consid graph complet sign unweight omit proof find appendix number round run time analysi follow [ ] [ ] main idea track fast maximum degre decreas remain graph end round lemma c clusterwild termin log n log round w h p analyz run time algorithm simplifi bsp model main idea run time super step e round determin straggl thread e one get assign amount work plu time need synchron end round assumpt assum thread oper asynchron within round synchron end round memori cell writtenread concurr multipl thread time spend per round algorithm proport time slow thread cost thread synchron end batch take time p p number thread total comput cost proport sum time spend round plu time spend bulk synchron step simplifi model show algorithm obtain nearli linear speedup clusterwild faster c precis due lack coordin main tool analyz c recent graphtheoret result [ ] theorem guarante one sampl n subset vertex graph sampl subgraph connect compon size log n combin appendix show follow result theorem theoret run time c p core upper bound mn log n p log n log long number core p small mini nii p nii size batch ith round algorithm run time clusterwild p core upper bound mn p log n log p approxim ratio proceed establish approxim ratio c clusterwild c serializ straightforward c obtain precis approxim ratio kwikclust one simpli show permut kwikclust c output cluster inde true two simpl concurr rule mention previou section suffici c equival kwikclust theorem c achiev approxim ratio expect clusterwild serial procedur noisi graph analyz clusterwild bit involv guarante base fact clusterwild treat one run peel algorithm noisi graph sinc adjac activ vertex still becom cluster center clusterwild one view edg delet somewhat unconvent adversari analyz new noisi graph establish theoret result theorem clusterwild achief opto nlog n approxim expect provid sketch proof deleg detail appendix sinc clusterwild ignor edg among activ vertex treat edg delet main result quantifi loss cluster accuraci caus ignor edg proceed defin bad triangl combinatori structur use measur cluster qualiti peel algorithm definit bad triangl g set three vertex two pair join posit edg one pair join neg edg let tb denot set bad triangl g quantifi cost clusterwild make observ lemma cost greedi algorithm pick vertex v irrespect sampl order creat cv peel away repeat equal number bad triangl adjac cluster center v lemma let g denot random graph induc delet edg activ vertex per round give run clusterwild let new denot number addit bad triangl thatp g compar g expect cost clusterwild upper bound e ttb pt new pt event triangl end point j k bad least one end point becom activ still part origin unclust graph proof begin bound second term e new consid number new bad triangl newi creat round e newi x uv e p u v ai n u [ n v x uv e e n use result clusterwild termin log n log round get e new n log n p p leav bind e ttb pt ttb pt use follow lemma p p pt lemma pt satisfi e tettb ttb pt op proof let b one mani set thatpattribut thep cost optim p possibl p p edg pt pt pt algorithm opt eb eb tettb ttb b \ ttb z [ ] p simpli boundsth expect bad triangl adjac edg u v uv ttb pt let suv uv ttb union set node bad triangl contain vertex u v observ w s\ u v becom activ u v cost e cost bad triangl u v w incur hand either u v select pivot round cuv high e equal bad triangl contain edg u v let auv u v activ vertex suv c e [ cuv ] e [ cuv auv ] p auv e cuv ac uv p auv p u v \ \ p v \ \ last inequ obtain union bind u v bind follow probabl p v \ p v p \ v p v p \ p \ p v p \ observ p v henc need upper bind p \ probabl per round posit neighbor becom activ upper bound np np np n p p p p n n n n e p henc probabl upper bound p v \ \ e know also n henc p e cuv exp ttb pt new overal expect bound e e opt n ln n log approxim ratio clusterwild opt n log n establish bsp algorithm proxi asynchron algorithm would like note analysi bsp model use proxi perform complet asynchron variant algorithm specif see alg remov synchron barrier differ asynchron execut alg compar alg complet lack bulk synchron end process activ set although analysi bsp variant algorithm tractabl unfortun analyz precis speedup asynchron c approxim guarante asynchron clusterwild challeng howev experiment section test complet asynchron algorithm bsp algorithm previou section observ perform quit similarli term accuraci cluster run time skip constant simplifi present howev small relat work correl cluster formal introduc bansal et al [ ] gener case minim disagr nphard hard approxim within arbitrarili small constant apxhard [ ] two variat problem cc complet graph edg present weight ii cc gener graph arbitrari edg weight problem hard howev gener graph setup seem fundament harder best know approxim ratio latter log n reduct minimum multicut problem indic improv requir fundament breakthrough theoret algorithm [ ] algorithm c clusterwild asynchron execut input g clusterid clusterid n random permut n v v first element v v v v c concurr control attemptclust v els clusterwild coordin free createclust v end remov cluster vertex v end output clusterid clusterid n case complet unweight graph long seri result establish approxim via round linear program lp [ ] recent result establish approxim use eleg round lp relax [ ] avoid expens lp use round procedur [ ] basi greedi algorithm yield kwikclust approxim cc complet unweight graph variat cost metric cc chang algorithm landscap maxim agreement dual measur disagr [ ] maxim differ number agreement disagr [ ] come differ hard approxim result also sever variant chromat cc [ ] overlap cc [ ] small number cluster cc add constraint suitabl biolog applic [ ] way c find cluster center see variat mi algorithm [ ] main differ case passiv detect mi lock memori variabl wait preced order thread mean vertex push cluster i would statu cluster centerclusteredunclust friend versu pull ask friend cluster statu save substanti amount comput effort experi parallel algorithm implement scalaw defer full discuss implement detail appendix c run experi amazon ec r xlarg vcpu gb memori instanc use thread real graph list tabl graph dblp enwiki uk webbas vertex edg descript dblp coauthorship network [ ] link graph english part wikipedia [ ] crawl uk domain [ ] crawl domain [ ] crawl webbas crawler [ ] tabl graph use evalu parallel algorithm test differ random order measur runtim speedup ratio runtim thread runtim p thread object valu obtain parallel algorithm comparison also implement algorithm present [ ] denot cdk short valu use c bsp clusterwild bsp cdk interest space present repres plot result full result give appendix code avail httpsgithub compxinghaoparallelcorrelationclust cdk test small graph dblp enwiki cdk prohibit slow often order magnitud slow c clusterwild even kwikclust mean runtim uk mean runtim ms mean runtim ms mean runtim serial c c bsp cw cw bsp mean speedup webbas serial c c bsp cw cw bsp ideal c c bsp cw cw bsp speedup number thread mean runtim uk block vertex number round mean number synchron round bsp algorithm number thread number thread c mean speedup webbas object valu rel serial dblp c bsp min c bsp mean c bsp max c bsp min c bsp mean c bsp max block vertex enwiki ccw bsp uk ccw bsp ccw bsp webbas ccw bsp dblp cdk dblp ccw bsp enwiki cdk enwiki number thread b mean runtim mean number round algo obj valu serial obj valu e percent block vertex c enwiki bsp run cw bsp mean cw bsp median cw mean cw median cdk mean cdk median number thread f median object valu dblp cw bsp cdk run figur figur cw short clusterwild bsp short bulksynchron variant parallel algorithm short asynchron variant runtim speedup c clusterwild initi slower serial due overhead requir atom oper parallel set howev parallel algorithm outperform kwikclust thread thread add asychron variant becom fast bsp counterpart synchron barrrier differ bsp asychron variant great small clusterwild also alway faster c sinc coordin overhead asynchron algorithm abl achiev speedup x thread bsp algorithm poor speedup ratio nevertheless achiev x speedup synchron round main overhead bsp algorithm lie need synchron round increas amount synchron decreas algorithm less synchron round small consid size graph multicor set block vertex addit c incur overhead number vertex block wait earli vertex complet note overhead extrem small practic graph less vertex block larg sparser graph drop less e vertex object valu design c algorithm also return output thu object valu kwikclust find clusterwild bsp bad serial across graph valu behavior asynchron clusterwild worsen thread add reach wors serial one graph final small graph abl test cdk cdk return bad median object valu clusterwild variant conclus futur direct paper present two parallel algorithm correl cluster nearli linear speedup provabl approxim ratio overal two approach support otherwhen c rel fast rel clusterwild may prefer c guarante accuraci clusterwild accur rel c may prefer clusterwild speed futur intend implement algorithm distribut environ synchron commun often account high cost c clusterwild wellsuit distribut environ sinc polylogarithm number round refer [ ] ahm k elmagarmid panagioti g ipeiroti vassilio verykio duplic record detect survey knowledg datum engin ieee transact [ ] arvind arasu christoph dan suciu largescal dedupl constraint use dedupalog datum engin icd ieee th intern confer page ieee [ ] micha elsner warren schudi bound compar method correl cluster beyond ilp proceed workshop integ linear program natur langaug process page associ comput linguist [ ] bilal hussain okti hassanzadeh fei chiang hyun chul lee rene j miller evalu cluster algorithm duplic detect technic report [ ] francesco bonchi david garciasoriano edo liberti correl cluster theori practic proceed th acm sigkdd intern confer knowledg discoveri datum mine page acm [ ] flavio chierichetti nilesh dalvi ravi kumar correl cluster mapreduc proceed th acm sigkdd intern confer knowledg discoveri datum mine page acm [ ] bo yang william k cheung jim liu commun mine sign social network knowledg datum engin ieee transact [ ] n cesabianchi c gentil f vital g zappella et al correl cluster approach link classif sign network annual confer learn theori page microtom [ ] amir bendor ron shamir zohar yakhini cluster gene express pattern journal comput biolog [ ] nir ailon mo charikar alantha newman aggreg inconsist inform rank cluster journal acm jacm [ ] xinghao pan joseph e gonzalez stefani jegelka tamara broderick michael jordan optimist concurr control distribut unsupervis learn advanc neural inform process system page [ ] guy e blelloch jeremi fineman julian shun greedi sequenti maxim independ set match parallel averag proceed twentyfourth annual acm symposium parallel algorithm architectur page acm [ ] michael krivelevich phase transit site percol pseudorandom graph arxiv preprint arxiv [ ] nikhil bansal avrim blum shuchi chawla correl cluster ieee th annual symposium foundat comput scienc page ieee comput societi [ ] mo charikar venkatesan guruswami anthoni wirth cluster qualit inform foundat comput scienc proceed th annual ieee symposium page ieee [ ] erik demain dotan emanuel amo fiat nicol immorlica correl cluster gener weight graph theoret comput scienc [ ] shuchi chawla konstantin makarychev tselil schramm grigori yaroslavtsev near optim lp round algorithm correl cluster complet complet kpartit graph proceed fortyseventh annual acm symposium theori comput stoc page [ ] chaitanya swami correl cluster maxim agreement via semidefinit program proceed fifteenth annual acmsiam symposium discret algorithm page societi industri appli mathemat [ ] ioanni gioti venkatesan guruswami correl cluster fix number cluster proceed seventeenth annual acmsiam symposium discret algorithm page acm [ ] mo charikar anthoni wirth maxim quadrat program extend grothendieck inequ foundat comput scienc proceed th annual ieee symposium page ieee [ ] noga alon konstantin makarychev yuri makarychev assaf naor quadrat form graph invent mathematica [ ] francesco bonchi aristid gioni francesco gullo antti ukkonen chromat correl cluster proceed th acm sigkdd intern confer knowledg discoveri datum mine page acm [ ] francesco bonchi aristid gioni antti ukkonen overlap correl cluster datum mine icdm ieee th intern confer page ieee [ ] gregori j puleo olgica milenkov correl cluster constrain cluster size extend weight bound arxiv preprint arxiv [ ] p boldi vigna webgraph framework compress techniqu www [ ] p boldi rosa santini vigna layer label propag multiresolut coordinatefre order compress social network www acm press [ ] p boldi b codenotti santini vigna ubicrawl scalabl fulli distribut web crawler softwar practic experi
